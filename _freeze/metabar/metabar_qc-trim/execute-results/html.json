{
  "hash": "1f668c0a4479e78d9d973bfdba11d20b",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"Read QC and primer trimming\"\nsubtitle: \"With FastQC, MultiQC, and Cutadapt\"\npagetitle: \"QC & Trimming\"\nauthor: Jelmer Poelstra\ndate: 2024-03-13\nexecute: \n  eval: false\nknitr:\n  opts_chunk:\n    out.width: \"85%\"\n    class-output: bash-out\neditor_options: \n  chunk_output_type: console\n---\n\n\n\n\n----------------------------------------------------------------------------------------------------\n\n<br>\n\n## Introduction {-}\n\nThe first series of steps our analysis workflow concerns\nthe quality control (QC) & \"pre-processing\" of the raw sequence reads,\nwhich are stored in FASTQ files.\n\nThe QC part will leave the data untouched,\nwhereas the pre-processing involves the removal of unwanted bits of sequence:\nin our case, amplicon primers.\nAfter the pre-processing step, we will still have FASTQ files,\njust with somewhat less content.\n\nSpecifically, we will go through the following steps:\n\n1. QC with **FastQC**\n2. Summarizing FastQC results with **MultiQC**\n3. Removing primers with **Cutadapt**\n\n<hr style=\"height:1pt; visibility:hidden;\" />\n\n::: {.callout-note collapse=\"true\"}\n#### You should have an active VS Code session. If not, follow these steps _(Click to expand)_\n\n**Start a new VS Code session with an open terminal:**\n\n1.  Log in to OSC's OnDemand portal at <https://ondemand.osc.edu>.\n2.  In the blue top bar, select `Interactive Apps` and then near the bottom of the\n    dropdown menu, click `Code Server`.\n3.  In the form that appears on a new page:\n    -   Select OSC project `PAS2714`\n    -   The starting directory: `/fs/ess/PAS2714/<user>` (replace `<user>` with your username)\n    -   `Number of hours`: `3`\n    -   Click `Launch`.\n4.  On the next page, once the top bar of the box has turned green and says `Runnning`,\n    click `Connect to VS Code`.\n5.  Open a Terminal by clicking   {{< fa bars >}}   =\\> `Terminal` =\\> `New Terminal`.\n:::\n\n<br>\n\n## Running FastQC for 1 sample\n\n### Intro to FastQC\n\nFastQC is a ubiquitous tools for **quality control of FASTQ files**.\nRunning FastQC or a similar program is the first step in nearly any\nhigh-throughput sequencing project.\nFastQC is also a good introductory example of a tool with a command-line interface.\n\nFor each FASTQ file, FastQC outputs an **HTML file** that you can open in your\nbrowser with about a dozen graphs showing different QC metrics.\nThe most important one is the **per-base quality score graph** shown below.\n\n![A FastQC per-base quality score graph for files with reasonably good quality reads.\nThe y-axis shows Phred quality scores (higher is better, see also the color-coding) and the x-axis shows the position along the read.](img/fastqc_good.png){fig-align=\"center\" width=\"70%\"}\n\n<hr style=\"height:1pt; visibility:hidden;\" />\n\n### Our FASTQ files\n\nOur FASTQ files contain reads from 2x300 bp (i.e. paired-end with 300 bp\nforward and 300 bp reverse reads) sequencing on an Illumina MiSeq machine.\n\nLet's take a look at our list of FASTQ files:\n\n``` bash\nls -lh data/fastq\n```\n``` bash-out\ntotal 150M\n-rw-r-----+ 1 jelmer PAS0471 2.0M Mar  1 17:09 NW102AB_R1.fastq.gz\n-rw-r-----+ 1 jelmer PAS0471 2.6M Mar  1 17:09 NW102AB_R2.fastq.gz\n-rw-r-----+ 1 jelmer PAS0471 2.3M Mar  1 17:09 NW102C_R1.fastq.gz\n-rw-r-----+ 1 jelmer PAS0471 3.0M Mar  1 17:09 NW102C_R2.fastq.gz\n-rw-r-----+ 1 jelmer PAS0471 1.9M Mar  1 17:09 NW103AB_R1.fastq.gz\n-rw-r-----+ 1 jelmer PAS0471 2.6M Mar  1 17:09 NW103AB_R2.fastq.gz\n-rw-r-----+ 1 jelmer PAS0471 2.3M Mar  1 17:09 NW103C_R1.fastq.gz\n-rw-r-----+ 1 jelmer PAS0471 3.1M Mar  1 17:09 NW103C_R2.fastq.gz\n# [...output truncated...]\n```\n\nNote in the file listing above that:\n\n-   There are two files per sample: `_R1` (forward reads) and `_R2` (reverse reads).\n    This indicates that we have data from **paired-end reads**,\n    as is customary when doing amplicon metabarcoding.\n-   The files all have a `.gz` extension, indicating they have been _compressed_ with the gzip utility.\n\n::: {.callout-warning collapse=\"true\"}\n#### Don't have the FASTQ files? Click here for instructions to copy them.\n\nRun the following two `cp` commands to copy the necessary data:\n\n```bash\ncp -rv /fs/ess/PAS2714/share/data /fs/ess/PAS2714/users/$USER\ncp -rv /fs/ess/PAS2714/share/results /fs/ess/PAS2714/users/$USER\n```\n:::\n\n<hr style=\"height:1pt; visibility:hidden;\" />\n\n### Building our FastQC command\n\nTo run FastQC, we can use the command `fastqc`.\n\nIf you want to analyze one of your FASTQ files with default FastQC settings,\na complete FastQC command to do so would simply be `fastqc` followed by the name of the file:\n\n``` bash\n# (Don't run this)\nfastqc data/fastq/NW102AB_R1.fastq.gz\n```\n\nHowever, an annoying FastQC **default behavior** is that it writes its output files\nin the dir where the input files are ---\nin general, it's not great practice to directly mix your primary data and results like that!\n\nTo figure out how we can change that behavior,\nfirst consider that many commands and bioinformatics tools alike have an\n**option `-h` and/or `--help`** to print usage information to the screen.\nLet's try that:\n\n``` bash\nfastqc -h\n```\n``` bash-out\nbash: fastqc: command not found...\n```\n\nHowever, there is a wrinkle:\nwhile FastQC is installed at OSC[^2], we have to first **\"load it\"**.\nThe way we will do this here is with a a so-called \"Conda environment\" that has\nFastQC installed along with the other programs we will need today.\n\n[^2]: For a full list of installed software at OSC: <https://www.osc.edu/resources/available_software/software_list>\n\n**Here's how we can load that Conda software environment** ---\nwe first load OSC's (mini)conda installation,\nand then we can load (\"activate\") the Conda environment that I created for you:\n\n``` bash\nmodule load miniconda3\nsource activate /fs/ess/PAS0471/jelmer/conda/mbar24\n```\n\n::: callout-tip\n#### Conda and software management\nWe won't have time to get into this now,\nbut you want to learn more about Conda / software usage at supercomputers,\nsee [this reference page elsewhere on the website](ref/software.qmd).\n:::\n\n<hr style=\"height:1pt; visibility:hidden;\" />\n\n::: exercise\n#### {{< fa user-edit >}} **Exercise**: FastQC help and output dir\n\nPrint FastQC's help info,\nand figure out which option you can use to specify a custom output directory.\n\n<details><summary>*Click for the solution*</summary>\n\n`fastqc -h` and `fastqc --help` will both work to show the help info.\n\nYou'll get quite a bit of output printed to screen,\nincluding the snippet about output directories that is reproduced below:\n\n``` bash\nfastqc -h\n```\n\n``` bash-out\n  -o --outdir     Create all output files in the specified output directory.\n                    Please note that this directory must exist as the program\n                    will not create it.  If this option is not set then the \n                    output file for each sequence file is created in the same\n                    directory as the sequence file which was processed.\n```\n\nSo, you can use `-o` or equivalently, `--outdir` to specify an output dir.\n\n</details>\n:::\n\n<hr style=\"height:1pt; visibility:hidden;\" />\n\nWith the added `--outdir` (or `-o`) option, let's try to run the following FastQC command:\n\n``` bash\n# We'll have to first create the outdir ourselves, in this case\nmkdir -p results/fastqc\n\n# Now we run FastQC\nfastqc --outdir results/fastqc data/fastq/NW102AB_R1.fastq.gz\n```\n``` bash-out\napplication/gzip\nStarted analysis of NW102AB_R1.fastq.gz\nApprox 5% complete for NW102AB_R1.fastq.gz\nApprox 10% complete for NW102AB_R1.fastq.gz\nApprox 15% complete for NW102AB_R1.fastq.gz\n[...truncated...]\nAnalysis complete for NW102AB_R1.fastq.gz\n```\n\nSuccess!! 🎉\n\n<hr style=\"height:1pt; visibility:hidden;\" />\n\n### FastQC output files\n\nLet's take a look at the files in the output dir we specified:\n\n``` bash\nls -lh results/fastqc\n```\n``` bash-out\ntotal 1.2M\n-rw-r--r-- 1 jelmer PAS0471 241K Mar 13 14:50 NW102AB_R1_fastqc.html\n-rw-r--r-- 1 jelmer PAS0471 256K Mar 13 14:50 NW102AB_R1_fastqc.zip\n```\n\n-   There is a `.zip` file, which contains **tables** with FastQC's data summaries.\n-   There is an `.html` (HTML) file, which contains **plots** --- this is what we'll look at next.\n\n<hr style=\"height:1pt; visibility:hidden;\" />\n\n::: exercise\n#### {{< fa user-edit >}} **Exercise**: Another FastQC run\n\nRun FastQC for the corresponding R2 FASTQ file. Would you use the same output dir?\n\n<details><summary>*Click for the solution*</summary>\n\nYes, it makes sense to use the same output dir, since as you could see above, the output file names have the input file identifiers in them. As such, we don't need to worry about overwriting files, and it will be more convenient to have all results in a single dir.\n\nTo run FastQC for the R2 (reverse-read) file:\n\n``` bash\nfastqc --outdir results/fastqc data/fastq/NW102AB_R2.fastq.gz\n```\n``` bash-out\nStarted analysis of NW102AB_R2.fastq.gz\nApprox 5% complete for NW102AB_R2.fastq.gz\nApprox 10% complete for NW102AB_R2.fastq.gz\nApprox 15% complete for NW102AB_R2.fastq.gz\n[...truncated...]\nAnalysis complete for NW102AB_R2.fastq.gz\n```\n\n``` bash\nls -lh results/fastqc\n```\n\n``` bash-out\n-rw-r--r-- 1 jelmer PAS0471 241K Mar 13 14:50 NW102AB_R1_fastqc.html\n-rw-r--r-- 1 jelmer PAS0471 256K Mar 13 14:50 NW102AB_R1_fastqc.zip\n-rw-r--r-- 1 jelmer PAS0471 234K Mar 13 14:53 NW102AB_R2_fastqc.html\n-rw-r--r-- 1 jelmer PAS0471 244K Mar 13 14:53 NW102AB_R2_fastqc.zip\n```\n\nNow, we have four files: two for each of our preceding successful FastQC runs.\n\n</details>\n:::\n\n<br>\n\n## Interpreting FastQC output\n\n### FastQC HTML modules\n\nWe'll now go through a couple of the FastQC plots/modules with example plots^[\nAttribution: Some of the FastQC example plots were taken from [here](https://rtsf.natsci.msu.edu/sites/_rtsf/assets/File/FastQC_TutorialAndFAQ_080717.pdf).]\nwith good/bad results for reference.\n\nFastQC has \"**pass**\" (checkmark in green), \"**warning**\" (exclamation mark in orange),\nand \"**fail**\" (cross in red) assessments for each module.\nThese assessments are handy,\nbut a \"warning\"/\"fail\" is not necessarily the bad news it may appear to be:\n\n-   Some of these modules are perhaps overly strict.\n-   Some warnings and fails are easily remedied or simply not a very big deal.\n-   FastQC effectively assumes that your data is derived from whole-genome shotgun sequencing ---\n    some other types of data with different properties will therefore _always_ trigger a\n    couple of warnings and fails, but these are not meaningful.\n    This is very much the case for metabarcoding data.\n\n![An example module results overview from a FastQC HTML file.<br>The green checkmarks indicate Pass, the orange exclamation marks indicate Warning, and the red crosses indicate Fail.](img/fastqc_summary2.png){fig-align=\"center\" width=\"30%\"}\n\n<hr style=\"height:1pt; visibility:hidden;\" />\n\n#### Basic statistics\n\nThis contains, among other things, the number of sequences (reads) and the read length range:\n\n![](img/fastqc_mod01_basic-stats.png){fig-align=\"center\" width=\"85%\"}\n\n<hr style=\"height:1pt; visibility:hidden;\" />\n\n#### Per base quality sequence quality\n\nThis figure visualizes the mean per-base quality score (y-axis) along the length of the reads (x-axis). \nNote that:\n\n-   A decrease in sequence quality along the reads (from left to right) is normal.\n-   R2 (reverse) reads are usually of worse quality than R1 (forward) reads.\n\n::: columns\n::: {.column width=\"50%\"}\n![**Good / acceptable**](img/fastqc_good.png){fig-align=\"center\" width=\"100%\"}\n:::\n::: {.column width=\"50%\"}\n![**Bad**](img/fastqc_bad.png){fig-align=\"center\" width=\"100%\"}\n:::\n:::\n\nTo interpret the y-axis quality scores,\nnote the color scaling in the graphs above, and see this table for details:\n\n| Phred quality score | Error probability | Rough interpretation |\n|---------------------|-------------------|----------------------|\n| **10**              | 1 in 10           | terrible             |\n| **20**              | 1 in 100          | bad                  |\n| **30**              | 1 in 1,000        | good                 |\n| **40**              | 1 in 10,000       | excellent            |\n\n<hr style=\"height:1pt; visibility:hidden;\" />\n\n#### Per sequence quality scores\n\nThis shows the same quality scores we saw above, but now simply as a density plot of per-read averages, with the quality score now along the x-axis, and the number of reads with that quality score along the y-axis:\n\n::: columns\n::: {.column width=\"50%\"}\n![**Good**](img/fastqc_mod04_per-seq-qual_good.png){fig-align=\"center\" width=\"100%\"}\n:::\n\n::: {.column width=\"50%\"}\n![**Bad**](img/fastqc_mod04_per-seq-qual_bad.png){fig-align=\"center\" width=\"100%\"}\n:::\n:::\n\n#### Per tile sequence quality\n\nThis graph shows whether specific tiles (areas on the flow cell, see box below)\nhave lower quality bases in some parts of or across all of the read.\n\nPoor qualities in some but not other tiles may indicate some (transient) problems with the flow cell.\nFor example, if a tile has poor qualities for a stretch of bases,\nthis could indicate that there was a bubble.\nIf such tile-based problems are severe, you can contact the sequencing facility\nas they may be able to re-run your data at no cost.\n\n::: {.callout-tip collapse=true}\n#### What is a tile? _(Click to expand)_\n![](img/tiles.png){fig-align=\"center\" width=\"90%\"}\n:::\n\n::: columns\n::: {.column width=\"43%\"}\n![**Good**](img/fastqc_mod03_per-tile_good.png){fig-align=\"center\" width=\"100%\"}\n:::\n\n::: {.column width=\"57%\"}\n![**Some problems**](img/fastq_mod04_per-tile_moderate.png){fig-align=\"center\" width=\"100%\"}\n:::\n:::\n\n#### Sequence length distribution\n\nWith Illumina sequencing, the vast majority of reads typically have nearly the same read length ---\nin our case, 300 bp. This graph can help you check if that is indeed the case.\nThe module will throw a warning as soon as not all sequences are of the same length (like below),\nbut having reads with a slightly shorter read length is normal and does not matter. \n\n::: columns\n::: {.column width=\"50%\"}\n![**Good**<br>Nearly all reads have the same read length. <br>FastQC still threw a warning.](img/fastqc_mod08_seqlen_good.png){fig-align=\"center\" width=\"100%\"}\n:::\n::: {.column width=\"50%\"}\n![**Somewhat bad**<br>There are unusually many reads that are shorter than the aimed-for, 150 bp read length. Though the large majority of reads are still 150 bp.](img/fastqc_mod08_seqlen_warning.png){fig-align=\"center\" width=\"100%\"}\n:::\n:::\n\n#### Other FastQC modules\n\nAnother module that can help to check the overall quality of your reads is\n**Per base N content**: its line graph should typically not visibly rise above 0%.\n\nThe remaining modules are not that useful for metabarcoding data:\n\n- Adapter content^[Checks for adapters at the ends of reads. Since we have to remove primers anyway, any adapters past the primers will be automatically removed.]\n- Sequence duplication levels^[\n  Will throw a Fail but this is not meaningful here: metabarcoding data has many duplicate sequences by design.]\n- Overrepresented sequences^[As with the previous module, this will throw a Fail but this is not meaningful here: metabarcoding data has many duplicate sequences by design.]\n- Per sequence GC content^[Useful in a whole-genome sequencing context or to detect contamination.]\n\n<hr style=\"height:1pt; visibility:hidden;\" />\n\n### Checking your FastQC results\n\nFirst, you'll unfortunately have to download FastQC's output HTML files to your computer\nto be able to view them:\n\n-   Find the FastQC HTML files in the file explorer in the VS Code side bar.\n-   Right-click on one of them, click `Download...` and follow the prompt to\n    download the file somewhere to your computer (doesn't matter where).\n-   Repeat this for the second file.\n-   Then, open your computer's file browser, find the downloaded files,\n    and double-click on one. It should be **opened in your default web browser**.\n\nAlternatively, you can take a look at the FastQC output files on this website:\n[R1](results/fastqc/NW102AB_R1_fastqc.html) and [R2](results/fastqc/NW102AB_R2_fastqc.html).\n\n::: exercise\n#### {{< fa user-edit >}} **Exercise**: Interpreting your FastQC results\n\n- Open the HTML file for the R1 FASTQ file and go through the modules we discussed above.\n  Can you make sense of it? Does the data look good to you, overall?\n\n- Now open the HTML file for the **R2** FASTQ file and take a look just at the quality scores.\n  Does it look any worse than the R1?\n:::\n\n<br>\n\n## Running FastQC for all samples\n\nIf we want to run FastQC for all samples,\nit will be much better to write a shell script and submit that as a so-called Slurm batch job,\nrather than running FastQC \"interactively\" like we did for the first sample.\n\nThis is especially true for a complete data set,\nwhich would have much larger FASTQ files and possibly more samples.\n\n### The components of our script\n\nHere is all the code we needed for out first FastQC run:\n\n```bash\n# Load the software\nmodule load miniconda3\nsource activate /fs/ess/PAS0471/jelmer/conda/mbar24\n\n# Create the output dir\nmkdir -p results/fastqc\n\n# Run FastQC\nfastqc --outdir results/fastqc data/fastq/NW102AB_R1.fastq.gz\n```\n\n<hr style=\"height:1pt; visibility:hidden;\" />\n\nWe will need that same code in the script,\nexcept that we will need to modify our call to `fastqc` ---\nwe will **loop over all FASTQ files** as follows:\n\n```bash\n# Run FastQC (replacement for fastqc line above)\nfor fastq_file in data/fastq/*fastq.gz; do\n    fastqc --outdir results/fastqc \"$fastq_file\"\ndone\n```\n\n- We are looping over all FASTQ files with the globbing pattern `data/fastq/*fastq.gz`.\n  The loop will run as many times as we have FASTQ files.\n- In every iteration of the loop, the `\"$fastq_file\"` variable will contain 1 FASTQ file name,\n  and we will run `fastqc` for that file^[Therefore, our FastQC analysis will run sequentially\n  (1-by-1) for each file, not in parallel.].\n\n<hr style=\"height:1pt; visibility:hidden;\" />\n\nWe will be **submitting this script as a batch job** to the Slurm compute job scheduler.\nTo do so, we should also add some lines at the top of the script:\n\n```bash\n#!/bin/bash\n\n#SBATCH --account=PAS2714\n#SBATCH --output=slurm-fastqc.out\n```\n\n- The first line `#!/bin/bash` merely indicates that this is a shell script^[\n  Using the shell language Bash, specifically]\n  rather than, say, an R or Python script.\n- The lines starting with `#SBATCH` tell Slurm some details about our compute job request\n  (much like we did when we filled out the form to start a VS Code session):\n  - We always need to specify an \"`account`\", i.e. OSC project, that should be billed.\n  - The only other option (of many possible!) we will use here is to specify\n    the `output` file: this is where any output will go that would otherwise be printed to screen,\n    such as the FastQC progress output we saw above.\n\n<hr style=\"height:1pt; visibility:hidden;\" />\n\nWe will also add the following line to change some shell script settings,\nwhich will cause the script to stop running if any **errors** occur:\n\n```bash\n# Strict bash settings\nset -euo pipefail\n```\n\n<hr style=\"height:1pt; visibility:hidden;\" />\n\n### Our final script\n\n1. Open a new file in VS Code: click <i class=\"fa fa-bars\"></i>, then `File`, then `New File`.\n2. Save the file (e.g. press <kbd>Ctrl/⌘</kbd>+<kbd>S</kbd>) in your `scripts` directory as `fastqc.sh`.\n3. Paste the following code in the script:\n\n```bash\n#!/bin/bash\n\n#SBATCH --account=PAS2714\n#SBATCH --output=slurm-fastqc.out\n\n# Strict bash settings\nset -euo pipefail\n\n# Load the software\nmodule load miniconda3\nsource activate /fs/ess/PAS0471/jelmer/conda/mbar24\n\n# Create the output dir\nmkdir -p results/fastqc\n\n# Run FastQC for all FASTQ files\nfor fastq_file in data/fastq/*fastq.gz; do\n    fastqc --outdir results/fastqc \"$fastq_file\"\ndone\n\n# Report\necho \"Done with script fastqc.sh\"\ndate\n```\n\n<hr style=\"height:1pt; visibility:hidden;\" />\n\n### Submitting the script\n\nSubmit the script to Slurm (\"submit it to the queue\") with the `sbatch` command:\n\n```bash\nsbatch scripts/fastqc.sh\n```\n```bash-out\nSubmitted batch job 27047185\n```\n\nAfter some seconds (sometimes up to a minute or so^[\nAnd very large jobs can sometimes take hours to start, but our jobs are small so that should not happen.]),\nthe Slurm job should start and create the output file that we specified at the top of the script:\n`slurm-fastqc.out`.\n\n<hr style=\"height:1pt; visibility:hidden;\" />\n\n### Checking the output\n\nIn our earlier two FastQC runs,\nFastQC logging output (\"10% complete\", etc.) was printed to screen.\nBut because this job now runs remotely on another compute node,\nsuch output will end up in the \"Slurm log file\" whose name we specified in the script.\nLet's take a look:\n\n```bash\nless slurm-fastqc.out\n```\n```bash-out\napplication/gzip\nStarted analysis of NW102AB_R1.fastq.gz\nApprox 5% complete for NW102AB_R1.fastq.gz\nApprox 15% complete for NW102AB_R1.fastq.gz\nApprox 20% complete for NW102AB_R1.fastq.gz\nApprox 30% complete for NW102AB_R1.fastq.gz\nApprox 35% complete for NW102AB_R1.fastq.gz\nApprox 45% complete for NW102AB_R1.fastq.gz\nApprox 50% complete for NW102AB_R1.fastq.gz\nApprox 60% complete for NW102AB_R1.fastq.gz\nApprox 70% complete for NW102AB_R1.fastq.gz\nApprox 75% complete for NW102AB_R1.fastq.gz\nApprox 85% complete for NW102AB_R1.fastq.gz\nApprox 90% complete for NW102AB_R1.fastq.gz\nAnalysis complete for NW102AB_R1.fastq.gz\napplication/gzip\nStarted analysis of NW102AB_R2.fastq.gz\nApprox 5% complete for NW102AB_R2.fastq.gz\nApprox 15% complete for NW102AB_R2.fastq.gz\nApprox 20% complete for NW102AB_R2.fastq.gz\n#[...output truncated...]\n```\n\nThat looks good, in the output I printed above we can see that FastQC ran to completion\nfor one FASTQ file and then started a second --- and this will go on and on,\nfor all of our 64 FASTQ files.\n\nYou will know that the job has successfully finished when the last few lines of the Slurm log file\nread \"_Done with script fastqc.sh_\" and print the date and time (as per the last lines of our script!):\n\n```bash\ntail slurm-fastqc.out\n```\n```bash-out\nApprox 75% complete for W404BC_R2.fastq.gz\nApprox 85% complete for W404BC_R2.fastq.gz\nApprox 90% complete for W404BC_R2.fastq.gz\nApprox 95% complete for W404BC_R2.fastq.gz\nAnalysis complete for W404BC_R2.fastq.gz\nDone with script fastqc.sh\nWed Mar  6 13:34:10 EST 2024\n```\n\n<hr style=\"height:1pt; visibility:hidden;\" />\n\nOf course, we should also check the **main output files** --- the HTMLs and zip files:\n\n```bash\nls results/fastqc\n```\n```bash-out\nNW102AB_R1_fastqc.html  NW103C_R1_fastqc.zip    NW203A_R2_fastqc.html   NW304BC_R2_fastqc.zip   NW403BC_R1_fastqc.html  W101AB_R1_fastqc.zip   W103C_R2_fastqc.html   W205A_R2_fastqc.zip    W304AB_R1_fastqc.html  W403C_R1_fastqc.zip\nNW102AB_R1_fastqc.zip   NW103C_R2_fastqc.html   NW203A_R2_fastqc.zip    NW305AB_R1_fastqc.html  NW403BC_R1_fastqc.zip   W101AB_R2_fastqc.html  W103C_R2_fastqc.zip    W205BC_R1_fastqc.html  W304AB_R1_fastqc.zip   W403C_R2_fastqc.html\nNW102AB_R2_fastqc.html  NW103C_R2_fastqc.zip    NW203BC_R1_fastqc.html  NW305AB_R1_fastqc.zip   NW403BC_R2_fastqc.html  W101AB_R2_fastqc.zip   W204A_R1_fastqc.html   W205BC_R1_fastqc.zip   W304AB_R2_fastqc.html  W403C_R2_fastqc.zip\nNW102AB_R2_fastqc.zip   NW201AB_R1_fastqc.html  NW203BC_R1_fastqc.zip   NW305AB_R2_fastqc.html  NW403BC_R2_fastqc.zip   W101C_R1_fastqc.html   W204A_R1_fastqc.zip    W205BC_R2_fastqc.html  W304AB_R2_fastqc.zip   W404A_R1_fastqc.html\nNW102C_R1_fastqc.html   NW201AB_R1_fastqc.zip   NW203BC_R2_fastqc.html  NW305AB_R2_fastqc.zip   NW404A_R1_fastqc.html   W101C_R1_fastqc.zip    W204A_R2_fastqc.html   W205BC_R2_fastqc.zip   W304C_R1_fastqc.html   W404A_R1_fastqc.zip\nNW102C_R1_fastqc.zip    NW201AB_R2_fastqc.html  NW203BC_R2_fastqc.zip   NW305C_R1_fastqc.html   NW404A_R1_fastqc.zip    W101C_R2_fastqc.html   W204A_R2_fastqc.zip    W303AB_R1_fastqc.html  W304C_R1_fastqc.zip    W404A_R2_fastqc.html\nNW102C_R2_fastqc.html   NW201AB_R2_fastqc.zip   NW304A_R1_fastqc.html   NW305C_R1_fastqc.zip    NW404A_R2_fastqc.html   W101C_R2_fastqc.zip    W204BC_R1_fastqc.html  W303AB_R1_fastqc.zip   W304C_R2_fastqc.html   W404A_R2_fastqc.zip\nNW102C_R2_fastqc.zip    NW201C_R1_fastqc.html   NW304A_R1_fastqc.zip    NW305C_R2_fastqc.html   NW404A_R2_fastqc.zip    W103AB_R1_fastqc.html  W204BC_R1_fastqc.zip   W303AB_R2_fastqc.html  W304C_R2_fastqc.zip    W404BC_R1_fastqc.html\nNW103AB_R1_fastqc.html  NW201C_R1_fastqc.zip    NW304A_R2_fastqc.html   NW305C_R2_fastqc.zip    NW404BC_R1_fastqc.html  W103AB_R1_fastqc.zip   W204BC_R2_fastqc.html  W303AB_R2_fastqc.zip   W403AB_R1_fastqc.html  W404BC_R1_fastqc.zip\nNW103AB_R1_fastqc.zip   NW201C_R2_fastqc.html   NW304A_R2_fastqc.zip    NW403A_R1_fastqc.html   NW404BC_R1_fastqc.zip   W103AB_R2_fastqc.html  W204BC_R2_fastqc.zip   W303C_R1_fastqc.html   W403AB_R1_fastqc.zip   W404BC_R2_fastqc.html\nNW103AB_R2_fastqc.html  NW201C_R2_fastqc.zip    NW304BC_R1_fastqc.html  NW403A_R1_fastqc.zip    NW404BC_R2_fastqc.html  W103AB_R2_fastqc.zip   W205A_R1_fastqc.html   W303C_R1_fastqc.zip    W403AB_R2_fastqc.html  W404BC_R2_fastqc.zip\nNW103AB_R2_fastqc.zip   NW203A_R1_fastqc.html   NW304BC_R1_fastqc.zip   NW403A_R2_fastqc.html   NW404BC_R2_fastqc.zip   W103C_R1_fastqc.html   W205A_R1_fastqc.zip    W303C_R2_fastqc.html   W403AB_R2_fastqc.zip\nNW103C_R1_fastqc.html   NW203A_R1_fastqc.zip    NW304BC_R2_fastqc.html  NW403A_R2_fastqc.zip    W101AB_R1_fastqc.html   W103C_R1_fastqc.zip    W205A_R2_fastqc.html   W303C_R2_fastqc.zip    W403C_R1_fastqc.html\n```\n\nThat's a lot of files! Do we need to check all of them?\nLuckily not, thanks to MultiQC.\n\n<br>\n\n## Summarizing QC results with MultiQC\n\nHere are some challenges you may run into after running FastQC:\n\n- When you have many FASTQ files, you'll generate a lot of FastQC HTML files to sort through\n  (as we did above).\n- Even if you diligently go through each file,\n  it's not that easy to compare the results across samples in detail,\n  since they are not drawn in the same graphs.\n\nMultiQC addresses these problems by aggregating FastQC results from many files,\nand summarizing them into a single HTML file with (still) one graph per FastQC module.\n\n::: callout-tip\n#### Not just for FastQC results! MultiQC can recognize and process the output of dozens of bioinformatics tools.\n:::\n\nMultiQC's graphs are also _interactive_, but here is a static example of a graph\nshowing the mean base quality scores along the read for many FASTQ files:\n\n![](img/multiqc_fastqc_per_base_sequence_quality_plot.png){fig-align=\"center\" width=\"95%\"}\n\n<hr style=\"height:1pt; visibility:hidden;\" />\n\n<details><summary>{{< fa user-edit >}} Above, what could the two \"groups of lines\", which diverge towards the right-hand side, represent?</summary>\nThese are the files with forward (top lines, better quality) and reverse \n(bottom lines, worse quality) reads.\n</details>\n\n<hr style=\"height:1pt; visibility:hidden;\" />\n\nMultiQC will also create a graph comparing the number of reads across files,\nwhich can be quite useful:\n\n![](img/multiqc_readcounts.png){fig-align=\"center\" width=\"100%\"}\n\n<hr style=\"height:1pt; visibility:hidden;\" />\n\n### Running MultiQC\n\nWe will only need to run MultiQC once (because it will aggregate all FastQC results at once),\nand that will only take a few seconds ---\ntherefore, we can run the command interactively without using a script.\n\n::: {.callout-note collapse=\"true\"}\n#### Side note: Checking the MultiQC help _(Click to expand)_\n\nWe can check MultiQC's help with the `--help` option:\n\n```bash\nmultiqc --help\n# (Only the top part of the output is shown in the screenshot below)\n```\n\n![](img/multiqc_help.png){fig-align=\"center\" width=\"100%\"}\n\nAs the first couple of help lines in the paler gray color explain,\nMultiQC will search the `[ANALYSIS DIRECTORY]`,\na dir that we pass to it as an argument at the end of the command line.\n:::\n\nIf we tell MultiQC (command `multiqc`) about the `results/fastqc` directory like so,\nit should find and then aggregate all the FastQC results in there:\n\n```bash\n# (Don't run this - we'll complete the command in a second)\nmultiqc results/fastqc\n```\n\n::: callout-warning\n#### Need to active the Conda environment?\n\nIf you don't/no longer have the `mbar24` Conda environment active,\n(re-)activate it as follows:\n\n```bash\nmodule load miniconda3\nsource activate /fs/ess/PAS0471/jelmer/conda/mbar24\n```\n:::\n\nThe default output directory of MultiQC is the current working directory,\nso just like with FastQC, we do want to use the option for the output dir ---\nthis is our final command and you can go ahead and execute it:\n\n```bash\n# Run MultiQC to summarize the FastQC results\nmultiqc --outdir results/multiqc results/fastqc\n```\n\n![](img/multiqc_stdout.png){fig-align=\"center\" width=\"100%\"}\n\n<hr style=\"height:1pt; visibility:hidden;\" />\n\n### MultiQC output\n\nOnce its done, you should have the following files in the output dir:\n\n```bash\nls -lh results/multiqc\n```\n``` bash-out\ntotal 1.7M\ndrwxr-xr-x 2 jelmer PAS2250 4.0K Mar  13 14:57 multiqc_data\n-rw-r--r-- 1 jelmer PAS2250 1.7M Mar  13 14:57 multiqc_report.html\n```\n\nGo ahead and find the `multiqc_report.html` listed above in VS Code's file browser,\nright-click on it and download it to your computer.\nThen, click on the file in your own computer to open it in your browser\n(i.e., just like we did with the FastQC output).\n\nYou can also find a copy of the [MultiQC HTML output file here](results/multiqc/multiqc_report.html).\n\n::: exercise\n#### {{< fa user-edit >}} **Exercise**: Explore the MultiQC results\n\nCheck for example whether patterns are consistent across samples,\nor if there are any outliers.\n:::\n\n<br>\n\n## Cutadapt\n\nWhen you prepare samples for amplicon metabarcoding, you amplify a specific region\nwith primers, and these primers will be included in the sequences that you receive.\nBefore we go any further, we need to **remove these primer sequences**,\nwhich we can do with the program Cutadapt.\n\nWe will write a script with a loop to run Cutadapt for all samples and submit\nit as a batch job like we did with FastQC.\n\n### Primer sequences\n\nWhen we run Cutadapt, we need to tell it about our primer sequences as well as their\nreverse complements.\nWe'll start by storing our particular primer sequences in variables:\n\n```bash\n# Primer sequences\nprimer_f=GTGTGYCAGCMGCCGCGGTAA\nprimer_r=GGACTACNVGGGTWTCTAAT\n```\n\n::: callout-tip\n#### Ambiguity codes\nNote that the `Y`, `M`, `N`, `V` and `W` in the primer sequences are so-called\n\"ambiguity codes\" that represent multiple possible bases.\nFor example, a `Y` represents a `C` or a `T`, and an `N` represents any of the 4 bases.\n:::\n\nThere are many ways of getting the reverse complement of a sequence,\nincluding manually building it up,\nbut here we'll use a trick with the `tr` command to change each base into its\ncomplement, followed by the `rev` command to get the _reverse_ complement ---\nfor example, for the forward primer:\n\n```bash\necho \"$primer_f\" | tr ATCGYRKMBDHV TAGCRYMKVHDB | rev\n```\n```bash-out\nTTACCGCGGCKGCTGRCACAC\n```\n\nBelow, we'll get the reverse complement for both primers, and will store\nthose in a variable as well using the construct `variable=$(command)`^[This is called \"command substitution\".]:\n\n```bash\n# Get the reverse-complements of the primers\nprimer_f_rc=$(echo \"$primer_f\" | tr ATCGYRKMBDHV TAGCRYMKVHDB | rev)\nprimer_r_rc=$(echo \"$primer_r\" | tr ATCGYRKMBDHV TAGCRYMKVHDB | rev)\n\n# Check the sequences\necho \"$primer_f_rc\"\necho \"$primer_r_rc\"\n```\n```bash-out\nTTACCGCGGCKGCTGRCACAC\nATTAGAWACCCBNGTAGTCC\n```\n\n::: {.callout-note collapse=\"true\"}\n#### More about the above `tr | rev` command _(Click to expand)_\n\n- `tr A T` changes every A to a T\n- `tr ATC TAG` changes every A to a T (first character in each of the two sequences),\n  every T to an a (second character in each of the two sequences), and every C to a G\n  (third character in each of the two sequences).\n- Therefore, in the full `tr` command above, we list all possible bases and ambiguity codes,\n  and then change them to their complement.\n- The `rev` command simply reverses a sequence, so that we end up with the _reverse_ complement.\n\n```bash\necho ACCT | rev\n```\n```bash-out\nTCCA\n```\n<hr style=\"height:1pt; visibility:hidden;\" />\n:::\n\n<hr style=\"height:1pt; visibility:hidden;\" />\n\n### Building the Cutadapt command\n\nFirst, here is how we can tell Cutadapt about the primer sequences:\n\n- With the `-a` and `-A` option we specify the primer sequences in the forward and\n  reverse reads, respectively.\n- The forward reads should contain the forward primer at the beginning of the read.\n  Because reads are sometimes longer than the amplicon length,\n  the reverse primer may be present at the end of the read, but as its reverse complement.\n  We specify this using `-a \"$primer_f\"...\"$primer_r_rc\"`.\n- Similarly, the reverse reads should contain the reverse primer at the beginning of the read,\n  and may contain the reverse complement of the forward primer at the end of the read,\n  which we specify using `-A \"$primer_r\"...\"$primer_f_rc\"`.\n\nAll in all, our primer specification looks like this:\n\n```bash\n# (Don't run this - this will be part of our script)\ncutadapt \\\n    -a \"$primer_f\"...\"$primer_r_rc\" \\\n    -A \"$primer_r\"...\"$primer_f_rc\"\n```\n\n::: callout-note\n#### Spreading commands across multiple lines with `\\`\nAbove, I spread the command across multiple lines,\nwhich makes it a little easier to read.\nYou can run the command exactly like that: the backslashes (**`\\`**) at the end of all except\nthe last line tell the shell that our command will continue on the next line.\n:::\n\nWe will also:\n\n- Tell Cutadapt to only keep sequences that contain the primer^[\n  This is not the default: Cutadapt is even more commonly used to remove adapters,\n  and then this doesn't apply],\n  with the `--trimmed-only` option.\n- Instruct Cutadapt to use 8 \"cores\" with `--cores 8`, which can speed up the run by up to 8-fold.\n  For our small FASTQ files, this isn't really necessary, but for a larger dataset,\n  that can save quite some time.\n\n```bash\n# (Don't run this - this will be part of our script)\ncutadapt \\\n    -a \"$primer_f\"...\"$primer_r_rc\" \\\n    -A \"$primer_r\"...\"$primer_f_rc\" \\\n    --trimmed-only \\\n    --cores 8\n```\n\nFinally, let's also add the output files (`--output` for R1 and `--paired-output` for R2)\nand the input files (as positional arguments at the end of the command)\nfor a single example sample.\nWith that, we have a final example command of running Cutadapt for a single sample:\n\n```bash\n# (Don't run this - this will be part of our script)\ncutadapt \\\n    -a \"$primer_f\"...\"$primer_r_rc\" \\\n    -A \"$primer_r\"...\"$primer_f_rc\" \\\n    --trimmed-only \\\n    --cores 8 \\\n    --output results/cutadapt/NW102AB_R1.fastq.gz \\\n    --paired-output results/cutadapt/NW102AB_R2.fastq.gz \\\n    data/fastq/NW102AB_R1.fastq.gz \\\n    data/fastq/NW102AB_R2.fastq.gz\n```\n\n<hr style=\"height:1pt; visibility:hidden;\" />\n\n### Our Cutadapt loop\n\nIn our script, we will run Cutadapt inside a loop, similar to how we ran FastQC.\nHowever, this case is a bit more complicated, because we need to run Cutadapt\nfor one **sample** and therefore two FASTQ files at a time,\nrather than for one FASTQ file at a time.\n\nWe will do that by **looping over the R1 (forward read) files only**,\nand inside the loop, inferring the name of the R2 file:\n\n```bash\n# (Don't run this - this will be part of our script)\n\n# Loop over the R1 files\nfor R1_in in data/fastq/*R1.fastq.gz; do\n    # Get the R2 file name with \"parameter expansion\"\n    # This does a search-and-replace: replace \"_R1\" with \"_R2\"\n    R2_in=${R1_in/_R1/_R2}\n    \n    # Report\n    echo \"Input files: $R1_in $R2_in\"\n    \n    # Define the output files\n    R1_out=\"$outdir\"/$(basename \"$R1_in\")\n    R2_out=\"$outdir\"/$(basename \"$R2_in\")\n    \n    # Run Cutadapt\n    cutadapt \\\n        -a \"$primer_f\"...\"$primer_r_rc\" \\\n        -A \"$primer_r\"...\"$primer_f_rc\" \\\n        --trimmed-only \\\n        --cores 8 \\\n        --output \"$R1_out\" \\\n        --paired-output \"$R2_out\" \\\n        \"$R1_in\" \"$R2_in\"\ndone\n```\n\n<hr style=\"height:1pt; visibility:hidden;\" />\n\n### The final script\n\n{{< fa user-edit >}} Open a new text file and save it as `scripts/cutadapt.sh`.\nThen paste the following code into the script:\n\n```bash\n#!/bin/bash\n\n#SBATCH --account=PAS2714\n#SBATCH --output=slurm-cutadapt.out\n#SBATCH --cpus-per-task=8\n\n# Strict bash settings\nset -euo pipefail\n\n# Load the software\nmodule load miniconda3\nsource activate /fs/ess/PAS0471/jelmer/conda/mbar24\n\n# Primer sequences\nprimer_f=GTGTGYCAGCMGCCGCGGTAA\nprimer_r=GGACTACNVGGGTWTCTAAT\n\n# Get the reverse-complements of the primers\nprimer_f_rc=$(echo \"$primer_f\" | tr ATCGYRKMBDHV TAGCRYMKVHDB | rev)\nprimer_r_rc=$(echo \"$primer_r\" | tr ATCGYRKMBDHV TAGCRYMKVHDB | rev)\n\n# Create the output dir\noutdir=results/cutadapt\nmkdir -p \"$outdir\"\n\n# Loop over the R1 files\nfor R1_in in data/fastq/*R1.fastq.gz; do\n    # Get the R2 file name\n    R2_in=${R1_in/_R1/_R2}\n    \n    # Report\n    echo \"Input files: $R1_in $R2_in\"\n    \n    # Define the output files\n    R1_out=\"$outdir\"/$(basename \"$R1_in\")\n    R2_out=\"$outdir\"/$(basename \"$R2_in\")\n    \n    # Run Cutadapt\n    cutadapt \\\n            -a \"$primer_f\"...\"$primer_r_rc\" \\\n            -A \"$primer_r\"...\"$primer_f_rc\" \\\n            --trimmed-only \\\n            --cores 8 \\\n            --output \"$R1_out\" \\\n            --paired-output \"$R2_out\" \\\n            \"$R1_in\" \"$R2_in\"\ndone\n\n# Report\necho \"Done with script cutadapt.sh\"\ndate\n```\n\nNow we **submit the script** as a batch job in the same way we did with the FastQC script:\n\n```bash\nsbatch scripts/cutadapt.sh\n```\n```bash-out\nSubmitted batch job 27047247\n```\n\n<hr style=\"height:1pt; visibility:hidden;\" />\n\n### Check the output\n\nOnce we see the \"_Done with script_\" line when we use `tail` on the Slurm log file,\nwe know the job has finished:\n\n```bash\ntail slurm-cutadapt.out\n```\n```bash-out\n22      4       0.0     2       0 3 1\n24      1       0.0     2       0 1\n25      1       0.0     2       0 0 1\n34      1       0.0     2       0 0 1\n38      2       0.0     2       0 2\n42      1       0.0     2       0 0 1\n44      1       0.0     2       0 1\n47      1       0.0     2       0 1\nDone with script cutadapt.sh\nWed Mar  6 14:46:56 EST 2024\n```\n\nLet's use `less` to take a closer look at the logging output:\n\n```bash\nless slurm-cutadapt.out\n```\n```bash-out\nInput files: data/fastq/NW102AB_R1.fastq.gz data/fastq/NW102AB_R2.fastq.gz\nThis is cutadapt 4.6 with Python 3.10.13\nCommand line parameters: -a GTGTGYCAGCMGCCGCGGTAA...ATTAGAWACCCBNGTAGTCC -A GGACTACNVGGGTWTCTAAT...TTACCGCGGCKGCTGRCACAC --trimmed-only --cores 8 --output results/cutadapt/NW102AB_R1.fastq.gz --paired-output results/cutadapt/NW102AB_R2.fast\nq.gz data/fastq/NW102AB_R1.fastq.gz data/fastq/NW102AB_R2.fastq.gz\nProcessing paired-end reads on 8 cores ...\nFinished in 0.875 s (68.148 µs/read; 0.88 M reads/minute).\n\n=== Summary ===\n\nTotal read pairs processed:             12,844\n  Read 1 with adapter:                  12,798 (99.6%)\n  Read 2 with adapter:                  12,541 (97.6%)\n\n== Read fate breakdown ==\nPairs discarded as untrimmed:              337 (2.6%)\nPairs written (passing filters):        12,507 (97.4%)\n# [...output truncated...]\n```\n\nWe can see that Cutadapt reports the numbers and percentages of reads that contained\nwhat it calls the \"adapter\": in our case, that's the primer.\nIn the example above, and that is typical, the percentages are in the upper 90s.\n\n::: callout-warning\n##### If you see much lower percentages here, then something is wrong, e.g. with the primer sequences you provided or the Cutadapt syntax you used.\n:::\n\nWe will use the `grep` command to print all lines that contain the information\non numbers and percentages of reads with the primer sequences:\n\n```bash\ngrep \"with adapter:\" slurm-cutadapt.out\n```\n```bash-out\n  Read 1 with adapter:                  12,798 (99.6%)\n  Read 2 with adapter:                  12,541 (97.6%)\n  Read 1 with adapter:                  14,499 (99.7%)\n  Read 2 with adapter:                  14,211 (97.7%)\n  Read 1 with adapter:                  12,174 (99.7%)\n  Read 2 with adapter:                  11,835 (97.0%)\n  Read 1 with adapter:                  15,054 (99.7%)\n  Read 2 with adapter:                  14,737 (97.6%)\n# [...output truncated...]\n```\n\n**You should always take a careful look at this output**,\nto check if there are no samples with much lower percentages:\nit looks like there are no such samples in this case, fortunately.\n\n::: {.callout-tip collapse=\"true\"}\n#### Want to quickly see the lowest % of reads with adapter? _(Click to expand)_\n\nUse this command to extract and sort the percentages:\n\n```bash\ngrep \"with adapter:\" slurm-cutadapt.out | cut -d\"(\" -f2 | sort -n | head\n```\n```bash-out\n97.0%)\n97.3%)\n97.5%)\n97.5%)\n97.5%)\n97.5%)\n97.6%)\n```\n:::\n\n::: {.callout-tip collapse=\"true\"}\n#### Need to identify the samples with a specific percentage? _(Click to expand)_\n\nUse this command to print the 7 lines preceding each match,\nso you can see the file names (samples) that correspond to each percentage of reads with primers ---\nin the box below, you'll have to scroll all the way to the right to see those file names.\n\n(An alternative way, of course, would just be to scroll through the entire output file,\nbut this is (even) more of a hassle, as Cutadapt has quite some output.)\n\n```bash\ngrep -B7 \"with adapter:\" results/cutadapt/logs/slurm-cutadapt.out\n```\n```bash-out\nCommand line parameters: -a GTGTGYCAGCMGCCGCGGTAA...ATTAGAWACCCBNGTAGTCC -A GGACTACNVGGGTWTCTAAT...TTACCGCGGCKGCTGRCACAC --trimmed-only --cores 8 --output results/cutadapt/NW102AB_R1.fastq.gz --paired-output results/cutadapt/NW102AB_R2.fastq.gz data/fastq/NW102AB_R1.fastq.gz data/fastq/NW102AB_R2.fastq.gz\nProcessing paired-end reads on 8 cores ...\nFinished in 0.875 s (68.148 µs/read; 0.88 M reads/minute).\n\n=== Summary ===\n\nTotal read pairs processed:             12,844\n  Read 1 with adapter:                  12,798 (99.6%)\n  Read 2 with adapter:                  12,541 (97.6%)\n--\nCommand line parameters: -a GTGTGYCAGCMGCCGCGGTAA...ATTAGAWACCCBNGTAGTCC -A GGACTACNVGGGTWTCTAAT...TTACCGCGGCKGCTGRCACAC --trimmed-only --cores 8 --output results/cutadapt/NW102C_R1.fastq.gz --paired-output results/cutadapt/NW102C_R2.fastq.gz data/fastq/NW102C_R1.fastq.gz data/fastq/NW102C_R2.fastq.gz\nProcessing paired-end reads on 8 cores ...\nFinished in 0.801 s (55.030 µs/read; 1.09 M reads/minute).\n\n=== Summary ===\n\nTotal read pairs processed:             14,549\n  Read 1 with adapter:                  14,499 (99.7%)\n  Read 2 with adapter:                  14,211 (97.7%)\n--\n# [...output truncated...]\n```\n:::\n\n<hr style=\"height:1pt; visibility:hidden;\" />\n\nFinally, let's check the output dir, which contains the trimmed FASTQ files\nwe'll use in the next step of the workflow:\n\n```bash\nls results/cutadapt\n```\n```bash-out\nNW102AB_R1.fastq.gz  NW103C_R1.fastq.gz   NW203A_R1.fastq.gz   NW304BC_R1.fastq.gz  NW403A_R1.fastq.gz   NW404BC_R1.fastq.gz  W103AB_R1.fastq.gz  W204BC_R1.fastq.gz  W303AB_R1.fastq.gz  W304C_R1.fastq.gz   W404A_R1.fastq.gz\nNW102AB_R2.fastq.gz  NW103C_R2.fastq.gz   NW203A_R2.fastq.gz   NW304BC_R2.fastq.gz  NW403A_R2.fastq.gz   NW404BC_R2.fastq.gz  W103AB_R2.fastq.gz  W204BC_R2.fastq.gz  W303AB_R2.fastq.gz  W304C_R2.fastq.gz   W404A_R2.fastq.gz\nNW102C_R1.fastq.gz   NW201AB_R1.fastq.gz  NW203BC_R1.fastq.gz  NW305AB_R1.fastq.gz  NW403BC_R1.fastq.gz  W101AB_R1.fastq.gz   W103C_R1.fastq.gz   W205A_R1.fastq.gz   W303C_R1.fastq.gz   W403AB_R1.fastq.gz  W404BC_R1.fastq.gz\nNW102C_R2.fastq.gz   NW201AB_R2.fastq.gz  NW203BC_R2.fastq.gz  NW305AB_R2.fastq.gz  NW403BC_R2.fastq.gz  W101AB_R2.fastq.gz   W103C_R2.fastq.gz   W205A_R2.fastq.gz   W303C_R2.fastq.gz   W403AB_R2.fastq.gz  W404BC_R2.fastq.gz\nNW103AB_R1.fastq.gz  NW201C_R1.fastq.gz   NW304A_R1.fastq.gz   NW305C_R1.fastq.gz   NW404A_R1.fastq.gz   W101C_R1.fastq.gz    W204A_R1.fastq.gz   W205BC_R1.fastq.gz  W304AB_R1.fastq.gz  W403C_R1.fastq.gz\nNW103AB_R2.fastq.gz  NW201C_R2.fastq.gz   NW304A_R2.fastq.gz   NW305C_R2.fastq.gz   NW404A_R2.fastq.gz   W101C_R2.fastq.gz    W204A_R2.fastq.gz   W205BC_R2.fastq.gz  W304AB_R2.fastq.gz  W403C_R2.fastq.gz\n```\n```bash\nls -lh results/cutadapt\n```\n```bash-out\n-rw-rw----+ 1 jelmer PAS0471 1.9M Mar  6 14:46 NW102AB_R1.fastq.gz\n-rw-rw----+ 1 jelmer PAS0471 2.4M Mar  6 14:46 NW102AB_R2.fastq.gz\n-rw-rw----+ 1 jelmer PAS0471 2.2M Mar  6 14:46 NW102C_R1.fastq.gz\n-rw-rw----+ 1 jelmer PAS0471 2.8M Mar  6 14:46 NW102C_R2.fastq.gz\n-rw-rw----+ 1 jelmer PAS0471 1.8M Mar  6 14:46 NW103AB_R1.fastq.gz\n-rw-rw----+ 1 jelmer PAS0471 2.4M Mar  6 14:46 NW103AB_R2.fastq.gz\n-rw-rw----+ 1 jelmer PAS0471 2.2M Mar  6 14:46 NW103C_R1.fastq.gz\n-rw-rw----+ 1 jelmer PAS0471 2.9M Mar  6 14:46 NW103C_R2.fastq.gz\n# [...output truncated...]\n```\n\n<br>\n\n## Bonus content\n\n### The FASTQ format\n\nFASTQ is a very common output format of high-throughput sequencing machines.\nLike most genomic data files, these are plain text files.\nEach sequence that is read by the sequencer (i.e., each \"read\") forms\n**one FASTQ entry represented by four lines**.\nThe lines contain, respectively:\n\n1.  A **header** that starts with `@` and e.g. uniquely identifies the read\n2.  The **sequence** itself\n3.  A **`+`** (plus sign)\n4.  One-character **quality scores** for each base in the sequence\n\n![One entry (read) in a FASTQ file covers 4 lines. <br>The header line is annotated, with some of the more useful components highlighted in red. <br>For viewing purposes, this read (at only 56 bp) is shorter than what is typical.](img/fastq_header.png){fig-align=\"center\" width=\"85%\"}\n\nThe \"Q\" in FASTQ stands for \"*quality*\", to contrast this format with FASTA,\na more basic and generic sequence data format that does not include base quality scores.\nFASTQ files have the extension `.fastq` or `.fq`,\nbut they are very commonly gzip-compressed, in which case their name ends in `.fastq.gz` or `.fq.gz`.\n\n::: {.callout-note collapse=\"true\"}\n#### FASTQ quality scores *(Click to expand)*\n\nThe quality scores we saw in the read above represent an **estimate of the error probability of the base call**.\nSpecifically, they correspond to a numeric \"Phred\" quality score (`Q`),\nwhich is a function of the estimated probability that a base call is erroneous (`P`):\n\n> **Q = -10 \\* log10(P)**\n\nFor some specific probabilities and their rough qualitative interpretations for Illumina data:\n\n| Phred quality score | Error probability | Rough interpretation | ASCII character |\n|------------------|------------------|------------------|------------------|\n| **10**              | 1 in 10           | terrible             | `+`             |\n| **20**              | 1 in 100          | bad                  | `5`             |\n| **30**              | 1 in 1,000        | good                 | `?`             |\n| **40**              | 1 in 10,000       | excellent            | `?`             |\n\nThis numeric quality score is represented in FASTQ files *not by the number itself*, but by a corresponding \"ASCII character\" (last column in the table). This allows for a single-character representation of each possible score — as a consequence, **each quality score character can conveniently correspond to (& line up with) a base character** in the read. (For your reference, [here is a complete lookup table](https://www.drive5.com/usearch/manual/quality_score.html) --- look at the top table, \"BASE=33\").\n:::\n\n<hr style=\"height:1pt; visibility:hidden;\" />\n\n### Viewing FASTQ files\n\nNext, we'll take a peak inside one of these FASTQ files.\n\nThe `head` command prints the first lines of a file.\nLet's use it try to and print 8 lines, which should show us two reads:\n\n``` bash\nhead -n 8 data/fastq/NW102AB_R1.fastq.gz\n```\n\n``` bash-out\n�\nԽے�8�E��_1f�\"�QD�J��D�fs{����Yk����d��*��\n|��x���l޴�j�N������?������ٔ�bUs�Ng�Ǭ���i;_��������������|<�v����3��������|���ۧ��3ĐHyƕ�bIΟD�%����Sr#~��7��ν��1y�Ai,4\nw\\]\"b�#Q����8��+[e�3d�4H���̒�l�9LVMX��U*�M����_?���\\[\"��7�s\\<_���:�$���N��v�}^����sw�|�n;<�<�oP����\ni��k��q�ְ(G�ϫ��L�^��=��<���K��j�_/�[ۭV�ns:��U��G�z�ݎ�j����&��~�F��٤ZN�'��r2z}�f\\#��:�9$�����H�݂�\"�@M����H�C�\n�0�pp���1�O��I�H�P됄�.Ȣe��Q�>���\n�'�;@D8���#��St�7k�g��|�A䉻���_���d�_c������a\\�|�_�mn�]�9N������l�٢ZN�c�9u�����n��n�`��\n\"gͺ�\n    ���H�?2@�FC�S$n���Ԓh�       nԙj��望��f      �?N@�CzUlT�&�h�Pt!�r|��9~)���e�A�77�h{��~��     ��\n# [...output truncated...]\n```\n\n<details><summary>Ouch! 😳 What went wrong here? *(Click for the solution)*</summary>\nWhat happened here is that we are directly seeing the contents of the *compressed* file,\nwhich is simply not human-readable.\n</details>\n\n<hr style=\"height:1pt; visibility:hidden;\" />\n\n::: callout-note\n#### No need to decompress\nTo get around the problem we just encountered with `head`,\nwe might be inclined to **uncompress** these files, which we could do with the **`gunzip` command**.\nHowever, uncompressed files take up several times as much disk storage space as compressed ones.\nFortunately, we don't need to decompress them:\n\n- Almost any bioinformatics tool will accept compressed FASTQ files.\n- We can still view these files in compressed form, as shown below.\n:::\n\nInstead, we'll use the `less` command,\nwhich will automatically display gzip-compressed files in human-readable form:\n\n``` bash\nless -S data/fastq/NW102AB_R1.fastq.gz\n```\n```bash-out\n@M02815:77:000000000-KPK85:1:2101:3678:10660 1:N:0:CCTAAGAC+TTCTAGCT\nCGAGCAATCCACTCGAGTGCCAGCAGCCGCAGTAATACGGAGGGTGCGAGCGTTGTCCGGAATCACTGGGCGTAAAGGGCGCGTAGGCGGCGCGGATAGTCGGCGGTGAAAGCCCGGAGCTCAACTCCGGGTCGGCCGTCGATACTTCCGGGCTTGAGCACTGTAGAGGCAGATGGAATTCCGGGTGTAGCGGTGGAATGCGTAGAGATCCGGAAGAACACCGGTGGCGAAGGCGGTCTGCTGGGCAGTTGCTGACGCTGATGCGCGACAGCGTGGGGAGCAAACAGGATTAGATACC\n+\nCCCCCGGGGGGGGGGGGGGFGGGGGGGGGG+CFGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGDGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGDGGGGGGGGGGGGGGGGGGGGGGGGGGGGGFGGGGGGGGGGGGGGGGEGGGGGGGGGGGGGGGGGGGGDGGGGGGGGGGGGGGFGGFGFFFFEBFFGFFFDGFGFGBFGFGFGFFFF6?FFFGBF?FBFFF\n@M02815:77:000000000-KPK85:1:2108:2535:14400 1:N:0:CCTAAGAC+TTCTAGCT\nCGAGCAATCCACTCGAGTGTCAGCCGCCGCGGTAATACAGAGGTCCCGAGCGTTGTTCGGATTCATTGGGCGTAAAGGGTGCGTAGGCGGCGGGGAAAGTCTGATGTGAAATCCTGGGGCTCAACCCTGGAACTGCATTGGATACTTCCTTGCTAGAGTACTGGAGAGGAAACTGGAATTTACGGTGTAGCAGTGAAATGCGTAGAGATCGTAAGGAAGACCAGTGGCGAAGGCGAGTTTCTGGACAGTTACTGACGCTGAGGCACGAAGGCCAGGGGAGCAAACGGGATTAGATACC\n+\nCCCCCCGFGFGGGC-FFFGFGFFGGDFFGGGGGECGEGGAEGGGGGGGFGGDGG7CFFGGDCCFGGFCF8FGGGGGGCEGDGGGGGCGGGGGGDEGGGGBFGGDFGGGDG<DFGGGGCEGGGD:FFGGGGFFGFGGFFFFGGGFGGCFGGFGGGGG9CGCGGGG7FGGC:FFGGGGGFGG<?FCGGGGGGGGGGG9CG<ACC?EG5CFGGGGF8CCCC:C@FGCFGGGGGC58=EEG8??77:9@:<3A>7AGFGGGGC?DFC?5<5>>BGGGFGGGGG>4?C42::3:DG=><<*)*\n```\n\n::: {.callout-tip collapse=\"true\"}\n#### `less -S` suppresses line-wrapping: lines in the file will not be \"wrapped\" across multiple lines\n:::\n\n::: exercise\n####  **Exercise**: Explore the file with `less`\n\n`less` doesn't print stuff to screen but instead opens it in a \"pager\".\nAfter running the command above, you should be viewing the file inside the `less` pager.\n\nYou can move around in the file in several ways: by scrolling with your mouse,\nwith up and down arrows, or, if you have them, <kbd>PgUp</kbd> and <kbd>PgDn</kbd> keys\n(also, <kbd>u</kbd> will move up half a page and <kbd>d</kbd> down half a page).\n\nNotice you won't get your shell prompt back until you **press** <kbd>q</kbd> to quit `less`.\n:::\n\n<br><br>\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}