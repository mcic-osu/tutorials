{
  "hash": "a168455b07763c62bd47ce112200f915",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"Using software at OSC\"\nauthor: Jelmer Poelstra\ndate: 2024-08-02\neditor_options: \n  chunk_output_type: console\nengine: knitr\n---\n\n\n\n----------------------------------------------------------------------------------------------------\n\n<br>\n\n### Overview {-}\n\nTo analyze omics data sets, especially in genomics and transcriptomics,\na typical workflow includes using a sequence of specialized bioinformatics\nsoftware/programs/tools (I will use these terms interchangeably).\n\nAt OSC, there are system-wide installations of a number of bioinformatics programs.\nWe do need to \"load\" such programs before we can use them^[\nAnd with Git we saw another kind of behavior, where the automatically available version is very old,\nbut we can load a more recent version.].\nWe will talk more about this process today.\n\nHowever, OSC's collection of bioinformatics programs is not comprehensive,\nand their versions are sometimes outdated.\nWe therefore need an additional way to use bioinformatics programs at OSC.\nTwo common ones are the **Conda** software management program, which we'll talk about today,\nand **containers**, which are discussed in the self-study material at the bottom of the page.\n\n<br>\n\n## Loading software at OSC with Lmod modules\n\nOSC administrators manage software with the \"Lmod\" system of software modules.\nFor us users, this means that even though a lot of software is installed,\n**most of it can only be used after we explicitly load it.**\nThat may seem like a drag, but on the upside,\nthis practice enables the use of different versions of the same software,\nand of mutually incompatible software on a single system.\n\nWe can load, unload, and search for available software modules using the\n**`module`** command and its sub-commands.\n\n### Checking whether a program is available\n\nThe OSC website has a\n[list of installed software](<https://www.osc.edu/resources/available_software/software_list>).\nYou can also search for available software in the shell\nusing two subtly different `module` commands:\n  \n- `module spider` lists all installed modules.\n- `module avail` lists modules that *can be directly loaded* given the current environment\n  (i.e., taking into account which other software has been loaded).\n\nSimply running `module spider` or `module avail` spits out complete lists\nof installed/available programs ---\nit is more useful to add a **search term** as an argument.\nBelow, we'll search for the Conda distribution \"miniconda\":\n\n```bash\nmodule spider miniconda\n```\n``` {.bash-out}\n-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n  miniconda3:\n-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n     Versions:\n        miniconda3/4.10.3-py37\n        miniconda3/4.12.0-py38\n        miniconda3/4.12.0-py39\n        miniconda3/23.3.1-py310\n\n-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n  For detailed information about a specific \"miniconda3\" module (including how to load the modules) use the module's full name.\n  For example:\n\n     $ module spider miniconda3/4.12.0-py39\n-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n```\n\n```bash\nmodule avail miniconda\n```\n```{.bash-out}\n------------------------------------------------------------------------------------------------------ /apps/lmodfiles/Core -------------------------------------------------------------------------------------------------------\n   miniconda3/4.10.3-py37 (D)    miniconda3/4.12.0-py38    miniconda3/4.12.0-py39    miniconda3/23.3.1-py310\n\n  Where:\n   D:  Default Module\n```\n\nAs stated at the bottom of the output below,\nthe `(D)` in the `module avail` output above marks the **default version** of the program:\nthis is the version of the program that will be loaded if we don't specify\na version ourselves (see examples below).\nThe `module spider` command does not provide this information.\n\n::: callout-tip\n#### Both of these search commands are case-insensitive, but `module load` (below) is not\n:::\n\n<hr style=\"height:1pt; visibility:hidden;\" />\n\n### Loading and unloading software\n\nAll other Lmod software functionality is also accessed using `module` commands.\nFor instance, to make a program available to you, use the `load` command:\n\n```bash\n# Load a module:\nmodule load miniconda3               # Load the default version\nmodule load miniconda3/23.3.1-py310  # Load a specific version\n```\n\n:::{.callout-tip collapse=\"true\"}\n## It can be good to specify the version even when you want the default _(Click to expand)_\n\nThis is especially true inside a shell script ---\nwhen using the `module load` command, specifying a version would:\n\n- Ensure that when you run the same script a year later,\n  the same version would be used (assuming it hasn't been removed) ---\n  otherwise, it's possible a newer version would has been installed in the meantime,\n  which might produce different results.\n- Make it easy to see which version you used,\n  which is something you typically want to know and report in your paper. \n:::\n\n::: {.callout-warning}\n#### Modules do not remain loaded across separate shell sessions \nModule loading does _not_ persist across shell sessions.\nWhenever you get a fresh shell session\n(including but not limited to after logging into OSC again),\nyou will have to reload any modules you want to use!\n:::\n\n<hr style=\"height:1pt; visibility:hidden;\" />\n\nTo check which modules are loaded, use `module list`.\nIts output also includes _automatically_ loaded modules ---\nfor example, after loading `miniconda3/23.3.1-py310`,\nit should list `miniconda3` as the 9^th^ entry^[\nThis may vary over time and also depends on whether you run this in the VS Code\nServer terminal --- some of the loaded modules are related to that.]:\n\n```bash\nmodule list\n```\n```{.bash-out}\nCurrently Loaded Modules:\n  1) xalt/latest               3) intel/19.0.5     5) modules/sp2020     7) git/2.18.0              9) miniconda3/23.3.1-py310\n  2) gcc-compatibility/8.4.0   4) mvapich2/2.3.3   6) project/ondemand   8) app_code_server/4.8.3\n```\n\nOccasionally, when you run into conflicting (mutually incompatible) modules,\nit can be useful to unload modules,\nwhich you can do with `module unload` or `module purge`:\n\n```bash\nmodule unload miniconda3    # Unload a specific module\nmodule purge                # Unload all modules\n```\n\n<hr style=\"height:1pt; visibility:hidden;\" />\n\n::: callout-note\n#### Always include the `module load` command in your shell script\n\nWhen you run a program that is loaded with Lmod in your shell script,\nalways include the `module load` command in the script,\nand it is best to do so way at the top of the script:\n\n```bash\n#!/bin/bash\nset -euo pipefail\n\n# Load software\nmodule load fastqc/0.11.8\n```\n:::\n\n<hr style=\"height:1pt; visibility:hidden;\" />\n\n::: {.exercise}\n#### {{< fa user-edit >}} Exercise: Load a BLAST module\n\nBLAST is a very widely used alignment tool,\noften used to identify sequences that are similar to a query sequence.\nThere is not just a web version on NCBI's website, but also a BLAST command-line tool.\n\n1. Use `module avail` to check if BLAST is installed at OSC, and if so, which versions.\n   (Note: you'll also see results for the related module `blast-database` --- ignore those.)\n   \n2. Load the default BLAST version by not specifying a version,\n   and then check which version was loaded and if that matches the `module avail` output.\n\n3. Load the _latest_ version of BLAST without unloading the earlier version first.\n   What output do you get?\n\n<details><summary>Click here for the solutions</summary> \n\n1. Check the BLAST modules:\n\n   ```bash\n   module avail BLAST\n   ```\n   ```bash-out\n   ---------------------------------------------------------------------------------- /apps/lmodfiles/Core -- --------------------------------------------------------------------------------\n      blast-database/2018-08 (D)    blast-database/2020-04    blast-database/2022-06    blast/2.8.0+         blast/2.11.0+\n      blast-database/2019-09        blast-database/2021-05    blast-database/2023-06    blast/2.10.0+ (D)    blast/2.13.0+\n   \n     Where:\n      D:  Default Module\n   ```\n\n2. Load the default version:\n\n   ```bash\n   module load BLAST\n   module list\n   ```\n   ```bash-out\n   Currently Loaded Modules:\n     1) xalt/latest               3) intel/19.0.5     5) modules/sp2020     7) git/2.18.0              9) miniconda3/23.3.1-py310\n     2) gcc-compatibility/8.4.0   4) mvapich2/2.3.3   6) project/ondemand   8) app_code_server/4.8.3  10) blast/2.10.0+\n   ```\n   \n   `blast/2.10.0+` was loaded,\n   which matches what `module avail` claimed with its `(D)` marker for the default version.\n\n3. Load the latest version:\n\n   ```bash\n   module load blast/2.13.0+\n   ```\n   ```{.bash-out}\n   The following have been reloaded with a version change:\n     1) blast/2.10.0+ => blast/2.13.0+\n   ```\n   \n   Lmod detected that you tried to load a different version of a software that was\n   already loaded, so it _changes_ the version and tells you about it.\n\n</details>\n:::\n\n::: exercise\n#### {{< fa user-edit >}} Bonus exercise: STAR and module availability\n\n1. Use `module spider` to check which versions of STAR,\n   an RNA-seq read alignment program, have been installed at OSC.\n   Compare this output with that of `module avail`.\n\n2. Try to load the most recent version of STAR that `module spider` listed\n   (this should fail).\n\n3. Follow the instructions in the error message to again try and load OSC's most\n   recent version of STAR.\n\n4. Search the internet to see what the most recent version of STAR is.\n\n<details><summary>Click here for the solutions</summary>\n\n1. Check the versions of STAR --- it looks like `2.7.9a` is installed but we can't\n   load it for some reason:\n\n   ```bash\n   module spider star\n   ```\n   ```bash-out\n   --------------------------------------------------------------------------------------------------------------------------------   ------------------------------------------------------\n     star:\n   --------------------------------------------------------------------------------------------------------------------------------   ------------------------------------------------------\n        Versions:\n           star/2.5.2a\n           star/2.7.9a\n   ```\n\n   ```bash\n   module avail star\n   ```\n   ```bash-out\n   ---------------------------------------------------------------------------------- /apps/lmodfiles/Core    ----------------------------------------------------------------------------------\n      star/2.5.2a\n   ```\n\n2. A first stubborn attempt to load the most recent one:\n\n   ```bash\n   module load star/2.7.9a\n   ```\n   ```bash-out\n   Lmod has detected the following error:  These module(s) exist but cannot be loaded as requested: \"star/2.7.9a\"\n      Try: \"module spider star/2.7.9a\" to see how to load the module(s).\n   ```\n\n3. Follow the instructions in the above error message to try and load it again:\n\n   ```bash\n   module spider star/2.7.9a\n   ```\n   ```bash-out\n   --------------------------------------------------------------------------------------------------------------------------------   ------------------------------------------------------\n     star: star/2.7.9a\n   --------------------------------------------------------------------------------------------------------------------------------   ------------------------------------------------------\n   \n       You will need to load all module(s) on any one of the lines below before the \"star/2.7.9a\" module is available to load.\n   \n         gnu/10.3.0\n   ```\n   \n   ```bash\n   module load gnu/10.3.0\n   ```\n   ```bash-out\n   Lmod is automatically replacing \"intel/19.0.5\" with \"gnu/10.3.0\".\n   \n   The following have been reloaded with a version change:\n     1) mvapich2/2.3.3 => mvapich2/2.3.6\n   ```\n   ```bash\n   module load star/2.7.9a\n   ```\n   \n   The last command prints no output, which is generally good news, and indeed,\n   it seems to have worked:\n   \n   ```bash\n   STAR --version\n   ```\n   ```bash-out\n   2.7.9a\n   ```\n\n4. Most recent version of STAR:\n\n   As of March 2024, it looks like that's version 2.7.11b  (<https://github.com/alexdobin/STAR>).\n</details>\n:::\n\n<br>\n\n## When software isn't installed at OSC\n\nIt's not uncommon that software you need for your project is not installed at OSC,\nor that you need a more recent version of the software than what is available.\nIn that case, the following two are generally your best options:\n\n- **Conda**, which creates software \"environments\" you can activate much like\n  we did with Lmod modules.\n- **Containers**, which are self-contained software environments that include\n  operating systems, akin to mini virtual machines.\n  Docker containers are most well-known, but OSC uses Apptainer\n  (formerly known as Singularity).\n  \nConda and containers are useful not only at OSC,\nwhere they bypass issues with dependencies and administrator privileges,\nbut more generally for **reproducible software environments**.\nThey also make it easy to access different versions of the same software,\nor use mutually incompatible software.\n\nIn this session, you will learn how to use Conda, and the self-study reading\nat the bottom of the page covers using containers.\n\n[^2]: When your personal computer asks you to \"authenticate\" while you are\n      installing something, you are authenticating yourself as a user with\n      administrator privileges. At OSC, you don't have such privileges.\n\n[^3]: Other software upon which the software that you are trying to install depends.\n\n<hr style=\"height:1pt; visibility:hidden;\" />\n\n::: {.callout-note}\n#### Other options to install software / get it installed\n\n- Send an **email to [OSC Help](mailto:oschelp@osc.edu)**.\n  They might be able to help you with your installation, or in case of commonly\n  used software, might be willing to perform a system-wide installation\n  (that is, making it available through Lmod / `module` commands).\n\n- **\"Manually\" install the software**, which in the best case involves\n  downloading a directly functioning binary (executable),\n  but more commonly requires you to \"compile\" (build) the program.\n  This is sometimes straightforward but can also become extremely tricky,\n  especially at OSC where you don't have \"administrator privileges\"[^2]\n  and will often have difficulties with \"dependencies\"[^3].\n:::\n\n<br>\n\n## Conda basics\n\nThe Conda software can create so-called **environments** in which you can install\none or more software packages.\n\nAs you'll learn below, as long as a program is available in one of the online Conda\nrepositories (and this is nearly always the case for open-source bioinformatics programs),\nthen installing it is quite straightforward, doesn't require admin privileges,\nand is done with a procedure that is nearly identical regardless of the program\nyou are installing.\n\nA Conda environment is \"just\" a directory that includes the executable (binary)\nfiles for the program(s) in question.\nI have a collection of Conda environments that anyone can use,\nand we can list these environments simply with `ls`:\n\n```bash\nls /fs/ess/PAS0471/jelmer/conda\n```\n```{.bash-out}\nabricate-1.0.1  clonalframeml        kraken2            picard                        salmon\nagat-0.9.1      codan-1.2            kraken-biom        pilon-1.24                    samtools\nalv             cogclassifier        krona              pkgs                          scoary\namrfinderplus   cutadapt             liftoff-1.6.3      plasmidfinder-2.1.6           seqkit\nantismash       deeploc              links-2.0.1        plink2                        seqtk\nariba-2.14.6    deeptmhmm            lissero            porechop                      shoot\nastral-5.7.8    deeptmhmm2           longstitch-1.0.3   prokka                        signalp-6.0\naswcli          diamond              mafft              pseudofinder                  sistr-1.1.1\nbactopia        dwgsim               maskrc-svg         purge_dups-1.2.6              smap\nbactopia3       eggnogmapper         mbar24             pycoqc-2.5.2                  smap_dev\nbactopia-dev    emboss               medaka-1.7.2       qiime2-2023.7                 smartdenovo-env\nbakta           entap-0.10.8         metaxa-2.2.3       qiime2-amplicon-2024.2        snippy-4.6.0\nbase            entrez-direct        methylpy           qualimap-env                  snpeff\nbbmap           evigene              minibusco          quast-5.0.2                   snp-sites-2.5.1\nbcftools        fastp                minimap2-2.24      quickmerge-env                soapdenovo-trans-1.0.4\nbedops          fastqc               mlst               racon-1.5.0                   sortmerna-env\nbedtools        fastq-dl             mlst_check         ragtag-2.1.0                  sourmash\nbioawk          fasttree-2.1.11      mobsuite           rascaf                        spades-3.15.5\nbioconvert      filtlong-env         multiqc            rcorrector-1.0.5              sra-tools\nbiopython       flye-2.9.1           mummer4            r-dartr                       star\nbit             fmlrc2-0.1.7         muscle             r-deseq                       subread-2.0.1\nblast           gcta                 nanolyse-1.2.1     recognizer-1.8.3              taxonkit\nbowtie1         geofetch             nanoplot           repeatmasker-4.1.2.p1         tgsgapcloser\nbowtie2         gffread-0.12.7       nanopolish-0.13.2  repeatmodeler-2.0.3           tracy-0.7.1\nbracken         gget                 ncbi-datasets      resfinder                     transabyss-2.0.1\nbraker2-env     gubbins              nextdenovo-env     resistomeanalyzer-2018.09.06  transdecoder-5.5.0\nbusco           hisat2               nextflow           rgi-5.2.1                     treetime\nbusco2          hmmer                nextflow-22.10     r-metabar                     trimgalore\nbusco3          interproscan-5.55    nf-core            rnaquast-2.2.1                trimmomatic-0.39\nbwa-0.7.17      iqtree               orna-2.0           roary-3.13                    trinity-2.13.2\ncabana          justorthologs-0.0.2  orthofinder        r-rnaseq                      unicycler\ncactus          kallisto-0.48.0      orthofisher        rsem-1.3.3                    virema\ncgmlst          kat-2.4.2            panaroo            rseqc-env                     virulencefinder\ncheckm-1.2.0    knsp-3.1             parsnp             r_tree                        wtdbg-2.5\nclinker         kofamscan            phylofisher        sabre-1.0\n```\n\nThis is organized similarly to the Lmod modules in that there's generally\n**one separate environment for one program**,\nand the environment is named after that program.\n\n(The naming of these environments is unfortunately not entirely consistent:\nmany environments include the version number of the program, but others do not.\nFor environments without version numbers, I try to have them contain the most\nrecent version of a software^[\n  It isn't feasible to keep separate environments around for many different\n  versions of a program, mostly because Conda environments contain a very\n  large number of files, and OSC has file number quotas.\n  This is why I have in many cases chosen the strategy of just updating\n  the version within the same environment.\n].)\n\n<hr style=\"height:1pt; visibility:hidden;\" />\n\n### Activating Conda environments\n\nBefore you can activate Conda environments, you always need to load OSC's\nMiniconda module first, and we will load the most recent one:\n      \n```bash\nmodule load miniconda3/23.3.1-py310\n```\n\nAs mentioned above, these environments are (de)activated much like with the Lmod system.\nBut while the term \"load\" is used for Lmod modules,\nthe term **\"activate\"** is used for Conda environments --- it means the same thing.\n\nAlso like Lmod, there is a main command (`conda`) and several sub-commands\n(`deactivate`, `create`, `install`, `update`). For example, to activate an environment:\n\n```bash\nconda activate /fs/ess/PAS0471/jelmer/conda/multiqc\n```\n```{.bash-out}\n(/fs/ess/PAS0471/jelmer/conda/multiqc) [jelmer@p0085 jelmer]$\n```\n\n:::{.callout-tip}\n##### Conda environment indicator!\nWhen you have an active Conda environment, its name is displayed in front of your prompt,\nas depicted above with `(multiqc)`.\n\nBecause the MultiQC environment you just loaded is not your own,\nthe full path to the environment is shown (making the prompt rather long...).\nBut when you load your own environment, only the name will be shown, like so:\n\n```bash-out-solo\n(multiqc) [jelmer@p0085 jelmer]$\n```\n:::\n\nAfter you have activated the _MultiQC_ environment, you should be able to use the program.\nTo test this, simply run the `multiqc` command with the `--help` option:\n\n```bash\nmultiqc --help\n```\n```bash-out\n /// MultiQC üîç | v1.17\n                                                                                              \n Usage: multiqc [OPTIONS] [ANALYSIS DIRECTORY]\n \n MultiQC aggregates results from bioinformatics analyses across many samples into a    \n single report.                                                                        \n[...output truncated...]\n```\n\n<hr style=\"height:1pt; visibility:hidden;\" />\n\nUnlike Lmod / `module load`, Conda will by default only keep **a single environment active**.\nTherefore, when you have one environment activate and then activate another.\nFor example, after activating the TrimGalore environment,\nthe MultiQC environment is no longer active:\n  \n```bash\nconda activate /fs/ess/PAS0471/jelmer/conda/trimgalore\n  \nmultiqc --help\n```\n```{.bash-out}\nbash: multiqc: command not found...\n```\n\n<hr style=\"height:1pt; visibility:hidden;\" />\n\n::: {.callout-note collapse=\"true\"}\n#### The `--stack` option does enable you having multiple Conda environments active _(Click to expand)_\n\n1. Activate the TrimGalore environment, if it isn't already active:\n\n   ```bash\n   conda activate /fs/ess/PAS0471/jelmer/conda/trimgalore\n   ```\n\n2. \"Stack\" the MultiQC environment:\n\n   ```bash\n   conda activate --stack /fs/ess/PAS0471/jelmer/conda/multiqc\n   ```\n\n3. Check that you can use both programs --- output not shown,\n   but both should successfully print help info:\n\n   ```bash\n   multiqc --help\n  \n   trim_galore --help\n   ```\n:::\n\n<hr style=\"height:1pt; visibility:hidden;\" />\n\n### Lines to add to your shell script\n\nLike for Lmod modules, you'll have to load Conda environments in every shell session\nthat you want to use them --- they don't automatically reload.\n\nConda environments loaded in your interactive shell environment _do_ \"carry over\"\nto the environment in which your script runs\n(even when you submit them to the Slurm queue with `sbatch`).\nHowever, it is good practice to always\n_include the necessary code to load/activate programs in your shell scripts:_\n\n```bash\n#!/bin/bash\nset -euo pipefail\n\n# Load software\nmodule load miniconda3/23.3.1-py310\nconda activate /fs/ess/PAS0471/jelmer/conda/multiqc\n```\n\n<hr style=\"height:1pt; visibility:hidden;\" />\n\n::: {.callout-warning}\n#### Perils of Conda environments inside scripts\nProblems can occur when you have a Conda environment active in your interactive\nshell while you submit a script as a batch job that activates a different environment.\nTherefore, it is generally a good idea **not to have any Conda environments active**\n**in your interactive shell when submitting batch jobs**^[\nUnless you first deactivate any active environments in your script.].\nTo deactivate the currently active Conda environment,\nsimply type `conda deactivate` without any arguments:\n\n```bash\nconda deactivate   \n```\n:::\n\n<br>\n\n## Creating your own Conda environments\n\n### One-time Conda configuration\n\nBefore you can create our own environments, you first have to do some one-time configuration[^6].\nThe configuration will set the **Conda \"channels\"** (basically, software repositories)\nthat we want to use when we install programs, including the relative priorities among channels\n(since one program may be available from multiple channels).\n\n[^6]: That is, these settings will be saved somewhere in your OSC home directory,\n      and you never have to set them again unless you need to make changes.\n\nWe can do this configuration with the `config` sub-command ---\nrun the following in your shell:\n\n```bash\nconda config --add channels defaults     # Added first => lowest priority\nconda config --add channels bioconda\nconda config --add channels conda-forge  # Added last => highest priority\n```\n\nLet's check whether the configuration was successfully saved:\n\n```bash\nconda config --get channels\n```\n``` {.bash-out}\n--add channels 'defaults'   # lowest priority\n--add channels 'bioconda'\n--add channels 'conda-forge'   # highest priority\n```\n\n<hr style=\"height:1pt; visibility:hidden;\" />\n\n### Example: Creating an environment for TrimGalore\n\nWe will now create a Conda environment with the program TrimGalore installed,\nwhich does not have a system-wide installation at OSC.\nHere is the command to all at once create a new Conda environment\nand install TrimGalore into that environment:\n\n```bash\n# [Don't run this - we'll modify this a bit below]\nconda create -y -n trim-galore -c bioconda trim-galore\n```\n\nLet's break that command down:\n\n- **`create`** is the Conda sub-command to create a new environment.\n- When adding **`-y`**, Conda will not ask us for confirmation to install.\n- Following the **`-n`** option, you can specify the _name_ you would like the\n  environment to have: we used `trim-galore`.\n  You can use whatever name you like for the environment,\n  but a descriptive yet concise name is a good idea.\n  For single-program environments, it makes sense to simply name it after the program.\n- The **`-c`** option is to specify a \"channel\" (repository) from which to install,\n  here `bioconda`^[\n  Given that you've done some config above, this is not always necessary,\n  but it can be good to be explicit.].\n- The **`trim-galore`** argument at the end of the line simply tells Conda to install the\n  package of that name.\n\n<hr style=\"height:1pt; visibility:hidden;\" />\n\nBy default, Conda will install the **latest available version** of a program.\nIf you create an entirely new environment for a program, like we're doing here,\nthat default should always apply ---\nbut if you're installing into an environment that already contains programs,\nit's _possible_ that due to compatibility issues, it will install a different version. \n\nIf you want to be explicit about the version you want to install,\nadd the version number after **`=`** following the package name,\nand you may then also want to include that version number in the Conda environment's name ---\ntry this:\n\n```bash\nconda create -y -n trim-galore-0.6.10 -c bioconda trim-galore=0.6.10\n```\n```{.bash-out}\nCollecting package metadata (current_repodata.json): done  \nSolving environment: done\n# [...truncated...]\n```\n\nThere should be a lot of output, with many packages that are being downloaded\n(these are all \"dependencies\" of TrimGalore), but if it works, you should see\nthis before you get your prompt back:\n\n```bash-out-solo\nDownloading and Extracting Packages\n\nPreparing transaction: done\nVerifying transaction: done\nExecuting transaction: done                                                                                                                   \n#                        \n# To activate this environment, use                          \n#\n#     $ conda activate trim-galore-0.6.10                          \n#\n# To deactivate an active environment, use\n#\n#     $ conda deactivate\n```\n\nNow, you should be able to activate the environment (using just its name -- see the box below):\n\n```bash\nconda activate trim-galore-0.6.10  \n```\n\nLet's test if we can run TrimGalore --- note, the command is `trim_galore`: \n\n```bash\ntrim_galore --help\n```\n```{.bash-out}\n USAGE:\n\ntrim_galore [options] <filename(s)>\n\n-h/--help               Print this help message and exits.\n# [...truncated...]\n```\n\n<hr style=\"height:1pt; visibility:hidden;\" />\n\n:::{.callout-note collapse=\"true\"}\n#### Specifying the full path to the environment dir _(Click to expand)_\n\nYou may have noticed above that we merely gave the environment a _name_\n(`trim-galore` or `trim-galore-0.6.10`),\nand did not tell it _where_ to put this environment.\nSimilarly, we were able to activate the environment with just its name.\nConda assigns a **personal default directory for its environments**,\nsomewhere in your Home directory.\n  \nYou can install environments in a different location with the `-p` (instead of `-n`)\noption --- for example:\n  \n```bash\n# [Don't run this]\nconda create -y -p /fs/scratch/PAS2700/$USER/conda/trim-galore -c bioconda trim-galore\n```\n  \nAnd when you want to load someone else's Conda environments,\nyou'll always have to specify the full path to environment's dir,\nlike you did when loading one of my Conda environments above.\n:::\n\n<hr style=\"height:1pt; visibility:hidden;\" />\n\n### Finding Conda installation info online\n\nMinor variations on the `conda create` command above can be used to install\nalmost any program for which a Conda package is available,\nwhich is the vast majority of open-source bioinformatics programs!\n\nHowever, you may wonder how you would know:\n\n- Whether the program is available and what the name of its Conda package is\n- Which Conda channel we should use\n- Which versions are available\n\nTo find this out, my strategy is to simply Google the program name together with\n\"conda\", e.g. \"cutadapt conda\" if I wanted to install the Cutadapt program.\nLet's see that in action:\n\n![](img/conda_google.png){fig-align=\"center\" width=\"85%\"}\n\nClick on that first link (in my experience, it is always the first Google hit):\n\n![](img/conda_website.png){fig-align=\"center\" width=\"85%\"}\n\n<hr style=\"height:1pt; visibility:hidden;\" />\n\n### Building the installation command from the online info\n\nYou can take the top of the two example installation commands as a template,\nhere: `conda install -c bioconda cutadapt`.\nYou may notice the `install` subcommand, which we haven't yet seen.\nThis would install Cutadapt into _the currently activated Conda environment_.\nSince our strategy here is to create a separate environment for each program,\njust installing a program into whatever environment is currently active is not a great idea.\n\nYou _can_ use the `install` command with a new environment,\nbut then you would first have to create an \"empty\" environment,\nand _then_ run the install command.\nHowever, we saw above that we can do all of this in a single command.\nTo build this create-plus-install command, all we need to do is replace `install`\nin the example command on the Conda website by `create -y -n <env-name>`.\nThen, our full command (without version specification) will be:\n\n```bash\n# [Don't run this - example command]\nconda create -y -n cutadapt -c bioconda cutadapt\n```\n\nTo see which **version** of the software will be installed by default,\nand to see which older versions are available:\n\n![](img/conda_website_version.png){fig-align=\"center\" width=\"70%\"}\n\nFor almost any other program,\nyou can use the exact same procedure to find the Conda package and install it!\n\n::: {.callout-note collapse=\"true\"}\n#### More Conda commands to manage your environments _(Click to expand)_\n\n- Remove an environment entirely:\n\n  ```bash\n  conda env remove -n cutadapt\n  ```\n\n- List all your conda environments:\n\n  ```bash\n  conda env list\n  ```\n\n- List all packages (programs) installed in an environment &mdash;\n  due to dependencies, this can be a long list,\n  even if you only actively installed one program:\n\n  ```bash\n  conda list -p /fs/ess/PAS0471/jelmer/conda/multiqc\n  ```\n  \n- Export a plain-text \"YAML\" file that contains the instructions to recreate\n  your currently-active environment (useful for reproducibility!)  \n\n  ```bash\n  conda env export > my_env.yml\n  ```\n\n  And you can use the following to create a Conda environment from such a YAML file:\n\n  ```bash\n  conda env create -n my_env --force --file my_env.yml\n  ```\n:::\n\n<hr style=\"height:1pt; visibility:hidden;\" />\n\n### Organizing your Conda environments\n\nThere are two reasonable alternative way to organize your Conda environments:\n\n- **Have one environment per program** (my preference)\n  - Easier to keep an overview of what you have installed\n  - No need to reinstall the same program across different projects\n  - Less risk of running into problems with your environment due to mutually\n    incompatible software and complicated dependency situations\n\n- **Have one environment per research project**\n  - You just need to activate that one environment when you're working on\n    your project.\n  - Easier when you need to share your entire project with someone else\n    (or yourself) on a different (super)computer.\n\nEven though it might seem easier, a third alternative,\nto simply install all programs across all projects in one single environment,\nis _not_ recommended. This doesn't benefit reproducibility,\nand your environment is likely to stop functioning properly sooner or later.\n\n<br>\n\n## Self-study: Using Apptainer containers\n\n**Containers** are an alternative to Conda to use programs that don't have\nsystem-wide installations at OSC.\n\nContainers are similar to Virtual Machines and different from Conda environments\nin that they come with an entire _operating system_.\nThis makes creating your own container \"image\" (see box below on terminology)\nmuch more involved than creating a  Conda environment, and we will not cover that here.\n\nHowever, pre-existing container images are available for most bioinformatics programs,\nand these can be easily found, downloaded, and used.\n\n::: {.callout-note}\n#### Container terminology\n\n- **Container image**: File (Apptainer) or files (Docker) that contain the container application.\n- **Container** (sensu stricto): A _running_ container image.\n- **Definition file** (Apptainer) / **Dockerfile** (Docker):\n  A plain text file that contains the recipe to build a container image.\n:::\n\nAmong container platforms, Apptainer (formerly known as _Singularity_)\nand especially Docker are the most widely used ones.\nAt supercomputers like OSC, however, only Apptainer containers can be used.\nLuckily, the Apptainer program can work with Docker container images:\nit will convert them on the fly. \n\n<hr style=\"height:1pt; visibility:hidden;\" />\n\n### Finding container images online\n\nThere are several online repositories with publicly available container images,\nbut I would recommend BioContainers (<https://biocontainers.pro/registry>)\nor Quay.io (<https://quay.io/biocontainers>).\n\nFor example, let's look on the BioContainers website for a TrimGalore container image:\n\n![](img/biocontainers_search.png){fig-align=\"center\" width=\"85%\" style=\"border:1px solid gray;\"}\n\n::: legend2\nThe search result on the BioContainers website after entering \"trim galore\" in the search box.\n:::\n\n<hr style=\"height:1pt; visibility:hidden;\" />\n\nClick on the only entry that is shown, `trim-galore`, which will get you to a page like this:\n\n![](img/biocontainers_match.png){fig-align=\"center\" width=\"85%\" style=\"border:1px solid gray;\"}\n\nThe website also includes Conda installation instructions ---\nto see the container results, scroll down to:\n\n![](img/biocontainers_download.png){fig-align=\"center\" width=\"85%\" style=\"border:1px solid gray;\"}\n\n::: legend2\nAfter scrolling down on the results page, you should see a recent available container image.  \nNote that the command shown is `singularity run`,\nbut we will use the more up-to-date `apptainer run`.\n:::\n\n<hr style=\"height:1pt; visibility:hidden;\" />\n\nThe version tag that is shown (`0.6.9--hdfd78af_0` above) pertains to the version of TrimGalore,\nbut the result that is shown here is not will always the container image(s) with\nthe most recent version. To see a list of all available images,\nclick on the `Packages and Containers` tab towards the top, and then sort by `Last Update`:\n\n![The logo with the large S depicts Singularity/Apptainer containers.](img/biocontainers_versions.png){fig-align=\"center\" width=\"95S%\"}\n\nWhenever you find both a Singularity/Apptainer and a Docker image for your program,\n**use the Singularity/Apptainer image**.\nThis is because those don't have to be converted, while Docker images do.\nBut when the version you want is only available as a Docker image, that will work too:\nas mentioned above, it will be automatically converted to the proper format.\n\n<hr style=\"height:1pt; visibility:hidden;\" />\n\n### Running a container image\n\nWhen you've found a container image that you want to use, copy its URL from the BioContainers website.\nFor example, for the most recent TrimGalore version as of March 2024:\n`https://depot.galaxyproject.org/singularity/trim-galore:0.6.10--hdfd78af_0`.\n\nYou could also copy the full command ---\nhowever, we will modify that in two ways, using:\n\n- The more up-to-date `apptainer` command[^8]\n- The `exec` subcommand instead of `run`,\n  allowing us to enter a custom command to run in the container^[\n  The `run` subcommand would only run some preset default action,\n  which is rarely useful for our purposes.]. \n\n[^8]: Though note that as of March 2024, the `singularity` command does still work,\n      and it will probably continue to work for a while.\n\nAs such, our \"base\" command to run TrimGalore in the container will be as follows:\n\n```bash\n# [Don't run this, we'll need to add a TrimGalore command]\napptainer exec https://depot.galaxyproject.org/singularity/trim-galore:0.6.10--hdfd78af_0\n```\n\n::: {.callout-warning collapse=\"true\"}\n#### Need to use a Docker container? You can't use the Docker URL as-is. _(Click to expand)_\nIf you want to use a Docker container, the listed quasi-URL on BioContainers will\nstart with \"quay.io\". In your `apptainer exec` command,\nyou need to preface this URL with `docker://`. For instance: \n\n```bash\napptainer exec docker://quay.io/biocontainers/trim-galore:0.6.10--hdfd78af_0\n```\n:::\n\nAfter the code above, we would finish our command by simply entering\na TrimGalore command in the exact same way as we would when running TrimGalore\noutside of the context of a container.\nFor example, to just print the help info like we've been doing before,\nthe TrimGalore command is:\n\n```bash\ntrim_galore --help\n```\n\nAnd to run that inside the container, our full command will be:\n\n```bash\napptainer exec https://depot.galaxyproject.org/singularity/trim-galore:0.6.10--hdfd78af_0 \\\n    trim_galore --help\n```\n```{.bash-out}\nINFO:    Downloading network image\n321.4MiB / 321.4MiB [===================================================================================================================================] 100 % 3.0 MiB/s 0s\nWARNING: Environment variable LD_PRELOAD already has value [], will not forward new value [/apps/xalt/xalt/lib64/libxalt_init.so] from parent process environment\n\n USAGE:\n\ntrim_galore [options] <filename(s)>\n\n-h/--help               Print this help message and exits.\n# [...truncated...]\n```\n\n::: {.callout-tip}\n#### The Apptainer/Singularity software does not need to be loaded at OSC, it is always automatically loaded.\n:::\n\nSo, all that is different from running a program inside a container instead of a\na locally installed program,\nis that you **prefix your command with `apptainer exec <URL>`.**\n\nThe first time you run this command, the container will be downloaded,\nwhich can take a few minutes\n(by default it will be downloaded to `~/.apptainer/cache`,\nbut you can change this by setting the `$APPTAINER_CACHEDIR` environment variable).\nAfter that, the downloaded image will be used and the command should be executed\nabout as instantaneously as when running `TrimGalore` outside of a container.\n\n_(You will keep seeing the warning  `WARNING: Environment variable LD_PRELOAD [...]`_\n_whenever you run a container, but this is nothing to worry about.)_\n\n::: {.callout-note}\n#### When to use a Container versus Conda\nWhen you need multiple programs in quick succession or in a single command\n(e.g., you're piping the output of one program into a second program),\nit can be more convenient to have those programs installed in a single environment or container.\nPre-built multi-program containers are not as easy to find.\nAnd since building your own Conda environment is easier than building your own\ncontainer, this is a situation where you might prefer Conda.\n:::\n\n<br>\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}