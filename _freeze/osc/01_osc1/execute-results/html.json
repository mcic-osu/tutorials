{
  "hash": "4899a73b4a29e35cf23981e8e1e1dc2e",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"Intro to the Ohio Supercomputer Center (OSC)\"\npagetitle: \"OSC Intro\"\nauthor: Jelmer Poelstra\ndate: 2024-08-27\nexecute: \n  eval: false\nknitr:\n  opts_chunk:\n    out.width: \"85%\"\n    class-output: bash-out\neditor_options: \n  chunk_output_type: console\n---\n\n\n\n\n------------------------------------------------------------------------\n\n<hr style=\"height:1pt; visibility:hidden;\" />\n\n![](img/osc_logo.png){fig-align=\"center\" width=\"70%\"}\n\n<br>\n\n## Goals for this session\n\nThis session will provide an introduction to high-performance computing in general\nand to the Ohio Supercomputer Center (OSC). \n\n<hr style=\"height:1pt; visibility:hidden;\" />\n\n## High-performance computing\n\nA **supercomputer** (also known as a \"compute cluster\" or simply a \"**cluster**\")\nconsists of many computers that are connected by a high-speed network,\nand that can be accessed remotely by its users.\nIn more general terms, supercomputers provide high-performance computing (**HPC**) resources.\n\nThis is what Owens, one of the OSC supercomputers, physically looks like:\n\n![](img/owens.jpg){fig-align=\"center\" width=\"50%\"}\n\nHere are some possible reasons to use a supercomputer instead of your own laptop or desktop:\n\n-   Your analyses take a long time to run, need large numbers of CPUs, or a large amount of memory.\n-   You need to run some analyses many times.\n-   You need to store a lot of data.\n-   Your analyses require specialized hardware, such as GPUs (Graphical Processing Units).\n-   Your analyses require software available only for the Linux operating system, but you use Windows.\n\nWhen you're working with omics data, many of these reasons typically apply.\nThis can make it hard or sometimes simply impossible to do all your work on your personal workstation,\nand supercomputers provide a solution.\n\n<hr style=\"height:1pt; visibility:hidden;\" />\n\n#### The Ohio Supercomputer Center (OSC)\n\nThe Ohio Supercomputer Center (OSC) is a facility provided by the state of Ohio in the US. It has two supercomputers, lots of storage space, and an excellent infrastructure for accessing these resources.\n\n<hr style=\"height:1pt; visibility:hidden;\" />\n\n::: {.callout-note}\n#### OSC websites and \"Projects\"\n\nOSC has **three main websites** --- we will mostly or only use the first:\n\n-   **<https://ondemand.osc.edu>**: A web portal to use OSC resources through your browser (*login needed*).\n-   <https://my.osc.edu>: Account and project management (*login needed*).\n-   <https://osc.edu>: General website with information about the supercomputers, installed software, and usage.\n\n----\n\nAccess to OSC's computing power and storage space goes through **OSC \"Projects\"**:\n\n-   A project can be tied to a research project or lab, or be educational like this material's project, `PAS2700`.\n-   Each project has a budget in terms of \"compute hours\" and storage space^[\n    But we don't have to pay anything for educational projects like this one.\n    Otherwise, for OSC's rates for academic research, see [this page](https://www.osc.edu/content/academic_fee_model_faq).].\n-   As a user, it's possible to be a member of multiple different projects.\n\n:::\n\n<hr style=\"height:1pt; visibility:hidden;\" />\n\n## The structure of a supercomputer center\n\n### Terminology\n\nLet's start with some (super)computing terminology, going from smaller things to bigger things:\n\n-   **Node**\\\n    A single computer that is a part of a supercomputer.\n-   **Supercomputer / Cluster**\\\n    A collection of computers connected by a high-speed network. OSC has two: \"Pitzer\" and \"Owens\".\n-   **Supercomputer Center**\\\n    A facility like OSC that has one or more supercomputers.\n\n### Supercomputer components\n\nWe can think of a supercomputer as having three main parts:\n\n-   **File Systems**: Where files are stored (these are shared between the two OSC supercomputers!)\n-   **Login Nodes**: The handful of computers everyone shares after logging in\n-   **Compute Nodes**: The many computers you can reserve to run your analyses\n\n![](img/cluster_overview_ed.png){fig-align=\"center\" width=\"85%\"}\n\n<hr style=\"height:1pt; visibility:hidden;\" />\n\n#### File systems\n\nOSC has several distinct file systems:\n\n| File system | Located within | Quota              | Backed up? | Auto-purged?  | One for each... |\n|----------|------------|--------------|------------|------------|------------|\n| **Home**        | `/users/`         | 500 GB / 1 M files | Yes        | No            | User            |\n| **Project**     | `/fs/ess/`   | Flexible           | Yes        | No            | OSC Project     |\n| **Scratch**     | `/fs/scratch/`    | 100 TB             | No         | After 90 days | OSC Project     |\n\nWith this material,\nwe will be working in the project directory of OSC Project `PAS2700`: `/fs/ess/PAS2700`.\n\n::: callout-tip\n#### Directory is just another word for folder, often written as \"dir\" for short\n:::\n\n<hr style=\"height:1pt; visibility:hidden;\" />\n\n#### Login Nodes\n\nLogin nodes are set aside as an initial landing spot for everyone who logs in to a supercomputer. There are only a handful of them on each supercomputer, they are shared among everyone, and cannot be \"reserved\".\n\nAs such, login nodes are meant only to do things like organizing your files and creating scripts for compute jobs, and are ***not*** **meant for any serious computing**, which should be done on the compute nodes.\n\n<hr style=\"height:1pt; visibility:hidden;\" />\n\n#### Compute Nodes\n\nData processing and analysis is done on compute nodes.\nYou can only use compute nodes after putting in a **request** for resources (a \"job\").\nThe Slurm *job scheduler*, which you can learn about in [this tutorial](osc/05_slurm.qmd),\nwill then assign resources to your request.\n\n::: {.callout-note}\n#### Compute node types\n\nCompute nodes come in different shapes and sizes.\nStandard, default nodes work fine for the vast majority of analyses,\neven with large-scale omics data.\nBut you will sometimes need non-standard nodes,\nsuch as when you need a lot of RAM memory or need GPUs^[GPUs are e.g. used for Nanopore basecalling].\n:::\n\n::: {.callout-caution collapse=\"true\"}\n## At-home reading: What works differently on a supercomputer like at OSC? _(Click to expand)_\n\nCompared to command-line computing on a laptop or desktop,\na number of aspects are different when working on a supercomputer like at OSC.\nYou'll learn much more about these later on, but here is an overview: \n\n-   **\"Non-interactive\" computing is common**\\\n    It is common to write and \"submit\" scripts to a queue instead of running programs interactively.\n-   **Software**\\\n    You generally can't install \"the regular way\", and a lot of installed software needs to be \"loaded\".\n-   **Operating system**\\\n    Supercomputers run on the Linux operating system.\n-   **Login versus compute nodes**\\\n    As mentioned, the nodes you end up on after logging in are not meant for heavy computing\n    and you have to *request access to \"compute nodes\"* to run most analyses.    \n:::\n\n<hr style=\"height:1pt; visibility:hidden;\" />\n\n## OSC OnDemand\n\nThe OSC OnDemand web portal allows you to use a web browser to access OSC resources such as:\n\n-   A **file browser** where you can also create and rename folders and files, etc.\n-   A **Unix shell**\n-   \"**Interactive Apps**\": programs such as RStudio, Jupyter, VS Code and QGIS.\n\n{{< fa user-edit >}} **Go to <https://ondemand.osc.edu> and log in** (use the boxes on the left-hand side)\n\nYou should see a landing page similar to the one below:\n\n<p align=\"center\">\n\n<img src=\"img/ondemand_home.png\" width=\"90%\"/>\n\n</p>\n\nWe will now go through some of the dropdown menus in the **blue bar along the top**.\n\n<hr style=\"height:1pt; visibility:hidden;\" />\n\n### Files: File system access\n\nHovering over the **Files** dropdown menu gives a list of directories that you have access to.\nIf your account is brand new, and you were added to `PAS2700`, you should only have three directories listed:\n\n1.  A **Home** directory (starts with `/users/`)\n2.  The `PAS2700` project's \"**scratch**\" directory (`/fs/scratch/PAS2700`) \n3.  The `PAS2700` project's \"**project**\" directory (`/fs/ess/PAS2700`)\n\nYou will only ever have one Home directory at OSC,\nbut for every additional project you are a member of,\nyou should usually see additional `/fs/ess` and `/fs/scratch` directories appear.\n\n{{< fa user-edit >}} **Click on our focal directory `/fs/ess/PAS2700`**.\n\n![](img/ondemand_files_selectproject.png){fig-align=\"center\" width=\"40%\"}\n\nOnce there, you should see whichever directories and files are present at the selected location,\nand you can click on the directories to explore the contents further:\n\n![](img/ondemand_files_pas2700.png){fig-align=\"center\" width=\"95%\"}\n\nThis interface is **much like the file browser on your own computer**, so you can also create, delete, move and copy files and folders, and even upload (from your computer to OSC) and download (from OSC your computer) files^[Though this is not meant for large (\\>1 GB) transfers. Different methods are available --- we'll talk about those later on.] --- see the buttons across the top.\n\n<hr style=\"height:1pt; visibility:hidden;\" />\n\n### Interactive Apps\n\nWe can access programs with Graphical User Interfaces (**GUI**s; point-and-click interfaces)\nvia the **Interactive Apps** dropdown menu:\n\n![](img/ondemand_vscode_select.png){fig-align=\"center\" width=\"32%\"}\n\nIn the next tutorial,\nwe will start using the VS Code text editor, which is listed here as `Code Server`.\n\n<hr style=\"height:1pt; visibility:hidden;\" />\n\n### Clusters: Unix shell access\n\n::: {.callout-note collapse=\"true\"}\n#### System Status within Clusters _(Click to expand)_\n\nIn the \"**Clusters**\" dropdown menu, click on the item at the bottom, \"**System Status**\":\n\n![](img/ondemand_systemstatus_select.png){fig-align=\"center\" width=\"50%\"}\n\nThis page shows an overview of the live, current usage of the two clusters ---\nthat can be interesting to get a good idea of the scale of the supercomputer center,\nwhich cluster is being used more,\nwhat the size of the \"queue\" (which has jobs waiting to start) is, and so on.\n\n![](img/ondemand_systemstatus.png){fig-align=\"center\" width=\"90%\"}\n:::\n\nInteracting with a supercomputer is most commonly done using a Unix shell.\nUnder the **Clusters** dropdown menu, you can access a Unix shell either on Owens or Pitzer:\n\n![](img/ondemand_shell_select.png){fig-align=\"center\" width=\"50%\"}\n\nI'm selecting a shell on the Pitzer supercomputer (\"Pitzer Shell Access\"),\nwhich will open a new browser tab, where the bottom of the page looks like this:\n\n![](img/ondemand_shell2.png){fig-align=\"center\" width=\"95%\"}\n\nWe'll return to this Unix shell in the next session.\n\n<br><br>\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}