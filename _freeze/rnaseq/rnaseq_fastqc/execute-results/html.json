{
  "hash": "ca437f88bf4f95596e9cad28667f7885",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"Read QC with _FastQC_\"\nsubtitle: \"And the distinction between program-specific scripts and an overarching runner/master script\"\npagetitle: \"FastQC\"\nhighlight-style: github\nnumber-sections: true\nengine: knitr\nauthor: Jelmer Poelstra\ndate: 2023-09-22\n---\n\n::: {.cell}\n\n:::\n\n\n\n\n::: {.callout-important}\n## Under construction \nThis page is still under construction.\n:::\n\n-------\n\n<br>\n\n## Overview & setting up {-}\n\nSo far,\nwe have covered all the building blocks to be able to run command-line programs\nat OSC:\n\n- Basics of a supercomputer and of **OSC** specifically\n- Unix (Bash) **shell** basics to work at a supercomputer,\n  and learn the language used in our scripts\n- The bells and whistles needed to turn our commands into a **shell script**\n- Loading and the **software** (command-line programs) that we want to run\n- Working with the **Slurm** job scheduler, so we can submit scripts as batch jobs\n- The ability to **loop** over commands, so that we can submit many scripts at once\n\nWith these skills,\nit's relatively straightforward to create and submit scripts that run command-line\nprograms to analyze our genomics data.\nIn this session, we'll apply them to run **_FastQC_**.\n\n::: {.callout-note}\n#### VS Code improvements\n\nThese two settings will make life easier when writing shell scripts in VS Code.\n\n**First, we'll add a keyboard shortcut to send code from your editor to the terminal.**\nThis is the same type of behavior that you may be familiar with from RStudio,\nand will prevent you from having to copy-and-paste code into the terminal:\n\n- Click the <i class=\"fa fa-cog\"></i> (bottom-left) => `Keyboard Shortcuts`.\n\n- Find `Terminal: Run Selected Text in Active Terminal`, click on it,\n  then add a shortcut, e.g. <kbd>Ctrl</kbd>+<kbd>Enter</kbd>.\n  (Don't worry about the warning that other bindings exist for this shortcut.)\n\nIn VS Code's editor pane,\nthe entire line that your cursor is on is always selected by default.\nAs such, your keyboard shortcut will by default send the line that your cursor\nis in to the terminal;\nyou can also send multiple lines to the terminal after selecting them.\n\n**Second, we'll add the _ShellCheck_ VS Code extension**.\nThis extension will check your shell scripts for errors like referencing variables\nthat have not been assigned, and not using variables that _have_ been assigned.\nPotential problems will show up as colored squiggly lines below the words or lines\nin question.\nYou can also click on the links that will appear when you hover over a problematic\npiece of code, and find information about how to fix this mistake and improve\nyour code. All in all, this extension is incredibly useful!\n\n- Click on the Extensions icon in the far left (narrow) sidebar in VS Code.\n\n- Type \"shellcheck\" and click the small purple \"Install\" button next to the entry\n  of this name (the description should include \"Timon Wong\", who is the author).\n\n:::\n\n#### _FastQC_: A program for quality control of FASTQ files {-}\n\n_FastQC_ is one the most ubiquitous pieces of genomics software.\nIt allows you to assess the overall quality of, and potential problems with,\nthe reads in your FASTQ files.\nIt produces visualizations and assessments of for statistics such as\nper-base quality (below) and adapter content.\nRunning FastQC or an equivalent program should always be the first analysis step\nafter you receive your sequences.  \n\nFor each FASTQ file, FastQC outputs an **HTML file** that you can open in your\nbrowser and which has about a dozen graphs showing different QC metrics.\nThe most important one is the **per-base quality score graph** shown below.\n\n::: {#fig-elephants layout-ncol=2 layout-nrow=1}\n\n![](img/fastqc_good.png)\n\n![](img/fastqc_bad.png)\n\nA FastQC per-base quality score graph for files with fairly good (left) and\nvery poor (right) quality reads.\nThe y-axis shows Phred quality scores\n(higher is better, see also the color-coding of the graph)\nand the x-axis shows the position along the read.\n:::\n\n#### Start VS Code and open your folder {-}\n\nAs always, we'll be working in VS Code &mdash;\nif you don't already have a session open, see below how to do so.\n\n**Make sure to open your `/fs/ess/PAS0471/<user>/rnaseq_intro` dir**,\neither by using the `Open Folder` menu item,\nor by clicking on this dir when it appears in the `Welcome` tab.\n\n:::{.callout-tip collapse=\"true\"}\n## Starting VS Code at OSC - with a Terminal (Click to expand)\n1. Log in to OSC's OnDemand portal at <https://ondemand.osc.edu>.\n\n2. In the blue top bar, select `Interactive Apps`\n   and then near the bottom of the dropdown menu, click `Code Server`.\n\n3. In the form that appears on a new page:\n   - Select an appropriate OSC project (here: `PAS0471`)\n   - For this session, select `/fs/ess/PAS0471` as the starting directory\n   - Make sure that `Number of hours` is at least `2`\n   - Click `Launch`.\n\n4. On the next page, once the top bar of the box has turned green\n   and says `Runnning`, click `Connect to VS Code`.\n\n<figure><p align=\"center\"><img src=img/osc-code-launch_ed.png width=\"80%\"></p></figure>\n\n5. Open a Terminal by clicking\n   &nbsp; {{< fa bars >}} &nbsp; => `Terminal` => `New Terminal`.\n   (Or use one of the keyboard shortcuts:\n   <kbd>Ctrl</kbd>+<kbd>\\`</kbd> (backtick) or\n   <kbd>Ctrl</kbd>+<kbd>Shift</kbd>+<kbd>C</kbd>.)\n\n6. In the `Welcome` tab under `Recent`,\n   you should see your `/fs/ess/PAS0471/<user>/rnaseq_intro` dir listed:\n   click on that to open it.\n   Alternatively, use\n   &nbsp; {{< fa bars >}} &nbsp; => &nbsp; `File` &nbsp; => &nbsp; `Open Folder`\n   to open that dir in VS Code.\n:::\n\n:::{.callout-warning collapse=\"true\"}\n#### Don't have your own dir with the data? (Click to expand)\nIf you missed the last session, or deleted your `rnaseq_intro` dir entirely,\nrun these commands to get a (fresh) copy of all files you should have so far:\n\n```bash\nmkdir -p /fs/ess/PAS0471/$USER/rnaseq_intro\ncp -r /fs/ess/PAS0471/demo/202307_rnaseq /fs/ess/PAS0471/$USER/rnaseq_intro\n```\n\nAnd if you do have an `rnaseq_intro` dir,\nbut you want to start over because you moved or removed some of the files\nwhile practicing, then delete the dir before your run the commands above:\n\n```bash\nrm -r /fs/ess/PAS0471/$USER/rnaseq_intro\n```\n\nYou should have at least the following files in this dir:\n\n```{.bash-out}\n/fs/ess/PAS0471/demo/202307_rnaseq\n├── data\n│   └── fastq\n│       ├── ASPC1_A178V_R1.fastq.gz\n│       ├── ASPC1_A178V_R2.fastq.gz\n│       ├── ASPC1_G31V_R1.fastq.gz\n│       ├── ASPC1_G31V_R2.fastq.gz\n│       ├── md5sums.txt\n│       ├── Miapaca2_A178V_R1.fastq.gz\n│       ├── Miapaca2_A178V_R2.fastq.gz\n│       ├── Miapaca2_G31V_R1.fastq.gz\n│       └── Miapaca2_G31V_R2.fastq.gz\n├── metadata\n│   └── meta.tsv\n└── README.md\n│   └── ref\n│       ├── GCF_000001405.40.fna\n│       ├── GCF_000001405.40.gtf\n```\n:::\n\n<br>\n\n## A script to run _FastQC_\n\n### FastQC syntax\n\nTo analyze one (optionally gzipped) FASTQ file with _FastQC_,\nthe syntax can be as simple as:\n  \n\n\n\n::: {.cell}\n\n```{.bash .cell-code}\nfastqc <fastq-file>\n```\n:::\n\n\n\n\nAbove, `<fastq-file>` should be replaced by the path to an actual FASTQ file.\nWe'll also always want to specify the output directory, though,\nbecause the unfortunate default for _FastQC_ is to put them in the directory\nthat contains the FASTQ files themselves[^1].\nWe can tell _FastQC_ about our desired output directory as follows:\n\n[^1]: And we'd like to separate our data from our results!\n\n\n\n\n::: {.cell}\n\n```{.bash .cell-code}\nfastqc --outdir <output-dir> <fastq-file>\n```\n:::\n\n\n\n\nFor instance, if we wanted output files to go to the directory `results/fastqc`\nand wanted the program to analyze the file `data/fastq/ASPC1_A178V_R1.fastq.gz`,\na functional command would be:\n\n\n\n\n::: {.cell}\n\n```{.bash .cell-code}\nfastqc --outdir results/fastqc data/fastq/ASPC1_A178V_R1.fastq.gz\n```\n:::\n\n\n\n\n:::{.callout-tip}\n## _FastQC_'s output file names are automatically determined\n_FastQC_ allows us to specify the output _directory_,\nbut not the output file names,\nwhich will be automatically determined based on the input file name.\n\nFor one FASTQ file, _FastQC_ will output one HTML file and one ZIP archive.\nThe latter contains files with the summary statistics that were computed and\non which the figures are based &mdash; we generally don't need to look at that.\n:::\n\n<br>\n\n### A basic script to run _FastQC_\n\nInstead of running _FastQC_ interactively,\nwe'll want to write a _FastQC_ script that we can submit as a batch job.\n\nSpecifically, our script will deliberately run _FastQC_ for **only one FASTQ file**.\nAlternative approaches would be to include multiple FASTQ files in our FastQC command\n(this _is_ possible), or even to loop over FASTQ files inside the FastQC script.\n_However_, given that we have access to OSC's compute cluster,\nit will be much more efficient to submit a separate batch job for each FASTQ file.\n\nThis approach means that our script needs to accept an argument with a file name\n(of the focal FASTQ file),\nsomething that we have practiced with quite a bit in the previous sessions.\nSo here is what a basic script along these lines could look like:\n  \n```bash\n#!/bin/bash\n\n# Strict Bash settings\nset -euo pipefail\n\n# Copy the placeholder variables\nfastq_file=$1\noutdir=$2\n\n# Run FastQC\nfastqc --outdir \"$outdir\" \"$fastq_file\"\n\n# (Don't run this in your terminal, this is an example script)\n```\n\n<br>\n\n### A more well-developed _FastQC_ script\n\nWe should add a few things to this script to e.g. make it run it smoothly as a\nbatch job at OSC:\n\n- A line to load the relevant OSC software module:\n\n\n\n\n  ::: {.cell}\n  \n  ```{.bash .cell-code}\n  module load fastqc/0.11.8\n  ```\n  :::\n\n\n\n  \n- A few `sbatch` options (we'll keep the time limit and number of cores at their\n  default values of 1 hour and 1 core, respectively):\n\n\n\n\n  ::: {.cell}\n  \n  ```{.bash .cell-code}\n  #SBATCH --account=PAS0471\n  #SBATCH --mail-type=FAIL\n  #SBATCH --output=slurm-fastqc-%j.out\n  ```\n  :::\n\n\n\n\n- Several `echo` statements to report what's going on\n\n- A line to create the output directory if it doesn't yet exist:\n\n  ```bash\n  mkdir -p \"$outdir\"\n  ```\n\n:::{.callout-tip collapse=\"true\"}\n## Refresher: the `-p` option to `mkdir` (Click to expand)\n\nUsing the `-p` option does two things at once for us,\nboth of which are necessary for a foolproof inclusion of this command\nin a script:\n\n- It will enable `mkdir` to create multiple levels of directories at once\n  (i.e., to act _recursively_):\n  by default, `mkdir` errors out if the parent directory/ies of the\n  specified directory don't yet exist.\n\n  ```bash\n  mkdir newdir1/newdir2\n  ```\n  ```{.bash-out}\n  mkdir: cannot create directory ‘newdir1/newdir2’: No such file or directory\n  ```\n\n  ```bash\n  mkdir -p newdir1/newdir2    # This successfully creates both directories\n  ```\n\n- If the directory already exists, it won't do anything and won't return an error\n  (by default, `mkdir` would return an error in this case,\n  which would in turn lead the script to abort at that point with our `set` settings):\n  \n  ```bash\n  mkdir newdir1/newdir2\n  ```\n  ```{.bash-out}\n  mkdir: cannot create directory ‘newdir1/newdir2’: File exists\n  ```\n\n  ```bash\n  mkdir -p newdir1/newdir2   # This does nothing since the dirs already exist\n  ```\n:::\n\nHere is what our script looks like with those additions:\n\n\n\n\n::: {.cell}\n\n```{.bash .cell-code}\n#!/bin/bash\n#SBATCH --account=PAS2250\n#SBATCH --mail-type=FAIL\n#SBATCH --output=slurm-fastqc-%j.out\n  \n# Strict Bash settings\nset -euo pipefail\n\n# Load the OSC module for FastQC\nmodule load fastqc\n\n# Copy the placeholder variables\nfastq_file=\"$1\"\noutdir=\"$2\" \n\n# Initial reporting\necho \"# Starting script fastqc.ch\"\ndate\necho \"# Input FASTQ file:   $fastq_file\"\necho \"# Output dir:         $outdir\"\necho\n\n# Create the output dir if needed\nmkdir -p \"$outdir\"\n\n# Run FastQC\nfastqc --outdir=\"$outdir\" \"$fastq_file\"\n\n# Final reporting\necho\necho \"# Listing the output files:\"\nls -lh \"$outdir\"\n\necho\necho \"# Done with script fastqc.sh\"\ndate\n\n# (Don't run this in your terminal, but copy it into a .sh text file)\n```\n:::\n\n\n\n\n{{< fa user-edit >}} Open a new file in VS Code\n(&nbsp; {{< fa bars >}} &nbsp; => &nbsp; `File` &nbsp; => &nbsp; `New File`)\nand save it as `fastqc.sh` within your `scripts/` directory.\nPaste in the code above and save the file.\n\nNotice that this script is very similar to our toy scripts from the previous\nsessions:\nmostly standard (\"boilerplate\") code with\n**just a single command to run our program of interest.**\nTherefore, you can adopt this script as a template for scripts that run other\ncommand-line programs, and will generally only need minor modifications!\n\n:::{.exercise}\n### On Your Own: Use multiple threads {-}\n\nMost bioinformatics programs, including _FastQC_,\ncan make use of multiple threads/CPUs/cores\n(which we can all treat as the same unit below the node level, for our purposes),\nand this can speed things up tremendously.\n\nTo run FastQC with multiple threads, we need to take two steps &mdash;\nbelow, `n` is the number of threads that we would like to use.\n\n- Add the `#SBATCH --cpus-per-task=n` option to the script.\n\n- Tell _FastQC_ that it can use `n` threads.\n\n**Include both of these options in your `fastqc.sh` script so as to run _FastQC_**\n**with 8 cores.**\n\n(To find out the name of the _FastQC_ option for the number of threads,\nrun `fastqc --help` and search for the relevant option.)\n\n<details><summary>Hint (click here)</summary>\n\nThe _FastQC_ option in question is `-t` (short form) or `--threads` (long form).\nFor clarity, I would suggest to use the long form option in your script.\n\n</details>\n\n<details><summary>Solution (click here)</summary>\n\n- You should add the following `#SBATCH` line at the top of the script:\n\n```bash\n#SBATCH --cpus-per-task=8\n```\n\n- Your _FastQC_ command in the script should now be as follows\n  (though the order of the `--threads` and `--outdir` options does not matter,\n  as long as the input file positional argument comes last):\n\n```bash\nfastqc --threads 8 --outdir \"$outdir\" \"$fastq_file\"\n```\n\n</details>\n\n:::\n\n<br>\n\n## A master / runner \"script\"\n\nAbove, we created a `fastqc.sh` script,\nwhich we'll eventually want to submit a bunch of times with a `for` loop.\nThe code with that loop and the `sbatch` command _could_ be directly typed in the terminal.\n**But it's better to save the commands used for job submission in a file/script as well.**\n\nWe will now create such a file,\nwhich has the overall purpose of documenting the steps we took\nand the batch jobs we submitted.\n_You can think of this file as your analysis lab notebook,_\n_or perhaps more accurately,_\n_your notebook entry that contains the final protocol you followed._\n\nThis kind of script is sometimes called a \"master\" or \"runner\" script.\nBecause it will contain shell code, we will save it as a shell script (`.sh`)\njust like the script to run `fastqc.sh` and other individual analysis steps.\n**However, it is important to realize that the runner script is conceptually different**\n**from the scripts that run individual steps of your analysis.**\nThe latter are meant to be run/submitted in their entirety by the runner script,\nwhereas a basic runner script that contains `sbatch` compute job commands for\nmultiple steps has to be run step-by-step (see the box below).\n\n::: {.callout-warning collapse=\"true\"}\n#### The runner script can't itself be run at once in its entirety (Click to expand)\nOnce we've added multiple batch job steps,\nand the input of a later step uses the output of an earlier step,\nwe won't be able to just _run_ the script as is.\n**This is because the runner script would then submit jobs from different steps**\n**all at once,**\n**and that later step would start running before the earlier step has finished.**\n\nFor example, consider the following series of two steps,\nin which the second step uses the output of the first step: \n\n```bash\n# This script would create a genome \"index\" for STAR, that will be used in the next step\n# ('my_genome.fa' = input genome FASTA, 'results/star_index' = output index dir)\nsbatch scripts/star_index.sh my_genome.fa results/star_index\n\n# This script would align a FASTQ file to the genome index created in the previous step\n# ('results/star_index' = input index dir, 'sampleA.fastq.gz' = input FASTQ file,\n# 'results/star_align' = output dir)\nsbatch scripts/star_align.sh results/star_index sampleA.fastq.gz results/star_align \n```\n\nIf these two lines were included in your runner script,\nand you would run that script in its entirety all at once,\nthe script in the second step would be submitted just a split-second after the\nfirst one\n(recall: when using `sbatch`, you get your prompt back immediately -- there is no waiting).\nAs such, it would fail because of the missing output from the first step.\n\nIt _is_ possible to make `sbatch` batch jobs wait for earlier steps to finish\n(e.g. with the `--dependency` option), but this quickly gets tricky.\nIf you want to create a workflow/pipeline that can run from start to finish in\nan automated way, \nyou should consider using a workflow management system\nlike [Snakemake](https://snakemake.readthedocs.io/en/stable/) or\n[NextFlow](https://www.nextflow.io/).\n\n:::\n\nTo summarize, we'll **separate our code into two hierarchical levels of scripts**,\nwhich we'll also save in separate dirs to make this division clear:\n\n- The scripts that run _individual steps of your analysis_, like `fastqc.sh`.\n  We'll save these in a directory called `scripts`.\n- An _overarching \"runner\" script_ that orchestrates the batch job submission\n  of these individual steps.\n  We'll save this script in a directory called `run`.\n\n{{< fa user-edit >}} Let's go ahead and open a new text file,\nand save it as `run/run.sh`\n(_VS Code_ should create that directory on the fly as needed).\n\n::: {.callout-tip}\n#### Keep the scripts for individual steps simple\nIt is a good idea to keep the shell scripts you will submit (e.g., `fastqc.sh`) simple\n_in the sense that they should generally just run one program_,\nand not a sequence of programs.\n\nOnce you get the hang of writing these scripts,\nit may seem appealing to string a series of programs/steps together in a single script,\nso that it's easier to rerun everything at once &mdash;\nbut in practice, that will often end up leading to more difficulties than convenience.\nOnce again, if you do want to develop a workflow that can run from start to finish,\nyou'll have to bite the bullet and learn a workflow management system like\nSnakemake or Nextflow.\n:::\n\n<br>\n\n## Running FastQC using batch jobs\n\n### Submitting the script for one FASTQ file\n\nLet's submit our `fastqc.sh` script to the Slurm queue with `sbatch`:\n\n```bash\nsbatch scripts/fastqc.sh data/fastq/ASPC1_A178V_R1.fastq.gz results/fastqc\n```\n```{.bash-out}\nSubmitted batch job 12521308\n```\n\n:::{.callout-note collapse=\"true\"}\n### Once again: Where does our output go? (Click to expand)\n\n- Output that would have been printed to screen if we had run the script directly,\n  such as our `echo` statements and _FastQC_'s progress logging,\n  will go into the Slurm log file `slurm-fastqc-<job-nr>.out` in our working dir.\n  \n- _FastQC_'s main output files (HTML and zip) will end up in the output directory\n  we specified, in this case `results/fastqc`.\n:::\n\n<br>\n\nIf we take a look at the queue,\nyou may catch the job while it's still pending\n(note below that the job's `NAME` will by default be the filename of the script):\n\n```{.bash-out}\nFri Aug 25 12:07:48 2023\n    JOBID PARTITION     NAME     USER    STATE       TIME TIME_LIMI  NODES NODELIST(REASON)\n  23666218 serial-40 fastqc.s   jelmer  PENDING       0:00   1:00:00      1 (None)\n```\n\n...and then it should start running:\n\n```{.bash-out}\nFri Aug 25 12:07:54 2023\n    JOBID PARTITION     NAME     USER    STATE       TIME TIME_LIMI  NODES NODELIST(REASON)\n  23666218 condo-osu fastqc.s   jelmer  RUNNING       0:06   1:00:00      1 p0133\n```\n\nThe job will be finished within 10 seconds, though\n(recall that we are working with small subsets of the full FASTQ files),\nand you might miss its listing in the `squeue` output entirely:\nas soon as it's done, it will be removed from the list.\n\n<br>\n\nOf course, just because a job has finished does not mean that it has ran\n_successfully_, and we should always check this.\nLet's start by taking a look at the Slurm log file:\n\n\n\n\n::: {.cell}\n\n```{.bash .cell-code}\ncat slurm-fastqc-23666218.out    # You'll have a different job number in the filename\n```\n:::\n\n\n\n\n:::{.callout-note collapse=\"true\"}\n## Click to see the contents of the Slurm log file\n\n```{.bash-out}\n# Starting script fastqc.ch\nFri Aug 25 12:07:50 EDT 2023\n# Input FASTQ file:   data/fastq/ASPC1_A178V_R1.fastq.gz\n# Output dir:         results/fastqc\n\nStarted analysis of ASPC1_A178V_R1.fastq.gz\nApprox 5% complete for ASPC1_A178V_R1.fastq.gz\nApprox 10% complete for ASPC1_A178V_R1.fastq.gz\nApprox 15% complete for ASPC1_A178V_R1.fastq.gz\nApprox 20% complete for ASPC1_A178V_R1.fastq.gz\nApprox 25% complete for ASPC1_A178V_R1.fastq.gz\nApprox 30% complete for ASPC1_A178V_R1.fastq.gz\nApprox 35% complete for ASPC1_A178V_R1.fastq.gz\nApprox 40% complete for ASPC1_A178V_R1.fastq.gz\nApprox 45% complete for ASPC1_A178V_R1.fastq.gz\nApprox 50% complete for ASPC1_A178V_R1.fastq.gz\nApprox 55% complete for ASPC1_A178V_R1.fastq.gz\nApprox 60% complete for ASPC1_A178V_R1.fastq.gz\nApprox 65% complete for ASPC1_A178V_R1.fastq.gz\nApprox 70% complete for ASPC1_A178V_R1.fastq.gz\nApprox 75% complete for ASPC1_A178V_R1.fastq.gz\nApprox 80% complete for ASPC1_A178V_R1.fastq.gz\nApprox 85% complete for ASPC1_A178V_R1.fastq.gz\nApprox 90% complete for ASPC1_A178V_R1.fastq.gz\nApprox 95% complete for ASPC1_A178V_R1.fastq.gz\nApprox 100% complete for ASPC1_A178V_R1.fastq.gz\nAnalysis complete for ASPC1_A178V_R1.fastq.gz\n\n# Listing the output files:\ntotal 5.1M\n-rw-r--r-- 1 jelmer PAS0471 266K Aug 25 12:07 ASPC1_A178V_R1_fastqc.html\n-rw-r--r-- 1 jelmer PAS0471 456K Aug 25 12:07 ASPC1_A178V_R1_fastqc.zip\n\n# Done with script fastqc.sh\nFri Aug 25 12:07:56 EDT 2023\n```\n:::\n\nThe Slurm log file shown in the box above looks good,\nwe can see that FastQC ran and finished and that there are  no errors.\nMake sure your log file looks similar.\n\nAt the end of the log file, our script listed _FastQC_'s output files\n(a ZIP file and an HTML file), so we could see their file names and sizes:\nanother useful check that everything went well.\n\n<br>\n\n### Submitting the script many times with a loop\n\nThe script that we wrote above will run FastQC for a single FASTQ file.\nNow, we will write a loop that iterates over all of our FASTQ files\n(only 8 files in our case, but this could be 100s of files just the same),\nand **submits a batch job for each of them.**\n\nIn our `run.sh` script, let's start by writing a loop that iterates over our\nFASTQ files and simply prints their names\n(note: the `-e` option to `echo` will allow us to insert an extra new line with `\\n`,\nresulting in an empty line):\n\n```bash\nfor fastq_file in data/fastq/*fastq.gz; do\n    echo -e \"\\nFASTQ file: $fastq_file\"\ndone\n```\n```{.bash-out}\n\nFASTQ file: data/fastq/ASPC1_A178V_R1.fastq.gz\n\nFASTQ file: data/fastq/ASPC1_A178V_R2.fastq.gz\n\nFASTQ file: data/fastq/ASPC1_G31V_R1.fastq.gz\n\nFASTQ file: data/fastq/ASPC1_G31V_R2.fastq.gz\n\nFASTQ file: data/fastq/Miapaca2_A178V_R1.fastq.gz\n\nFASTQ file: data/fastq/Miapaca2_A178V_R2.fastq.gz\n\nFASTQ file: data/fastq/Miapaca2_G31V_R1.fastq.gz\n\nFASTQ file: data/fastq/Miapaca2_G31V_R2.fastq.gz\n```\n\nNow that we've confirmed that we are succesfully looping over our files,\nlet's add the code to submit a batch job in every iteration:\n\n```bash\nfor fastq_file in data/fastq/*fastq.gz; do\n    echo -e \"\\nFASTQ file: $fastq_file\"\n    sbatch scripts/fastqc.sh \"$fastq_file\" results/fastqc\ndone\n```\n``` {.bash-out}\nFASTQ file: data/fastq/ASPC1_A178V_R1.fastq.gz\nSubmitted batch job 24048031\n\nFASTQ file: data/fastq/ASPC1_A178V_R2.fastq.gz\nSubmitted batch job 24048032\n\nFASTQ file: data/fastq/ASPC1_G31V_R1.fastq.gz\nSubmitted batch job 24048033\n\nFASTQ file: data/fastq/ASPC1_G31V_R2.fastq.gz\nSubmitted batch job 24048034\n\nFASTQ file: data/fastq/Miapaca2_A178V_R1.fastq.gz\nSubmitted batch job 24048035\n\nFASTQ file: data/fastq/Miapaca2_A178V_R2.fastq.gz\nSubmitted batch job 24048036\n\nFASTQ file: data/fastq/Miapaca2_G31V_R1.fastq.gz\nSubmitted batch job 24048037\n\nFASTQ file: data/fastq/Miapaca2_G31V_R2.fastq.gz\nSubmitted batch job 24048038\n```\n\n:::{.exercise}\n### On Your Own: Check if everything went well {-}\n\n- Use `squeue` to monitor your jobs.\n\n- Take a look at the Slurm log files while the jobs are running and/or after the\n  jobs are finished.\n  \n  A nice trick when you have many log files is to check the last few lines of\n  all of them using `tail` with a wildcard.\n  This is useful because recall that with our strict Bash settings,\n  a script should only run until the end if it did not encounter errors.\n  And `tail` will helpfully include file name markers when you run it on\n  multiple files as follows:\n  \n  ```bash\n  tail slurm-fastqc*\n  ```\n\n- Take a look at _FastQC_'s output files: are you seeing 8 HTML files?\n\n- Check your email to see that you didn't receive any emails from Slurm:\n  any emails would mean that the job(s) in question failed. \n\n:::\n\n<br>\n\n## Interpreting the FastQC output\n\n### Downloading the HTML files\n\nIn the older version of VS Code that's installed at OSC,\nwe unfortunately can't view HTML files.\nSo we'll have to _download_ FastQC's HTML output files to our own computers and\nthen take a look at them.\n\nFind the `results/fastqc` dir in VS Code's file Explorer on the left-hand side of the screen,\nright-click on it, and find and use the **\"Download...\"** entry towards the bottom\n(the screenshot just has a single file selected, but please select the dir instead):\n\n<p align=\"center\"><img src=img/vscode_download.png width=\"50%\"></p>\n\nOnce you've downloaded the files,\ngo to the folder you've downloaded them to in your computer's file explorer / Finder.\n\nWe will look at just two of the HTML files:\nthose for the R1 and R2 files of the first sample, `ASPC1_A178V`.\nIt would be a bit tedious to have to go through all HTML files,\nand this would especially be the case if we have dozens of files,\nwhich would be the case for most full datasets.\n_After looking at these two FastQC HTML files,_\n_we will use **MultiQC** to summarize all FastQC outputs into a single file_,\nand examine the MultiQC output to look for differences among samples.\n\nIn your file explorer,\ndouble-click on the first file (`ASPC1_A178V_R1_fastqc.html`) and it should open\ninside your browser.\n\n### Interpreting the results\n\nTBA -- for now,\nsee these [slides](https://biodash.github.io/tutorials/2021-01_rnaseq/03-fastqc-output.html).\n\n<br>\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}