{
  "hash": "15777df736971962656f949562809efd",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"Lab: Running the nf-core rnaseq pipeline\"\nauthor: Jelmer Poelstra\ndate: 2025-01-27\nknitr:\n  opts_chunk:\n    out.width: \"85%\"\n    class-output: styled-output\nproject:\n  execute-dir: project\neditor_options: \n  chunk_output_type: console\neditor: source\n---\n\n\n\n\n-------\n\n<br>\n\n## Introduction\n\nIn this tutorial,\nwe will run the **[nf-core rnaseq pipeline](https://nf-co.re/rnaseq)**.\nUsing raw RNA-seq reads in FASTQ files and reference genomes files as inputs,\nthis pipeline will generate a gene count table as its most important output.\nThat gene count table can then be analyzed to examine, for example, differential expression,\nwhich is the topic of the [self-study lab](lab2.qmd).\n\n![An overview of the steps in the [nf-core rnaseq](https://nf-co.re/rnaseq) pipeline.](img/nf-core-rnaseq.png){fig-align=\"center\" width=\"100%\"}\n\n<br>\n\nWe will work with the data set from the paper\n\"*Two avian Plasmodium species trigger different transcriptional responses on their vector Culex pipiens*\",\npublished last year in Molecular Ecology ([link](https://doi.org/10.1111/mec.17240)):\n\n![](img/paper.png){fig-align=\"center\" width=\"80%\"}\n\nThis paper uses RNA-seq data to study gene expression in *Culex pipiens* mosquitoes\ninfected with malaria-causing *Plasmodium* protozoans --- specifically, it compares mosquito according to:\n\n- Infection status: *Plasmodium cathemerium* vs. *P. relictum* vs. control\n- Time after infection: 24 h vs. 10 days vs. 21 days\n\n<br>\n\n## Getting started with VS Code\n\nWe will use the VS Code text editor to write a script to run the nf-core rnaseq pipeline.\nTo emphasize the additional functionality relative to basic text editors like Notepad and TextEdit,\neditors like VS Code are also referred to as \"**IDEs**\": *Integrated Development Environments*.\nThe RStudio program is another good example of an IDE.\nJust like RStudio is an IDE for R, VS Code will be our IDE for shell code today. \n\n### Starting VS Code at OSC\n\n- Log in to OSC's OnDemand portal at <https://ondemand.osc.edu>.\n\n- In the blue top bar, select `Interactive Apps` and near the bottom, click `Code Server`.\n\n- VS Code runs on a compute node so we have to fill out a form to make a reservation for one:\n  - The OSC \"_Project_\" that we want to bill for the compute node usage: `PAS2658`.\n  - The \"_Number of hours_\" we want to make a reservation for: `2`.\n  - The \"_Working Directory_\" for the program:  your personal folder in `/fs/scratch/PAS2658`\n    (e.g. `/fs/scratch/PAS2658/jelmer`).\n  - The \"_Codeserver Version_\": `4.8` (most recent).\n  - Click `Launch`.\n\n- First, your job will be \"*Queued*\" — that is,\n  waiting for the job scheduler to allocate compute node resources to it.\n\n- Your job is typically granted resources within a few seconds (the card will then say \"*Starting*\"),\n  and should be ready for usage (\"*Running*\") in another couple of seconds.\n  Once the job is running click on the blue **Connect to VS Code** button to open\n  VS Code --- it will open in a new browser tab.\n\n- When VS Code opens, you may get these two pop-ups (and possibly some others) ---\n  click \"Yes\" (and check the box) and \"Don't Show Again\", respectively:\n\n::: columns\n::: {.column width=\"52%\"}\n![](img/vscode-trust2.png){fig-align=\"center\" width=\"90%\"}\n:::\n\n::: {.column width=\"48%\"}\n![](img/vscode-git.png){fig-align=\"center\" width=\"90%\"}\n:::\n:::\n\n- You'll also get a Welcome/Get Started page ---\n  you don't have to go through steps that may be suggested there.\n\n<br>\n\n### The VS Code User Interface\n\n<details><summary>*Click to see an annotated screenshot*</summary>\n![](img/vscode-welcome_ed.png){fig-align=\"center\" width=\"80%\"}\n</details>\n\n#### Side bars\n\nThe _narrow side bar_ on the far left has:\n\n- A {{< fa bars >}} (\"hamburger menu\"), which has menu items like `File` that you often find in a top bar.\n- A {{< fa cog >}} (cog wheel icon) in the bottom, through which you can mainly access *settings*.\n- Icons to toggle between options for what to show in the _wide side bar_,\n  e.g. a File Explorer (the default option).\n\n<hr style=\"height:1pt; visibility:hidden;\" />\n\n#### Terminal\n\nOpen a terminal with a Unix shell: click   {{< fa bars >}}   =\\> `Terminal` =\\> `New Terminal`.\nIn the terminal, create a dir for this lab, e.g.:\n\n```sh\n# You should be in your personal dir in /fs/scratch/PAS2658\npwd\n```\n```bash-out\n/fs/scratch/PAS2658/jelmer\n```\n\n```bash\nmkdir -p Lab9 \ncd Lab9\nmkdir scripts run software\n```\n\n<hr style=\"height:1pt; visibility:hidden;\" />\n\n#### Editor pane and `Welcome` document\n\nThe main part of the VS Code window is the editor pane.\nHere, you can open text files and images.\nCreate two new files:\n\n```bash\ntouch run/run.sh scripts/nfc-rnaseq.sh\n```\n\nThen open the `run.sh` file in the editor --\nhold <kbd>Ctrl/Cmd</kbd> and click on the path in the command you just issued:\n\n![](img/vscode_click-open-file.png){fig-align=\"center\" width=\"45%\"}\n\n::: {.callout-note collapse=\"true\"}\n##### Or create and open files using the menus _(Click to expand)_\n1. **Open a new file:** Click the hamburger menu <i class=\"fa fa-bars\"></i>, then `File` > `New File`.\n2. **Save the file** (<kbd>Ctrl/⌘</kbd>+<kbd>S</kbd>),\n   inside one of the dirs you just created: `Lab9/run/run.sh`.\n3. Repeat steps 1 and 2 to create a file `Lab9/scripts/nfc-rnaseq.sh`.\n4. Find the `run.sh` file in the File Explorer in the left side bar, and click on it to open.\n:::\n\n::: {.callout-tip collapse=\"true\"}\n#### Some VS Code tips and tricks _(Click to expand)_\n\n- **A folder as a starting point**\\\n  Conveniently, VS Code takes a specific directory as a **starting point in all parts of the program**:\n  \n  -   In the file explorer in the side bar\n  -   In the terminal\n  -   When saving files in the editor pane.\n  \n  This is why your terminal was \"already\" located in `/fs/scratch/PAS2658/<your-name>`.\\\n  (If you need to switch folders, click   {{< fa bars >}}   >   `File`   >   `Open Folder`.)\n\n- **Resizing panes**\\\n  You can resize panes (terminal, editor, side bar) by hovering your cursor over the borders and then dragging.\n\n- **Hide the side bars**\\\n  If you want to save some screen space while coding along in class,\n  you may want to occasionally hide the side bars:\n\n  - In {{< fa bars >}} > `View` > `Appearance` you can toggle both the `Activity Bar`\n    (narrow side bar) and the `Primary Side Bar` (wide side bar).\n  - Or use keyboard shortcuts:\n    - <kbd>Ctrl/⌘</kbd>+<kbd>B</kbd> for the primary/wide side bar\n    - <kbd>Ctrl</kbd>+<kbd>Shift</kbd>+<kbd>B</kbd> for the activity/narrow side bar\n\n- **The Command Palette**\\\n  To access all the menu options that are available in VS Code,\n  the so-called \"Command Palette\" can be handy, especially if you know what you are looking for.\n  To access the Command Palette, click   <i class=\"fa fa-cog\"></i>   and then\n  `Command Palette` (or press <kbd>F1</kbd> or <kbd>Ctrl</kbd>/<kbd>⌘</kbd>+<kbd>Shift</kbd>+<kbd>P</kbd>).\n  To use it, start typing something to look for an option.\n    \n- **Keyboard shortcuts**\\\n  For a single-page PDF overview of keyboard shortcuts for your operating system:\n  {{< fa bars >}}   =\\>   `Help`   =\\>   `Keyboard Shortcut Reference`.\n  (Or for direct links to these PDFs:\n  [Windows](https://code.visualstudio.com/shortcuts/keyboard-shortcuts-windows.pdf) /\n  [Mac](https://code.visualstudio.com/shortcuts/keyboard-shortcuts-macos.pdf) /\n  [Linux](https://code.visualstudio.com/shortcuts/keyboard-shortcuts-linux.pdf).)\n  \n- **Install the Shellcheck extension**\\\n  Click the gear icon <i class=\"fa fa-cog\"></i> and then `Extensions`,\n  and search for and then install the **shellcheck** (by *simonwong*) extension,\n  which will check your shell scripts for errors, and is extremely useful.\n\n:::\n\n<br>\n\n## Setting up\n\n### Getting your own copy of the data\n\nAs mentioned above, we will use the RNA-seq data from Garrigos et al. 2023.\nHowever, to keep things manageable for a lab like this,\nI have **subset** the data set we'll be working with: I omitted the 21-day samples and\nonly kept 500,000 reads per FASTQ file. All in all, our set of files consists of:\n\n- 44 paired-end Illumina RNA-seq FASTQ files for 22 samples.\n- [_Culex pipiens_ reference genome](https://www.ncbi.nlm.nih.gov/datasets/genome/GCF_016801865.2/)\n  files from NCBI: assembly in FASTA format and annotation in GTF format.\n- A metadata file in TSV format matching sample IDs with treatment & time point info.\n- A README file describing the data set.\n\nGo ahead and get yourself a copy of the data with `cp` command:\n\n``` bash\n# (Using the -r option for recursive copying, and -v to print what it's doing)\ncp -rv /fs/scratch/PAS2658/jelmer/share/* .\n```\n```bash-out\n‘/fs/scratch/PAS2658/jelmer/share/data’ -> ‘./data’\n‘/fs/scratch/PAS2658/jelmer/share/data/meta’ -> ‘./data/meta’\n‘/fs/scratch/PAS2658/jelmer/share/data/meta/metadata.tsv’ -> ‘./data/meta/metadata.tsv’\n‘/fs/scratch/PAS2658/jelmer/share/data/ref’ -> ‘./data/ref’\n‘/fs/scratch/PAS2658/jelmer/share/data/ref/GCF_016801865.2.gtf’ -> ‘./data/ref/GCF_016801865.2.gtf’\n‘/fs/scratch/PAS2658/jelmer/share/data/ref/GCF_016801865.2.fna’ -> ‘./data/ref/GCF_016801865.2.fna’\n‘/fs/scratch/PAS2658/jelmer/share/data/fastq’ -> ‘./data/fastq’\n‘/fs/scratch/PAS2658/jelmer/share/data/fastq/ERR10802868_R2.fastq.gz’ -> ‘./data/fastq/ERR10802868_R2.fastq.gz’\n‘/fs/scratch/PAS2658/jelmer/share/data/fastq/ERR10802863_R1.fastq.gz’ -> ‘./data/fastq/ERR10802863_R1.fastq.gz’\n‘/fs/scratch/PAS2658/jelmer/share/data/fastq/ERR10802886_R2.fastq.gz’ -> ‘./data/fastq/ERR10802886_R2.fastq.gz’\n# [...output truncated...]\n```\n\nUse the `tree` command to get a nice overview of the files you copied:\n\n```bash\n# '-C' will add colors to the output (not visible in the output below)\ntree -C data\n```\n```bash-out\ndata\n├── fastq\n│   ├── ERR10802863_R1.fastq.gz\n│   ├── ERR10802863_R2.fastq.gz\n│   ├── ERR10802864_R1.fastq.gz\n│   ├── ERR10802864_R2.fastq.gz\n│   ├── ERR10802865_R1.fastq.gz\n│   ├── ERR10802865_R2.fastq.gz\n    ├── [...truncated...]\n├── meta\n│   └── metadata.tsv\n├── README.md\n└── ref\n    ├── GCF_016801865.2.fna\n    └── GCF_016801865.2.gtf\n\n3 directories, 48 files\n```\n\nWe'll take a look at some of the files:\n\n- The metadata file:\n\n  ```bash\n  cat data/meta/metadata.tsv\n  ```\n  ```bash-out\n  sample_id       time    treatment\n  ERR10802882     10dpi   cathemerium\n  ERR10802875     10dpi   cathemerium\n  ERR10802879     10dpi   cathemerium\n  ERR10802883     10dpi   cathemerium\n  ERR10802878     10dpi   control\n  ERR10802884     10dpi   control\n  ERR10802877     10dpi   control\n  ERR10802881     10dpi   control\n  ERR10802876     10dpi   relictum\n  ERR10802880     10dpi   relictum\n  ERR10802885     10dpi   relictum\n  ERR10802886     10dpi   relictum\n  ERR10802864     24hpi   cathemerium\n  ERR10802867     24hpi   cathemerium\n  ERR10802870     24hpi   cathemerium\n  ERR10802866     24hpi   control\n  ERR10802869     24hpi   control\n  ERR10802863     24hpi   control\n  ERR10802871     24hpi   relictum\n  ERR10802874     24hpi   relictum\n  ERR10802865     24hpi   relictum\n  ERR10802868     24hpi   relictum\n  ```\n\n- The FASTQ files:\n\n  ```bash\n  ls -lh data/fastq\n  ```\n  ```bash-out\n  total 941M\n  -rw-r--r-- 1 jelmer PAS2658 21M Mar 23 12:40 ERR10802863_R1.fastq.gz\n  -rw-r--r-- 1 jelmer PAS2658 22M Mar 23 12:40 ERR10802863_R2.fastq.gz\n  -rw-r--r-- 1 jelmer PAS2658 21M Mar 23 12:40 ERR10802864_R1.fastq.gz\n  -rw-r--r-- 1 jelmer PAS2658 22M Mar 23 12:40 ERR10802864_R2.fastq.gz\n  -rw-r--r-- 1 jelmer PAS2658 22M Mar 23 12:40 ERR10802865_R1.fastq.gz\n  -rw-r--r-- 1 jelmer PAS2658 22M Mar 23 12:40 ERR10802865_R2.fastq.gz\n  -rw-r--r-- 1 jelmer PAS2658 21M Mar 23 12:40 ERR10802866_R1.fastq.gz\n  -rw-r--r-- 1 jelmer PAS2658 22M Mar 23 12:40 ERR10802866_R2.fastq.gz\n  -rw-r--r-- 1 jelmer PAS2658 22M Mar 23 12:40 ERR10802867_R1.fastq.gz\n  -rw-r--r-- 1 jelmer PAS2658 22M Mar 23 12:40 ERR10802867_R2.fastq.gz\n  # [...output truncated...]\n  ```\n\n<hr style=\"height:1pt; visibility:hidden;\" />\n\n### How we'll run the pipeline\n\nAs discussed in the lecture,\nthe entire nf-core rnaseq pipeline can be run with a single command.\nThat said, before we can do so, we'll need to a bunch of prep, such as:\n\n- Activating the software environment and downloading the pipeline files.\n- Defining the pipeline's inputs and outputs, which includes creating a \"sample sheet\".\n- Creating a small \"config file\" to run Nextflow pipelines at OSC.\n\nWe need the latter configuration because\n**the pipeline will submit Slurm batch jobs for us** for each step of the pipeline.\nAnd in most steps, programs are run independently for each sample,\nso the pipeline will submit a separate job for each sample for these steps ---\ntherefore, we'll have many jobs altogether (typically 100s).\n\nThe main Nextflow process does not need much computing power\n(a single core with the default 4 GB of RAM will be sufficient)\nand even though our VS Code shell already runs on a compute and not a login node,\nwe are still better off **submitting the main process as a batch job as well**, because:\n\n- This process can run for hours and we don't want to risk it disconnecting.\n- We want to store all the standard output about pipeline progress and so on to a file ---\n  this will automatically end up in a Slurm log file if we submit it as a batch job.\n\n<hr style=\"height:1pt; visibility:hidden;\" />\n\n### Conceptual overview of our script setup\n\nWe will be working with two scripts in this lab,\nboth of which you already created an empty file for:\n\n- A \"runner\" script that you can also think of as a digital lab notebook,\n  containing _commands that we run interactively_.\n- A script that we will _submit as a Slurm batch job_ with `sbatch`,\n  containing code to run the nf-core nextflow pipeline.\n\nTo give you an idea of what this will look like ---\nthe _runner script_ will include code like this, which will submit the _job script_:\n\n```bash\n# [Don't run or copy this]\nsbatch scripts/nfc_rnaseq.sh \"$samplesheet\" \"$fasta\" \"$gtf\" \"$outdir\"\n```\n\nThe variables above (`\"$samplesheet\"` etc.) are the inputs and outputs of the pipeline,\nwhich we will have defined elsewhere in the runner script.\nInside the job script, we will then use these variables to run the pipeline\nin a specific way.\n\n<hr style=\"height:1pt; visibility:hidden;\" />\n\n### Activating the Conda environment\n\nTo save some time, you won't do your own Conda installation of\n[Nextflow](https://anaconda.org/bioconda/nextflow) or\n[nf-core tools](https://anaconda.org/bioconda/nf-core) ---\nI've installed both in an environment you can activate as follows:\n\n```bash\n# [Paste this code into the run/run.sh script, then run it in the terminal]\n\n# First load OSC's (mini)Conda module\nmodule load miniconda3\n# Then activate the Nextflow conda environment \nsource activate /fs/ess/PAS0471/jelmer/conda/nextflow\n```\n\nCheck that Nextflow and nf-core tools can be run by printing the versions:\n\n```bash\n# [Run this code directly in the terminal]\nnextflow -v\n```\n```bash-out\nnextflow version 23.10.1.5891\n```\n```bash\n# [Run this code directly in the terminal]\nnf-core --version\n```\n```bash-out\n                                          ,--./,-.\n          ___     __   __   __   ___     /,-._.--~\\\n    |\\ | |__  __ /  ` /  \\ |__) |__         }  {\n    | \\| |       \\__, \\__/ |  \\ |___     \\`-._,-`-,\n                                          `._,._,'\n\n    nf-core/tools version 2.13.1 - https://nf-co.re\n\nnf-core, version 2.13.1\n```\n\n<hr style=\"height:1pt; visibility:hidden;\" />\n\n### Downloading the nf-core rnaseq pipeline\n\nWe'll use the `nf-core download` command to download the rnaseq pipeline's files.\n\nFirst, we need to set the environment variable `NXF_SINGULARITY_CACHEDIR` to tell\nNextflow where to store the Singularity containers for all the tools the pipeline runs^[\nThese kinds of settings are more commonly specified with command _options_,\nbut somewhat oddly, this is the only way we can specify that here.].\nWe will use a dir of mine that already has all containers, to save some downloading time^[\nBut if you want to run a pipeline yourself for your own research,\nmake sure to use a dir that you have permissions to write to.\n]:\n\n```bash\n# [Paste this code into the run/run.sh script, then run it in the terminal]\n\n# Create an environment variable for the container dir\nexport NXF_SINGULARITY_CACHEDIR=/fs/ess/PAS0471/containers\n```\n\nNext, we'll run the `nf-core download` command to download the currently latest\nversion (`3.14.0`) of the rnaseq pipeline to `software/rnaseq`,\nand the associated container files to the previously specified dir:\n\n```bash\n# [Paste this code into the run/run.sh script, then run it in the terminal]\n\n# Download the nf-core rnaseq pipeline files\nnf-core download rnaseq \\\n    --revision 3.14.0 \\\n    --outdir software/nfc-rnaseq \\\n    --compress none \\\n    --container-system singularity \\\n    --container-cache-utilisation amend \\\n    --download-configuration\n```\n\n![](img/nfcore_download_output.png){fig-align=\"center\" width=90%\"}\n\n::: {.callout-tip collapse=\"true\"}\n#### Explanation of all options given to `nf-core download` _(Click to expand)_\n\n- `--revision`: The version of the rnaseq pipeline.\n- `--outdir`: The dir to save the pipeline definition files.\n- `--compress`: Whether to compress the pipeline files --- we chose not to.\n- `--container-system`: The type of containers to download.\n  This should always be `singularity` at OSC, because that's the only supported type.\n- `--container-cache-utilisation`: This is a little technical and not terribly interesting,\n  but we used `amend`, which will make it check our `$NXF_SINGULARITY_CACHEDIR` dir\n  for existing containers, and simply download any that aren't already found there.\n- `--download-configuration`: This will download some configuration files that we\n  will actually not use, but if you don't provide this option,\n  it will ask you about it when you run the command.\n  \nAlso, don't worry about the following warning, this doesn't impact the downloading:\n\n> WARNING  Could not find GitHub authentication token. Some API requests may fail.\n\n<hr style=\"height:1pt; visibility:hidden;\" />\n:::\n\nLet's take a quick peek at the dirs and files we just downloaded:\n\n```bash\n# [Run this code directly in the terminal]\nls software/nfc-rnaseq\n```\n```bash-out\n3_14_0  configs\n```\n\n```bash\n# [Run this code directly in the terminal]\nls software/nfc-rnaseq/3_14_0\n```\n```bash-out\nassets        CODE_OF_CONDUCT.md  LICENSE       nextflow.config       subworkflows\nbin           conf                main.nf       nextflow_schema.json  tower.yml\nCHANGELOG.md  docs                modules       pyproject.toml        workflows\nCITATIONS.md  lib                 modules.json  README.md\n```\n\nThe dir and file structure here is unfortunately quite complicated,\nas are the individual pipeline definition files,\nso we won't go into further detail about that here.\n\n<br>\n\n## Writing a shell script to run the pipeline\n\nIn this section, we'll go through the components of the `scripts/nfc-rnaseq.sh` script\nthat we'll later submit as a Slurm batch job.\nThe most important part of this script is the `nextflow` command that will actually\nrun the pipeline.\n\n### Building our `nextflow run` command\n\nTo run the pipeline, we use the command `nextflow run`,\nfollowed by the path to the dir that we just downloaded:\n\n```bash\n# [Partial shell script code, don't copy or run]\nnextflow run software/nfc-rnaseq/3_14_0\n```\n\nAfter that, there are several **required options**\n(see the [pipeline's documentation](https://nf-co.re/rnaseq/3.14.0/docs/usage)),\nwhich represent the input and output files/dirs for the pipeline:\n\n- **`--input`**: The path to a \"sample sheet\" with the paths to FASTQ files\n  (more on that below).\n- **`--fasta`**: The path to a reference genome assembly FASTA file ---\n  we'll use the FASTA file we have in `data/ref`.\n- **`--gtf`**: The path to a reference genome annotation file^[\n  Preferably in GTF (`.gtf`) format,\n  but the pipeline can accept GFF/GFF3 (`.gff`/`.gff3`) format files as well.]\n  --- we'll use the GTF file we have in `data/ref`.\n- **`--outdir`**: The path to the desired output dir for the _final_ pipeline output ---\n  this can be whatever we like.\n\nAs discussed in the lecture,\nthis pipeline has different options for e.g. alignment and quantification.\nWe will stick close to the defaults,\nwhich includes alignment with `STAR` and quantification with `Salmon`,\nwith one exception:\nwe want to remove reads from ribosomal RNA (this step is skipped by default).\n\n::: exercise\n#### {{< fa user-edit >}} Exercise: Finding the option to remove rRNA\nTake a look at the\n[\"Parameters\" tab on the pipeline's documentation website](https://nf-co.re/rnaseq/parameters):\n\n- Browse through the options for a bit to get a feel for the extent to which you\n  can customize the pipeline.\n- Try to find the option to turn on removal of rRNA with SortMeRNA.\n\n<details><summary> _Click for the solution_ </summary>\nThe option we want is **`--remove_ribo_rna`**.\n</details>\n:::\n\n<hr style=\"height:1pt; visibility:hidden;\" />\n\nWe'll also use several **general Nextflow options**\n(note the single dash `-` notation; pipeline-specific options have `--`):\n\n- **`-profile`**: A so-called \"profile\" ---\n  should be `singularity` when running the pipeline with Singularity containers.\n- **`work-dir`**: The dir in which all the pipeline's jobs/processes will run.\n- **`-ansi-log false`**: Change Nextflow's progress \"logging\" type to a format\n  that works with Slurm log files^[\n  The default logging does not work well the output goes to a text file,\n  as it will in our case because we will submit the script with the Nextflow command\n  as a Slurm batch job.].\n- **`-resume`**: Resume the pipeline where it \"needs to\" (e.g., where it left off)\n  instead of always starting over.\n\n::: {.callout-note collapse=\"true\"}\n#### More on `-work-dir` and `-resume` _(Click to expand)_\n\n**`work-dir`**: \n\nThe pipeline's final outputs will go to the `--outdir` we talked about earlier.\nBut all jobs/processes will run in, and initial outputs will be written to, a so-called `-work-dir`.\nAfter each process finishes, its key output files will then be copied to the final output dir.\n(There are also several pipeline options to customize what will and will not be copied.)\n\nThe distinction between such a work-dir and a final output dir can be very useful on\nHPC systems like OSC:\nyou can use a scratch dir (at OSC: `/fs/scratch/`) with lots of storage space\nand fast I/O as the `work-dir`,\nand a backed-up project dir (at OSC: `/fs/ess/`) as the `outdir`,\nwhich will then not become unnecessarily large.\n  \n**`-resume`:**\n\nBesides resuming wherever the pipeline left off after an incomplete run\n(for example: it ran out of time or ran into an error),\nthe `-resume` option also checks for any changes in input files or pipeline settings.\n\nFor example, if you have run the pipeline to completion previously,\nbut rerun it after adding or replace one sample,\n`-resume` would make the pipeline _only_ rerun the \"single-sample steps\" of the pipeline\n(which is most of them) for that sample as well as all steps that use all samples.\nSimilarly, if you change an option that affects one of the first processes in the pipeline,\nthe entire pipeline may be rerun,\nwhereas if you change an option that only affects the last process, then only that\nlast process would be rerun.\n\nThis option won't make any difference when we run the pipeline for the first time,\nsince there is nothing to resume.\nNextflow will even give a warning along these lines, but this is not a problem.\n:::\n\nWith all the above-mentioned options, our final `nextflow run` command will be:\n\n```bash\n# [Partial shell script code, don't copy or run]\nnextflow run software/nfc-rnaseq/3_14_0 \\\n    --input \"$samplesheet\" \\\n    --fasta \"$fasta\" \\\n    --gtf \"$gtf\" \\\n    --outdir \"$outdir\" \\\n    --remove_ribo_rna \\\n    -work-dir \"$outdir\"/raw \\\n    -profile singularity \\\n    -ansi-log false \\\n    -resume\n```\n\nThe command uses several variables (e.g. `\"$samplesheet\"`) ---\nthese will enter the script via command-line arguments.\n\n<hr style=\"height:1pt; visibility:hidden;\" />\n\n### Creating an OSC configuration file\n\nTo speed things up and make use of the computing power at OSC,\nwe want the pipeline to submit Slurm batch jobs for us.\n\nWe have to tell it to do this, and how, using a configuration (config) file.\nThere are multiple ways of storing this file and telling Nextflow about it ---\nthe one we'll use is to simply create a file `nextflow.config` in the dir from\nwhich we submit the `nextflow run` command:\nNextflow will automatically detect and parse such a file.\n\nWe will keep this file as simple as possible, only providing the \"executor\"\n(in our case: the Slurm program) and the OSC project to use:\n\n```bash\necho \"\nprocess.executor = 'slurm'\nprocess.clusterOptions='--account=PAS2658'\n\" > nextflow.config\n```\n\n<hr style=\"height:1pt; visibility:hidden;\" />\n\n### Adding `#SBATCH` options\n\nWe will use `#SBATCH` header lines to define some parameters for our batch job for Slurm.\nNote that these are **only** for the \"main\" Nextflow job,\nnot for the jobs that Nextflow itself will submit!\n\n```bash\n#SBATCH --account=PAS2658\n#SBATCH --time=3:00:00\n#SBATCH --mail-type=END,FAIL\n#SBATCH --output=slurm-nfc_rnaseq-%j.out\n```\n\n- `--account=PAS2658`: As always, we have to specify the OSC project.\n- `--time=3:00:00`: Ask for 3 hours\n  (note that for a run of a full data set, you may want to use 6-24 hours).\n- `--mail-type=END,FAIL`: Have Slurm send us an email when the job ends normally\n  or with an error.\n- `--output=slurm-nfc_rnaseq-%j.out`: Use a descriptive Slurm log file name\n  (`%j` is the Slurm job number).\n\nWe only a need a single core and up to a couple GB of RAM,\nso the associated Slurm defaults will work for us.\n  \n<hr style=\"height:1pt; visibility:hidden;\" />\n\n### The final script\n\nWe've covered most of the pieces of our script.\nBelow is the full code for the script, in which I also added:\n\n- A shebang header line to indicate that this is a Bash shell script: `#!/bin/bash`.\n- A line to use \"strict Bash settings\", `set -euo pipefail`^[\n  These setting will make the script abort whenever an error occurs,\n  and it will also turn referencing unassigned/non-existing variables into an error.\n  This is a recommended best-practice line to include in all shell scripts.].\n- Some `echo` reporting of arguments/variables, printing the date, etc.\n\n{{< fa user-edit >}} Open your `scripts/nfc-rnaseq.sh` script and paste the following into it:\n\n```bash\n#!/bin/bash\n#SBATCH --account=PAS2658\n#SBATCH --time=3:00:00\n#SBATCH --mail-type=END,FAIL\n#SBATCH --output=slurm-nfc_rnaseq-%j.out\n\n# Settings and constants\nWORKFLOW_DIR=software/nfc-rnaseq/3_14_0\n\n# Load the Nextflow Conda environment\nmodule load miniconda3\nsource activate /fs/ess/PAS0471/jelmer/conda/nextflow\nexport NXF_SINGULARITY_CACHEDIR=/fs/ess/PAS0471/containers\n\n# Strict Bash settings\nset -euo pipefail\n\n# Process command-line arguments\nsamplesheet=$1\nfasta=$2\ngtf=$3\noutdir=$4\n\n# Report\necho \"Starting script nfc-rnaseq.sh\"\ndate\necho \"Samplesheet:          $samplesheet\"\necho \"Reference FASTA:      $fasta\"\necho \"Reference GTF:        $gtf\"\necho \"Output dir:           $outdir\"\necho\n\n# Create the output dir\nmkdir -p \"$outdir\"\n\n# Create the config file\necho \"\nprocess.executor = 'slurm'\nprocess.clusterOptions='--account=PAS2658'\n\" > nextflow.config\n\n# Run the workflow\nnextflow run \"$WORKFLOW_DIR\" \\\n    --input \"$samplesheet\" \\\n    --fasta \"$fasta\" \\\n    --gtf \"$gtf\" \\\n    --outdir \"$outdir\" \\\n    --remove_ribo_rna \\\n    -work-dir \"$outdir\"/raw \\\n    -profile singularity \\\n    -ansi-log false \\\n    -resume\n\n# Report\necho \"Done with script nfc-rnaseq.sh\"\ndate\n```\n\n<hr style=\"height:1pt; visibility:hidden;\" />\n\n::: exercise\n#### {{< fa user-edit >}} Exercise: Take a look at the script\nGo through your complete `scripts/nfc-rnaseq.sh` script and see if you understand\neverything that's going on in there. Ask if you're confused about anything!\n:::\n\n<br>\n\n## Running the pipeline\n\nWe will now switch back to the `run/run.sh` script to add the code to submit our script.\nBut we'll have to create a sample sheet first.\n\n### Preparing the sample sheet\n\nThis pipeline requires a \"sample sheet\" as one of its inputs.\nIn the sample sheet, you provide the paths to your FASTQ files and the so-called\n\"strandedness\" of your RNA-Seq library.\n\n::: callout-note\n#### RNA-Seq library strandedness\nDuring RNA-Seq library prep, information about the directionality of the original\nRNA transcripts can be retained (resulting in a \"stranded\" library) or lost\n(resulting in an \"unstranded\" library: specify `unstranded` in the sample sheet).\n\nIn turn, stranded libraries can prepared either in\nreverse-stranded (`reverse`, by far the most common) or forward-stranded (`forward`) fashion.\nFor more information about library strandedness,\nsee [this page](https://www.azenta.com/blog/stranded-versus-non-stranded-rna-seq).\n\nThe pipeline also allows for a fourth option: `auto`,\nin which case the strandedness is automatically determined at the start of the pipeline\nby pseudo-mapping a small proportion of the data with Salmon.\n:::\n\nThe sample sheet should be a plain-text comma-separated values (CSV) file.\nHere is the example file from the\n[pipeline's documentation](https://nf-co.re/rnaseq/3.14.0/docs/usage#samplesheet-input):\n\n```bash-out-solo\nsample,fastq_1,fastq_2,strandedness\nCONTROL_REP1,AEG588A1_S1_L002_R1_001.fastq.gz,AEG588A1_S1_L002_R2_001.fastq.gz,auto\nCONTROL_REP1,AEG588A1_S1_L003_R1_001.fastq.gz,AEG588A1_S1_L003_R2_001.fastq.gz,auto\nCONTROL_REP1,AEG588A1_S1_L004_R1_001.fastq.gz,AEG588A1_S1_L004_R2_001.fastq.gz,auto\n```\n\nSo, we need a header row with column names, then one row per sample,\nand the following columns:\n\n- Sample ID (we will simply use the part of the file names shared by R1 and R2).\n- R1 FASTQ file path (including the dir unless they are in your working dir).\n- R2 FASTQ file path (idem).\n- Strandedness: `unstranded`, `reverse`, `forward`, or `auto` ---\n  this data is forward-stranded, so we'll use `forward`.\n\nYou can create this file in several ways ---\nwe will do it here with a helper script that comes with the pipeline^[\nThe box below shows an alternative method with Unix shell commands]:\n\n- First, we define an output dir (this will also be the output dir for the pipeline),\n  and the sample sheet file name:\n  \n  ```bash\n  # [Paste this into run/run.sh and then run it in the terminal]\n  \n  # Define the output dir and sample sheet file name\n  outdir=results/nfc-rnaseq\n  samplesheet=\"$outdir\"/nfc_samplesheet.csv\n  mkdir -p \"$outdir\"\n  ```\n\n- Next, we run that helper script, specifying the strandedness of our data,\n  the suffices of the R1 and R2 FASTQ files, and as arguments at the end,\n  the input FASTQ dir (`data/fastq`) and the output file (`$samplesheet`):\n\n  ```bash\n  # [Paste this into run/run.sh and then run it in the terminal]\n  \n  # Create the sample sheet for the nf-core pipeline\n  python3 software/nfc-rnaseq/3_14_0/bin/fastq_dir_to_samplesheet.py \\\n      --strandedness forward \\\n      --read1_extension \"_R1.fastq.gz\" \\\n      --read2_extension \"_R2.fastq.gz\" \\\n      data/fastq \\\n      \"$samplesheet\"\n  ```\n\n- Finally, let's check the contents of our newly created sample sheet file:\n\n  ```bash\n  # [Run this directly in the terminal]\n  cat \"$samplesheet\"\n  ```\n  ```bash-out\n  sample,fastq_1,fastq_2,strandedness\n  ERR10802863,data/fastq/ERR10802863_R1.fastq.gz,data/fastq/ERR10802863_R2.fastq.gz,forward\n  ERR10802864,data/fastq/ERR10802864_R1.fastq.gz,data/fastq/ERR10802864_R2.fastq.gz,forward\n  ERR10802865,data/fastq/ERR10802865_R1.fastq.gz,data/fastq/ERR10802865_R2.fastq.gz,forward\n  ERR10802866,data/fastq/ERR10802866_R1.fastq.gz,data/fastq/ERR10802866_R2.fastq.gz,forward\n  ERR10802867,data/fastq/ERR10802867_R1.fastq.gz,data/fastq/ERR10802867_R2.fastq.gz,forward\n  ERR10802868,data/fastq/ERR10802868_R1.fastq.gz,data/fastq/ERR10802868_R2.fastq.gz,forward\n  ERR10802869,data/fastq/ERR10802869_R1.fastq.gz,data/fastq/ERR10802869_R2.fastq.gz,forward\n  ERR10802870,data/fastq/ERR10802870_R1.fastq.gz,data/fastq/ERR10802870_R2.fastq.gz,forward\n  ERR10802871,data/fastq/ERR10802871_R1.fastq.gz,data/fastq/ERR10802871_R2.fastq.gz,forward\n  ERR10802874,data/fastq/ERR10802874_R1.fastq.gz,data/fastq/ERR10802874_R2.fastq.gz,forward\n  ERR10802875,data/fastq/ERR10802875_R1.fastq.gz,data/fastq/ERR10802875_R2.fastq.gz,forward\n  ERR10802876,data/fastq/ERR10802876_R1.fastq.gz,data/fastq/ERR10802876_R2.fastq.gz,forward\n  ERR10802877,data/fastq/ERR10802877_R1.fastq.gz,data/fastq/ERR10802877_R2.fastq.gz,forward\n  ERR10802878,data/fastq/ERR10802878_R1.fastq.gz,data/fastq/ERR10802878_R2.fastq.gz,forward\n  ERR10802879,data/fastq/ERR10802879_R1.fastq.gz,data/fastq/ERR10802879_R2.fastq.gz,forward\n  ERR10802880,data/fastq/ERR10802880_R1.fastq.gz,data/fastq/ERR10802880_R2.fastq.gz,forward\n  ERR10802881,data/fastq/ERR10802881_R1.fastq.gz,data/fastq/ERR10802881_R2.fastq.gz,forward\n  ERR10802882,data/fastq/ERR10802882_R1.fastq.gz,data/fastq/ERR10802882_R2.fastq.gz,forward\n  ERR10802883,data/fastq/ERR10802883_R1.fastq.gz,data/fastq/ERR10802883_R2.fastq.gz,forward\n  ERR10802884,data/fastq/ERR10802884_R1.fastq.gz,data/fastq/ERR10802884_R2.fastq.gz,forward\n  ERR10802885,data/fastq/ERR10802885_R1.fastq.gz,data/fastq/ERR10802885_R2.fastq.gz,forward\n  ERR10802886,data/fastq/ERR10802886_R1.fastq.gz,data/fastq/ERR10802886_R2.fastq.gz,forward\n  ```\n\n::: {.callout-note collapse=\"true\"}\n#### Creating the sample sheet with shell commands instead _(Click to expand)_\n\n```bash\n# A) Define the file name and create the header line\necho \"sample,fastq_1,fastq_2,strandedness\" > \"$samplesheet\"\n  \n# B) Add a row for each sample based on the file names\nls data/fastq/* | paste -d, - - |\n    sed -E -e 's/$/,forward/' -e 's@.*/(.*)_R1@\\1,&@' >> \"$samplesheet\"\n```\n\nHere is an explanation of the last command:\n\n- The `ls` command will spit out a list of all FASTQ files that includes the dir name.\n\n- `paste - -` will paste that FASTQ files side-by-side in two columns ---\n  because there are 2 FASTQ files per sample, and they are automatically correctly\n  ordered due to their file names, this will create one row per sample with the\n  R1 and R2 FASTQ files next to each other.\n\n- The `-d,` option to `paste` will use a comma instead of a Tab to delimit columns.\n\n- We use `sed` with extended regular expressions (`-E`) and two separate search-and-replace\n  expressions (we need `-e` in front of each when there is more than one).\n  \n- The first `sed` expression `'s/$/,forward/'` will simply add `,forward`\n  at the end (`$`) of each line to indicate the strandedness.\n\n- The second `sed` expression, `'s@.*/(.*)_R1@\\1,&@'`:\n  - Here we are adding the sample ID column by copying that part from the R1 FASTQ file name.\n  - This uses `s@<search>@replace@` with `@` instead of `/`, because there is a `/` in our search pattern.\n  - In the search pattern (`.*/(.*)_R1`), we capture the sample ID with `(.*)`.\n  - In the replace section (`\\1,&`), we recall the captured sample ID with `\\1`,\n    then insert a comma, and then insert the _full_ search pattern match\n    (i.e., the path to the R1 file) with `&`.\n\n- We _append_ (`>>`) to the file because we need to keep the header line that\n  we had already put in it.\n:::\n\n<hr style=\"height:1pt; visibility:hidden;\" />\n\n### Submitting our shell script\n\nAs a last preparatory step,\nwe will save the paths of the reference genome files in variables:\n\n```bash\n# [Paste this into run/run.sh and then run it in the terminal]\n# Define the reference genome files\nfasta=data/ref/GCF_016801865.2.fna\ngtf=data/ref/GCF_016801865.2.gtf\n```\n\nBefore we submit the script,\nlet's check that all the variables have been assigned by prefacing the command with `echo`:\n\n```bash\n# [ Run this directly in the terminal]\necho sbatch scripts/nfc-rnaseq.sh \"$samplesheet\" \"$fasta\" \"$gtf\" \"$outdir\"\n```\n```bash-out\nsbatch scripts/nfc-rnaseq.sh results/nfc-rnaseq/nfc_samplesheet.csv data/ref/GCF_016801865.2.fna data/ref/GCF_016801865.2.gtf results/nfc-rnaseq\n```\n\nNow we are ready to submit the script as a batch job:\n\n```bash\n# [Paste this into run/run.sh and then run it in the terminal]\n# Submit the script to run the pipeline as a batch job\nsbatch scripts/nfc-rnaseq.sh \"$samplesheet\" \"$fasta\" \"$gtf\" \"$outdir\"\n```\n```bash-out\nSubmitted batch job 27767854\n```\n\n<hr style=\"height:1pt; visibility:hidden;\" />\n\n### Checking the pipeline's progress\n\nWe can check whether our job has started running,\nand whether Nextflow has already spawned jobs, with `squeue`:\n\n```bash\n# [Run this directly in the terminal]\nsqueue -u $USER -l\n```\n```bash-out\nMon Mar 25 12:13:38 2024\n      JOBID PARTITION     NAME     USER    STATE   TIME TIME_LIMI  NODES NODELIST(REASON)\n  27767854 serial-40 nfc-rnas   jelmer  RUNNING    1:33   3:00:00      1 p0219\n```\n\nIn the example output above, the only running job is the one we directly submitted,\ni.e. the main Nextflow process.\nBecause we didn't give the job a name, the `NAME` column is the script's name,\n`nfc-rnaseq.sh` (truncated to `nfc-rnas`).\n\n::: {.callout-note collapse=\"true\"}\n#### See examples of `squeue` output that includes Nextflow-submitted jobs _(Click to expand)_\n\nThe top job, with partial name `nf-NFCOR`, is a job that's been submitted by Nextflow:\n\n```bash\nsqueue -u $USER -l\n```\n```bash-out\nMon Mar 25 13:14:53 2024\n             JOBID PARTITION     NAME     USER    STATE       TIME TIME_LIMI  NODES NODELIST(REASON)\n          27767861 serial-40 nf-NFCOR   jelmer  RUNNING       5:41  16:00:00      1 p0053\n          27767854 serial-40 nfc_rnas   jelmer  RUNNING    1:03:48   3:00:00      1 p0219\n```\n\nUnfortunately, the columns in the output above are quite narrow,\nso it's **not possible to see which step of the pipeline is being run by that job**.\nThe following (awful-looking!) code can be used to make that column much wider,\nso we can see the job's full name which makes clear which step is being run\n(rRNA removal with SortMeRNA):\n\n```bash\nsqueue -u $USER --format=\"%.9i %.9P %.60j %.8T %.10M %.10l %.4C %R %.16V\"\n```\n```bash-out\nMon Mar 25 13:15:05 2024\n    JOBID PARTITION                                                          NAME    STATE       TIME TIME_LIMIT CPUS NODELIST(REASON)      SUBMIT_TIME\n 27767861 serial-40   nf-NFCORE_RNASEQ_RNASEQ_SORTMERNA_(SRR27866691_SRR27866691)  RUNNING       5:55   16:00:00   12 p0053 2024-03-23T09:37\n 27767854 serial-40                                                    nfc_rnaseq  RUNNING    1:04:02    3:00:00    1 p0219 2024-03-23T09:36\n```\n\nYou might also catch the pipeline while there are many more jobs running, e.g.:\n\n```bash-out-solo\nMon Mar 25 13:59:50 2024\n             JOBID PARTITION     NAME     USER    STATE       TIME TIME_LIMI  NODES NODELIST(REASON)\n          27823107 serial-40 nf-NFCOR   jelmer  RUNNING       0:13  16:00:00      1 p0091\n          27823112 serial-40 nf-NFCOR   jelmer  RUNNING       0:13  16:00:00      1 p0119\n          27823115 serial-40 nf-NFCOR   jelmer  RUNNING       0:13  16:00:00      1 p0055\n          27823120 serial-40 nf-NFCOR   jelmer  RUNNING       0:13  16:00:00      1 p0055\n          27823070 serial-40 nf-NFCOR   jelmer  RUNNING       0:43  16:00:00      1 p0078\n          27823004 serial-40 nfc-rnas   jelmer  RUNNING       2:13   3:00:00      1 p0146\n          27823083 serial-40 nf-NFCOR   jelmer  RUNNING       0:37  16:00:00      1 p0078\n          27823084 serial-40 nf-NFCOR   jelmer  RUNNING       0:37  16:00:00      1 p0096\n          27823085 serial-40 nf-NFCOR   jelmer  RUNNING       0:37  16:00:00      1 p0096\n          27823086 serial-40 nf-NFCOR   jelmer  RUNNING       0:37  16:00:00      1 p0115\n          27823087 serial-40 nf-NFCOR   jelmer  RUNNING       0:37  16:00:00      1 p0115\n          27823088 serial-40 nf-NFCOR   jelmer  RUNNING       0:37  16:00:00      1 p0123\n          27823089 serial-40 nf-NFCOR   jelmer  RUNNING       0:37  16:00:00      1 p0123\n          27823090 serial-40 nf-NFCOR   jelmer  RUNNING       0:37  16:00:00      1 p0057\n          27823091 serial-40 nf-NFCOR   jelmer  RUNNING       0:37  16:00:00      1 p0057\n          27823092 serial-40 nf-NFCOR   jelmer  RUNNING       0:37  16:00:00      1 p0058\n          27823093 serial-40 nf-NFCOR   jelmer  RUNNING       0:37  16:00:00      1 p0058\n          27823095 serial-40 nf-NFCOR   jelmer  RUNNING       0:37  16:00:00      1 p0118\n          27823099 serial-40 nf-NFCOR   jelmer  RUNNING       0:37  16:00:00      1 p0118\n          27823103 serial-40 nf-NFCOR   jelmer  RUNNING       0:37  16:00:00      1 p0119\n          27823121 serial-48 nf-NFCOR   jelmer  RUNNING       0:13  16:00:00      1 p0625\n          27823122 serial-48 nf-NFCOR   jelmer  RUNNING       0:13  16:00:00      1 p0744\n          27823123 serial-48 nf-NFCOR   jelmer  RUNNING       0:13  16:00:00      1 p0780\n          27823124 serial-48 nf-NFCOR   jelmer  RUNNING       0:13  16:00:00      1 p0780\n```\n:::\n\nWe can keep an eye on the pipeline's progress, and see if there are any errors,\nby checking the Slurm log file --- the top of the file should look like this:\n\n```bash\n# You will have a different job ID - replace as appropriate or use Tab completion\nless slurm-nfc_rnaseq-27767861.out\n```\n```bash-out\nStarting script nfc-rnaseq.sh\nMon Mar 25 13:01:30 EDT 2024\nSamplesheet:          results/nfc-rnaseq/nfc_samplesheet.csv\nReference FASTA:      data/ref/GCF_016801865.2.fna\nReference GTF:        data/ref/GCF_016801865.2.gtf\nOutput dir:           results/nfc-rnaseq\n\nN E X T F L O W  ~  version 23.10.1\nWARN: It appears you have never run this project before -- Option `-resume` is ignored\nLaunching `software/nfc-rnaseq/3_14_0/main.nf` [curious_linnaeus] DSL2 - revision: 746820de9b\nWARN: ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n  Multiple config files detected!\n  Please provide pipeline parameters via the CLI or Nextflow '-params-file' option.\n  Custom config files including those provided by the '-c' Nextflow option can be\n  used to provide any configuration except for parameters.\n\n  Docs: https://nf-co.re/usage/configuration#custom-configuration-files\n~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n\n\n------------------------------------------------------\n                                        ,--./,-.\n        ___     __   __   __   ___     /,-._.--~'\n  |\\ | |__  __ /  ` /  \\ |__) |__         }  {\n  | \\| |       \\__, \\__/ |  \\ |___     \\`-._,-`-,\n                                        `._,._,'\n  nf-core/rnaseq v3.14.0\n------------------------------------------------------\nCore Nextflow options\n  runName                   : curious_linnaeus\n  containerEngine           : singularity\n[...output truncated...]\n```\n\nThe warnings about `-resume` and config files shown above can be ignored.\nSome of this output actually has nice colors:\n\n![](img/slurmlog.png){fig-align=\"center\" width=\"95%\"}\n\nIn the Slurm log file, the job progress is show in the following way ---\nwe only see which jobs are being submitted, not when they finish^[\nThe default Nextflow logging (without `-ansi-log false`) does show when jobs finish,\nbut this would result in very messy output in a Slurm log file.\n]:\n\n```bash-out-solo\n[e5/da8328] Submitted process > NFCORE_RNASEQ:RNASEQ:PREPARE_GENOME:GTF_FILTER (GCF_016801865.2.fna)\n[b5/9427a1] Submitted process > NFCORE_RNASEQ:RNASEQ:PREPARE_GENOME:CUSTOM_GETCHROMSIZES (GCF_016801865.2.fna)\n[05/e0e09f] Submitted process > NFCORE_RNASEQ:RNASEQ:FASTQ_FASTQC_UMITOOLS_TRIMGALORE:TRIMGALORE (ERR10802863)\n[25/a6c2f5] Submitted process > NFCORE_RNASEQ:RNASEQ:FASTQ_FASTQC_UMITOOLS_TRIMGALORE:FASTQC (ERR10802863)\n[24/cef9a0] Submitted process > NFCORE_RNASEQ:RNASEQ:FASTQ_FASTQC_UMITOOLS_TRIMGALORE:TRIMGALORE (ERR10802864)\n[b1/9cfa7e] Submitted process > NFCORE_RNASEQ:RNASEQ:FASTQ_FASTQC_UMITOOLS_TRIMGALORE:FASTQC (ERR10802864)\n[c4/3107c1] Submitted process > NFCORE_RNASEQ:RNASEQ:FASTQ_FASTQC_UMITOOLS_TRIMGALORE:TRIMGALORE (ERR10802865)\n[7e/92ec89] Submitted process > NFCORE_RNASEQ:RNASEQ:FASTQ_FASTQC_UMITOOLS_TRIMGALORE:TRIMGALORE (ERR10802866)\n[01/f7ccfb] Submitted process > NFCORE_RNASEQ:RNASEQ:FASTQ_FASTQC_UMITOOLS_TRIMGALORE:FASTQC (ERR10802866)\n[42/4b4da2] Submitted process > NFCORE_RNASEQ:RNASEQ:FASTQ_FASTQC_UMITOOLS_TRIMGALORE:TRIMGALORE (ERR10802868)\n[8c/fe6ca5] Submitted process > NFCORE_RNASEQ:RNASEQ:FASTQ_FASTQC_UMITOOLS_TRIMGALORE:TRIMGALORE (ERR10802867)\n[e6/a12ec8] Submitted process > NFCORE_RNASEQ:RNASEQ:FASTQ_FASTQC_UMITOOLS_TRIMGALORE:FASTQC (ERR10802867)\n[2e/f9059d] Submitted process > NFCORE_RNASEQ:RNASEQ:FASTQ_FASTQC_UMITOOLS_TRIMGALORE:FASTQC (ERR10802865)\n[de/2735d1] Submitted process > NFCORE_RNASEQ:RNASEQ:FASTQ_FASTQC_UMITOOLS_TRIMGALORE:FASTQC (ERR10802868)\n```\n\n<details><summary>You should also see the following warning among the job submissions _(Click to expand)_</summary>\n\nThis warning can be ignored, the \"Biotype QC\" is not important and this information\nis indeed simply missing from our GTF file, there is nothing we can do about that.\n\n```bash-out-solo\nWARN: ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n  Biotype attribute 'gene_biotype' not found in the last column of the GTF file!\n\n  Biotype QC will be skipped to circumvent the issue below:\n  https://github.com/nf-core/rnaseq/issues/460\n\n  Amend '--featurecounts_group_type' to change this behaviour.\n~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n```\n</details>\n\nBut any errors would be reported in this file,\nand we can also see when the pipeline has finished:\n\n```bash-out-solo\n[28/79e801] Submitted process > NFCORE_RNASEQ:RNASEQ:BEDGRAPH_BEDCLIP_BEDGRAPHTOBIGWIG_FORWARD:UCSC_BEDGRAPHTOBIGWIG (ERR10802864)\n[e0/ba48c9] Submitted process > NFCORE_RNASEQ:RNASEQ:BEDGRAPH_BEDCLIP_BEDGRAPHTOBIGWIG_REVERSE:UCSC_BEDGRAPHTOBIGWIG (ERR10802864)\n[62/4f8c0d] Submitted process > NFCORE_RNASEQ:RNASEQ:MULTIQC (1)\n-[nf-core/rnaseq] Pipeline completed successfully -\nDone with script nfc-rnaseq.sh\nMon Mar 25 14:09:52 EDT 2024\n```\n\n<br>\n\n## Checking the pipeline's outputs\n\nIf your pipeline run finished in time\n(it may finish in as little as 15-30 minutes, but this can vary substantially^[\nThis variation is mostly the result of variation in Slurm queue-ing times.\nThe pipeline makes quite large resource requests,\nso you sometimes have to wait for a while for some jobs to start.\n]),\nyou can take a look at the files and dirs in the output dir we specified:\n\n```bash\nls -lh results/nfc-rnaseq\n```\n```bash-out\ntotal 83K\ndrwxr-xr-x   2 jelmer PAS0471  16K Mar 25 13:02 fastqc\ndrwxr-xr-x   2 jelmer PAS0471 4.0K Mar 25 12:58 logs\ndrwxr-xr-x   3 jelmer PAS0471 4.0K Mar 25 13:14 multiqc\n-rw-r--r--   1 jelmer PAS0471 2.0K Mar 25 19:55 nfc_samplesheet.csv\ndrwxr-xr-x   2 jelmer PAS0471 4.0K Mar 25 13:14 pipeline_info\ndrwxr-xr-x 248 jelmer PAS0471  16K Mar 25 13:10 raw\ndrwxr-xr-x   2 jelmer PAS0471 4.0K Mar 25 13:06 sortmerna\ndrwxr-xr-x  33 jelmer PAS0471  16K Mar 25 13:12 star_salmon\ndrwxr-xr-x   3 jelmer PAS0471 4.0K Mar 25 13:02 trimgalore\n```\n\nThe two outputs we are most interested in are:\n\n- The **MultiQC report** (`<outdir>/multiqc/star_salmon/multiqc_report.html`):\n  this has lots of QC summaries of the data, both the raw data and the alignments,\n  and even a gene expression PCA plot.\n  \n- The **gene count table** (`<outdir>/star_salmon/salmon.merged.gene_counts_length_scaled.tsv`):\n  if you do the [Gene count table analysis](lab2.qmd) lab,\n  you will use an equivalent file (but then run on the _full_ data set) as the main input.\n\n<hr style=\"height:1pt; visibility:hidden;\" />\n\n### The MultiQC report\n\nYou can find a copy of the MultiQC report on this website,\n[here](results/multiqc_report.html).\nGo ahead and open that in a separate browser tab.\nThere's a lot of information in the report!\nHere are some items to especially pay attention to, with figures from our own data set:\n\n- The **General Statistics** table (the first section) is very useful,\n  with the following notes:\n  \n  - Most of the table's content is also in later graphs,\n    but the table allows for comparisons across metrics.\n  \n  - The `%rRNA` (% of reads identified as rRNA and removed by SortMeRNA)\n    can only be found in this table.\n  \n  - It's best to _hide the columns with statistics from Samtools_,\n    which can be confusing if not downright misleading: click on \"Configure Columns\"\n    and uncheck all the boxes for stats with Samtools in their name.\n  \n  - Some stats are for R1 and R2 files only, and some are for each sample as a whole.\n    Unfortunately, this means you get 3 rows per sample in the table.\n\n![](img/multiqc_table.png){fig-align=\"center\" width=\"90%\"}\n\n<hr style=\"height:1pt; visibility:hidden;\" />\n\n- The **Qualimap** > **Genomic origin of reads** plot shows, for each sample,\n  the proportion of reads mapping to exonic vs. intronic vs. intergenic regions.\n  This is an important QC plot: the vast majority of your reads should be exonic^[\n  A lot of intronic content may indicate that you have a lot of pre-mRNA in your data;\n  this is more common when your library prep used rRNA depletion instead of poly-A selection.\n  A lot of intergenic content may indicate DNA contamination.\n  Poor genome annotation quality may also contribute to a low percentage of exonic reads.\n  The _RSeQC_ > _Read Distribution_ plot will show this with even more categories,\n  e.g. separately showing UTRs.].\n\n![This is a good result, with 80-90% of mapped reads in exonic regions.](img/multiqc_genomic-origin.png){fig-align=\"center\" width=\"90%\"}\n\n<hr style=\"height:1pt; visibility:hidden;\" />\n\n- The **STAR** > **Alignment Scores** plot shows, for each sample,\n  the percentage of reads that was mapped.\n  Note that \"Mapped to multiple loci\" reads _are_ also included in the final counts,\n  and that \"Unmapped: too short\" merely means unmapped, really, and not that the\n  reads were too short.\n\n![This is a pretty good results, with 80-90% of reads mapped.](img/multiqc_star.png){fig-align=\"center\" width=\"90%\"}\n\n<hr style=\"height:1pt; visibility:hidden;\" />\n\n- **FastQC** checks your FASTQ files, i.e. your data prior to alignment.\n  There are FastQC plots both before and after trimming with TrimGalore/Cutadapt.\n  The most important FastQC modules are:\n  - **Sequence Quality Histograms** --- You'd like the mean qualities to stay in the \"green area\".\n  - **Per Sequence GC Content** --- Secondary peaks may indicate contamination.\n  - **Adapter Content** --- Any adapter content should be gone in the post-trimming plot.\n\n<hr style=\"height:1pt; visibility:hidden;\" />\n\n::: exercise\n#### {{< fa user-edit >}} Exercise: Interpreting FastQC results in the MultiQC report\n\nTake a look at the three FastQC modules discussed above, both before and after trimming.\n\n- Has the base quality improved after trimming, and does this look good?\n\n<details><summary>*Click to see the answer*</summary>\n\n- Pre-trimming graph: The qualities are good overall, but there is more variation\n  that what is usual, and note the poorer qualities in the first 7 or so bases.\n  There is no substantial decline towards the end of the read as one often sees\n  with Illumina data, but this is expected given that the reads are only 75 bp.\n  \n![**Pre-trimming** (Mean base quality scores: one line is one sample.)](img/multiqc_basequal_pretrim.png){fig-align=\"center\" width=\"90%\"}\n\n- Post-trimming graph: The qualities have clearly improved.\n  The first 7 or so bases remain of clearly poorer quality, on average.\n\n![**Post-trimming** ](img/multiqc_basequal_posttrim.png){fig-align=\"center\" width=\"90%\"}\n\n</details>\n\n- Do you have any idea what's going with the pre-trimming GC content distribution?\n  What about after trimming --- does this look good or is there reason to worry?\n\n<details><summary>*Click to see the answer*</summary>\n\n- The pre-trimming GC content is very odd but this is mostly due to a high number\n  of reads with zero and near-zero percent GC content.\n  These are likely reads with only Ns.\n  There are also some reads with near-hundred percent GC content.\n  These are likely artifactual G-only reads that NextSeq/NovaSeq machines can produce.\n  \n![**Pre-trimming**. One line is one file.](img/multiqc_gc-pretrim.png){fig-align=\"center\" width=\"90%\"}\n\n- After trimming, things look a lot better but there may be contamination here,\n  given the weird \"shoulder\" at 30-40% GC.\n\n![**Post-trimming**](img/multiqc_gc-posttrim.png){fig-align=\"center\" width=\"90%\"}\n\n</details>\n\n- Do you know what the \"adapters\" that FastQC found pre-trimming are?\n  Were these sequences removed by the trimming?\n\n<details><summary>*Click to see the answer*</summary>\n\n- Pre-trimming, there seem to be some samples with very high adapter content throughout\n  the read. This doesn't make sense for true adapters, because these are usually\n  only found towards the end of the read, when the read length is longer than the\n  DNA fragment length. If you hover over the lines, you'll see it says \"polyg\".\n  These are artifactual G-only reads that NextSeq/NovaSeq can produce,\n  especially in the reverse reads --- and you can see that all of the lines are\n  for reverse-read files indeed.\n\n![**Pre-trimming**](img/multiqc_adapter-pretrim.png){fig-align=\"center\" width=\"90%\"}\n\n- Post-trimming, no adapter content was found.\n\n![**Post-trimming**](img/multiqc_adapter-posttrim.png){fig-align=\"center\" width=\"90%\"}\n\n</details>\n:::\n\n<hr style=\"height:1pt; visibility:hidden;\" />\n\n::: {.callout-note collapse=\"true\"}\n#### Some additional graphs of interest in the MultiQC report _(Click to expand)_\n\n- The **Qualimap** > **Gene Coverage Profile** plot.\n  This shows average read-depth across the position of genes/transcripts\n  (for all genes together), which helps to assess the amount of RNA degradation.\n  For poly-A selected libraries, RNA molecules \"begin\" at the 3' end\n  (right-hand side of the graph), so the more degradation there is,\n  the more you expect there to be a higher read-depth towards the 3' end compared\n  to the 5' end.\n  (Though note that sharp decreases at the _very_ end on each side are expected.)\n\n![There depth at ~20% (near the 5' end) is clearly lower than at ~80% (near the 3' end),<br>indicating some RNA degradation.](img/multiqc_gene-coverage.png){fig-align=\"center\" width=\"85%\"}\n\n- The **RSeqQC** > **Infer experiment** (library strandedness) plot. If your library is:\n  - Unstranded, there should be similar percentages of Sense and Antisense reads.\n  - Forward-stranded, the vast majority of reads should be Sense.\n  - Reverse-stranded, the vast majority of reads should be Antisense.\n\n![This libary is clearly forward-stranded, as we indicated in our sample sheet.](img/multiqc_strandedness.png){fig-align=\"center\" width=\"85%\"}\n\n- The **STAR_SALMON DESeq2 PCA** plot is from a Principal Component Analysis (PCA) run\n  on the final gene count table, thus showing overall patterns of gene expression\n  similarity among samples.\n\n![The sampels clear form two distinct groups along PC1.](img/multiqc_pca.png){fig-align=\"center\" width=\"80%\"}\n:::\n  \n::: {.callout-tip collapse=\"true\"}\n#### Did your pipeline run finish? Here's how to check out your own MultiQC report _(Click to expand)_\nTo download the MultiQC HTML file at\n`results/nfc-rnaseq/multiqc/star_salmon/multiqc_report.html`, \nfind this file in the VS Code explorer (file browser) on the left,\nright-click on it, and select `Download...`.\n\nYou can download it to any location on your computer.\nThen find the file on your computer and click on it to open it ---\nit should be opened in your browser.\n:::\n\n<hr style=\"height:1pt; visibility:hidden;\" />\n\n### The gene count table\n\nThe gene count table has one row for each gene and one column for each sample,\nwith the first two columns being the `gene_id` and `gene_name`^[\nWhich happen to be the same here, but these are usually different.].\nEach cell's value contains the read count estimate for a specific gene in a specific sample:\n\n```bash\n# [Paste this into the run/run.sh script and run it in the terminal]\n\n# Take a look at the count table:\n# ('column -t' lines up columns, and less's '-S' option turns off line wrapping)\ncounts=results/nfc-rnaseq/star_salmon/salmon.merged.gene_counts_length_scaled.tsv\ncolumn -t \"$counts\" | less -S\n```\n```bash-out\ngene_id             gene_name           ERR10802863        ERR10802864        ERR10802865        ERR10802866        ERR10802867        ERR10802868       \nATP6                ATP6                163.611027228009   178.19903533081    82.1025390726658   307.649552934133   225.78249209207    171.251589309856  \nATP8                ATP8                0                  1.01047333891691   0                  0                  0                  0                 \nCOX1                COX1                1429.24769032452   2202.82009602881   764.584344577622   2273.6965332904    2784.47391614249   2000.51277019854  \nCOX2                COX2                116.537361366535   175.137972566817   54.0166352459629   256.592955351283   193.291937038438   164.125833130119  \nCOX3                COX3                872.88670991359    1178.29247734231   683.167933227141   1200.01735304529   1300.3853323715    1229.11746824104  \nCYTB                CYTB                646.028108528182   968.256051104547   529.393909319439   1025.23768317788   1201.46662840336   842.533209911258  \nLOC120412322        LOC120412322        0                  0                  0                  0                  0.995135178345792  0.996805450081561 \nLOC120412324        LOC120412324        37.8326244586681   20.9489661184365   27.6702324729125   48.6417838830061   22.8313729348804   36.87899862428    \nLOC120412325        LOC120412325        3.21074365394071   2.10702898851342   4.40315394778926   5.47978997387391   4.33241716734803   4.23386924919438  \nLOC120412326        LOC120412326        0                  0                  0                  0                  0                  0                 \nLOC120412327        LOC120412327        37.8206758601034   35.9063291323018   38.517771617566    27.7802608986967   37.6979028802121   32.885944667709   \nLOC120412328        LOC120412328        35.0080600370267   20.0019192467143   23.9260736995594   30.0191332346116   21.0383665366408   28.9844776623531  \nLOC120412329        LOC120412329        121.777922287929   112.794544755113   131.434181046282   127.753086659103   114.864750589664   131.589608063253  \nLOC120412330        LOC120412330        42.8505448763697   28.9442284428204   36.6285174684674   46.7310765909945   42.7633834468768   26.9265243413636  \nLOC120412331        LOC120412331        11.013179311581    9.00559907892481   12.9836833055803   13.029954361225    7.02624958751718   16.000552787954   \nLOC120412332        LOC120412332        12.1055360835441   26.1231316926989   21.2767913384733   18.2783703626438   26.4932540325187   22.098808637857   \nLOC120412333        LOC120412333        19.1159998132169   17.0558058070299   12.0965688236319   14.1510477997588   15.2033452089903   9.02624985028677  \nLOC120412334        LOC120412334        9.01332125155807   3.00232591636489   5.99566364212933   11.0306919231504   8.03448732510427   11.0022053123759  \n# [...output truncated...]\n```\n\n::: callout-note\n#### Count table versions\nThe workflow outputs several versions of the count table^[\nAnd each version in two formats: `.rds` (a binary R object file type) and `.tsv`.\n], but the one with `gene_counts_length_scaled` is the one we want:\n\n- `gene_counts` as opposed to `transcript_counts` for counts that are summed across\n  transcripts for each gene.\n- `length` for estimates that have been adjusted to account for between-sample\n  differences in mean transcript length\n  (longer transcripts would be expected to produce more reads in sequencing).\n- `scaled` for estimates that have been scaled back using the \"library sizes\",\n  per-sample total read counts.\n:::\n\n<br> <br>\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}